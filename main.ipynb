{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "class DataPreprocessor:\n",
    "    def __init__(self, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the Data Preprocessor with required models and tools\n",
    "        \n",
    "        Args:\n",
    "            model_name (str): The SentenceTransformer model to use for embeddings\n",
    "        \"\"\"\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.sentence_model = SentenceTransformer(model_name)\n",
    "        self.tfidf_vectorizer = TfidfVectorizer()\n",
    "        self.bm25 = None\n",
    "        self.processed_data = None\n",
    "        self.embeddings = None\n",
    "        \n",
    "    def load_dataset(self, file_paths):\n",
    "        \"\"\"\n",
    "        Load and merge multiple legal QA datasets\n",
    "        \n",
    "        Args:\n",
    "            file_paths (dict): Dictionary mapping dataset names to file paths\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Combined dataset\n",
    "        \"\"\"\n",
    "        combined_data = []\n",
    "        \n",
    "        for dataset_name, file_path in file_paths.items():\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Handle different possible JSON structures\n",
    "                if isinstance(data, list):\n",
    "                    for item in data:\n",
    "                        if isinstance(item, dict):\n",
    "                            item['source'] = dataset_name\n",
    "                            combined_data.append(item)\n",
    "                elif isinstance(data, dict):\n",
    "                    for key, item in data.items():\n",
    "                        if isinstance(item, dict):\n",
    "                            item['source'] = dataset_name\n",
    "                            item['id'] = key\n",
    "                            combined_data.append(item)\n",
    "                \n",
    "                print(f\"Successfully loaded {len(data)} QA pairs from {dataset_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        \n",
    "        # Create DataFrame and ensure required columns\n",
    "        df = pd.DataFrame(combined_data)\n",
    "        \n",
    "        # Standardize column names if needed\n",
    "        if 'question' not in df.columns and 'Question' in df.columns:\n",
    "            df = df.rename(columns={'Question': 'question'})\n",
    "        if 'answer' not in df.columns and 'Answer' in df.columns:\n",
    "            df = df.rename(columns={'Answer': 'answer'})\n",
    "            \n",
    "        print(f\"Combined dataset contains {len(df)} QA pairs\")\n",
    "        return df\n",
    "    \n",
    "    def normalize_text(self, text):\n",
    "        \"\"\"\n",
    "        Normalize text by removing special characters, extra spaces, etc.\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to normalize\n",
    "            \n",
    "        Returns:\n",
    "            str: Normalized text\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "            \n",
    "        # Convert to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove special characters but keep legal symbols like §, ¶\n",
    "        text = re.sub(r'[^\\w\\s§¶.,-]', ' ', text)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def tokenize_text(self, text):\n",
    "        \"\"\"\n",
    "        Tokenize text into words, removing stopwords\n",
    "        \n",
    "        Args:\n",
    "            text (str): Input text to tokenize\n",
    "            \n",
    "        Returns:\n",
    "            list: List of tokens\n",
    "        \"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            return []\n",
    "            \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        \n",
    "        # Remove stopwords\n",
    "        tokens = [token for token in tokens if token.lower() not in self.stop_words]\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def preprocess_dataset(self, df):\n",
    "        \"\"\"\n",
    "        Apply preprocessing to the entire dataset\n",
    "        \n",
    "        Args:\n",
    "            df (pandas.DataFrame): Dataset with questions and answers\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Preprocessed dataset\n",
    "        \"\"\"\n",
    "        # Make a copy to avoid modifying the original\n",
    "        processed_df = df.copy()\n",
    "        \n",
    "        # Normalize questions and answers\n",
    "        processed_df['normalized_question'] = processed_df['question'].apply(self.normalize_text)\n",
    "        processed_df['normalized_answer'] = processed_df['answer'].apply(self.normalize_text)\n",
    "        \n",
    "        # Tokenize questions and answers\n",
    "        processed_df['tokenized_question'] = processed_df['normalized_question'].apply(self.tokenize_text)\n",
    "        processed_df['tokenized_answer'] = processed_df['normalized_answer'].apply(self.tokenize_text)\n",
    "        \n",
    "        # Create a combined field for context retrieval\n",
    "        processed_df['combined_text'] = processed_df['normalized_question'] + \" \" + processed_df['normalized_answer']\n",
    "        \n",
    "        self.processed_data = processed_df\n",
    "        return processed_df\n",
    "    \n",
    "    def generate_embeddings(self):\n",
    "        \"\"\"\n",
    "        Generate embeddings for questions and answers using SentenceTransformer\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary containing question and answer embeddings\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Call preprocess_dataset first.\")\n",
    "        \n",
    "        print(\"Generating embeddings for questions...\")\n",
    "        question_embeddings = self.sentence_model.encode(\n",
    "            self.processed_data['normalized_question'].tolist(),\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        print(\"Generating embeddings for answers...\")\n",
    "        answer_embeddings = self.sentence_model.encode(\n",
    "            self.processed_data['normalized_answer'].tolist(),\n",
    "            show_progress_bar=True\n",
    "        )\n",
    "        \n",
    "        self.embeddings = {\n",
    "            'question': question_embeddings,\n",
    "            'answer': answer_embeddings\n",
    "        }\n",
    "        \n",
    "        return self.embeddings\n",
    "    \n",
    "    def build_tfidf_index(self):\n",
    "        \"\"\"\n",
    "        Build TF-IDF vectors for questions and combined text\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary containing TF-IDF matrices\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Call preprocess_dataset first.\")\n",
    "        \n",
    "        # Fit TF-IDF on questions\n",
    "        question_tfidf = self.tfidf_vectorizer.fit_transform(self.processed_data['normalized_question'])\n",
    "        \n",
    "        # Create a new vectorizer for combined text\n",
    "        combined_vectorizer = TfidfVectorizer()\n",
    "        combined_tfidf = combined_vectorizer.fit_transform(self.processed_data['combined_text'])\n",
    "        \n",
    "        return {\n",
    "            'question_tfidf': question_tfidf,\n",
    "            'question_vectorizer': self.tfidf_vectorizer,\n",
    "            'combined_tfidf': combined_tfidf,\n",
    "            'combined_vectorizer': combined_vectorizer\n",
    "        }\n",
    "    \n",
    "    def build_bm25_index(self):\n",
    "        \"\"\"\n",
    "        Build BM25 index for efficient retrieval\n",
    "        \n",
    "        Returns:\n",
    "            BM25Okapi: BM25 index object\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Call preprocess_dataset first.\")\n",
    "        \n",
    "        # Prepare corpus for BM25\n",
    "        tokenized_corpus = self.processed_data['tokenized_question'].tolist()\n",
    "        \n",
    "        # Initialize BM25\n",
    "        self.bm25 = BM25Okapi(tokenized_corpus)\n",
    "        \n",
    "        return self.bm25\n",
    "    \n",
    "    def save_processed_data(self, output_path):\n",
    "        \"\"\"\n",
    "        Save processed data to disk\n",
    "        \n",
    "        Args:\n",
    "            output_path (str): Path to save the processed data\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Call preprocess_dataset first.\")\n",
    "        \n",
    "        # Convert embeddings to lists for JSON serialization\n",
    "        if self.embeddings is not None:\n",
    "            embeddings_dict = {\n",
    "                'question': self.embeddings['question'].tolist(),\n",
    "                'answer': self.embeddings['answer'].tolist()\n",
    "            }\n",
    "            \n",
    "            # Save embeddings separately as they can be large\n",
    "            np.save(f\"{output_path}_embeddings.npy\", self.embeddings)\n",
    "        \n",
    "        # Prepare data for saving\n",
    "        save_data = {\n",
    "            'processed_df': self.processed_data.to_dict(orient='records'),\n",
    "            'metadata': {\n",
    "                'num_samples': len(self.processed_data),\n",
    "                'sources': self.processed_data['source'].unique().tolist(),\n",
    "                'embedding_model': self.sentence_model.get_sentence_embedding_dimension()\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(save_data, f)\n",
    "            \n",
    "        print(f\"Processed data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import json\n",
    " \n",
    " \n",
    "class QuestionClassifier:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the Question Classification Component using Bayesian approach\n",
    "        \"\"\"\n",
    "        # Use 'english' as a string instead of the set for sklearn compatibility\n",
    "        self.stop_words = 'english'\n",
    "        self.question_types = [\n",
    "            'DEFINITION',\n",
    "            'FACTUAL',\n",
    "            'LEGAL_PROVISION',\n",
    "            'PROCEDURE',\n",
    "            'RIGHTS',\n",
    "            'EXCEPTION',\n",
    "            'COMPARISON',\n",
    "            'CONSEQUENCE',\n",
    "            'JURISDICTION',\n",
    "            'TIMEFRAME'\n",
    "        ]\n",
    "        self.classifier = None\n",
    "        self.vectorizer = None\n",
    "        self.keywords = self._init_keywords()\n",
    "        self.syntactic_patterns = self._init_syntactic_patterns()\n",
    "        \n",
    "    def _init_keywords(self):\n",
    "        \"\"\"\n",
    "        Initialize keyword lists for different question types\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary mapping question types to associated keywords\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'DEFINITION': [\n",
    "                'what is', 'define', 'meaning', 'description', 'explain',\n",
    "                'concept', 'refer to', 'constitute', 'definition', 'termed'\n",
    "            ],\n",
    "            'FACTUAL': [\n",
    "                'who', 'when', 'where', 'which', 'how many', 'list',\n",
    "                'name', 'identify', 'mention', 'specify'\n",
    "            ],\n",
    "            'LEGAL_PROVISION': [\n",
    "                'section', 'provision', 'article', 'clause', 'rule', \n",
    "                'act', 'statute', 'law', 'regulation', 'ordinance', 'code'\n",
    "            ],\n",
    "            'PROCEDURE': [\n",
    "                'how to', 'process', 'steps', 'procedure', 'method',\n",
    "                'way', 'approach', 'protocol', 'file', 'submit', 'apply'\n",
    "            ],\n",
    "            'RIGHTS': [\n",
    "                'right', 'entitle', 'claim', 'privilege', 'protection',\n",
    "                'freedom', 'liberty', 'enable', 'permit', 'allow'\n",
    "            ],\n",
    "            'EXCEPTION': [\n",
    "                'exception', 'exempt', 'waive', 'excuse', 'exclude',\n",
    "                'unless', 'except', 'other than', 'apart from', 'besides'\n",
    "            ],\n",
    "            'COMPARISON': [\n",
    "                'compare', 'contrast', 'difference', 'distinguish', 'versus',\n",
    "                'differentiate', 'similar', 'differ', 'relate', 'connection'\n",
    "            ],\n",
    "            'CONSEQUENCE': [\n",
    "                'penalty', 'punishment', 'sanction', 'outcome', 'result',\n",
    "                'effect', 'consequence', 'implication', 'lead to', 'happen if'\n",
    "            ],\n",
    "            'JURISDICTION': [\n",
    "                'jurisdiction', 'authority', 'power', 'control', 'competence',\n",
    "                'court', 'tribunal', 'forum', 'bench', 'judiciary'\n",
    "            ],\n",
    "            'TIMEFRAME': [\n",
    "                'deadline', 'time limit', 'period', 'duration', 'within',\n",
    "                'by when', 'limitation', 'expire', 'extend', 'timeline'\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    def _init_syntactic_patterns(self):\n",
    "        \"\"\"\n",
    "        Initialize syntactic patterns for question classification\n",
    "        \n",
    "        Returns:\n",
    "            dict: Dictionary of regex patterns for different question types\n",
    "        \"\"\"\n",
    "        return {\n",
    "            'DEFINITION': [\n",
    "                r'^what\\s+(is|are|does|do)\\s+(.+?)\\s+(mean|refer\\s+to)',\n",
    "                r'^(define|explain)\\s+(.+)',\n",
    "                r'^(meaning|definition)\\s+of\\s+(.+)',\n",
    "                r'what\\s+constitutes\\s+(.+)'\n",
    "            ],\n",
    "            'FACTUAL': [\n",
    "                r'^who\\s+(.+)',\n",
    "                r'^when\\s+(.+)',\n",
    "                r'^where\\s+(.+)',\n",
    "                r'^which\\s+(.+)',\n",
    "                r'^(how\\s+many|list|name|mention|specify)\\s+(.+)'\n",
    "            ],\n",
    "            'LEGAL_PROVISION': [\n",
    "                r'(section|article|clause|rule)\\s+\\d+',\n",
    "                r'under\\s+(what|which)\\s+(section|provision|article|clause|rule)',\n",
    "                r'(which|what)\\s+(act|statute|law|regulation)'\n",
    "            ],\n",
    "            'PROCEDURE': [\n",
    "                r'^how\\s+to\\s+(.+)',\n",
    "                r'^what\\s+(is|are)\\s+the\\s+(steps|procedure|process)',\n",
    "                r'^(describe|explain)\\s+the\\s+(procedure|process|method)',\n",
    "                r'how\\s+(can|should|do|does|is)\\s+(.+?)\\s+(done|filed|submitted|processed)'\n",
    "            ],\n",
    "            'RIGHTS': [\n",
    "                r'(what|which)\\s+(rights|entitlements)',\n",
    "                r'(am|is|are)\\s+(.+?)\\s+(entitled|allowed|permitted)',\n",
    "                r'(can|may)\\s+(.+?)\\s+(claim|exercise|demand)'\n",
    "            ],\n",
    "            'EXCEPTION': [\n",
    "                r'(what|which|any)\\s+(exceptions|exemptions)',\n",
    "                r'(except|exempted|excluded|waived)',\n",
    "                r'(unless|except\\s+for|other\\s+than|apart\\s+from)'\n",
    "            ],\n",
    "            'COMPARISON': [\n",
    "                r'(difference|distinguish|compare)\\s+between\\s+(.+?)\\s+and\\s+(.+)',\n",
    "                r'how\\s+(.+?)\\s+(differs|compares)\\s+to\\s+(.+)',\n",
    "                r'(what|which)\\s+is\\s+the\\s+(relationship|connection)'\n",
    "            ],\n",
    "            'CONSEQUENCE': [\n",
    "                r'(what|which)\\s+(is|are)\\s+the\\s+(penalty|punishment|sanction|consequence)',\n",
    "                r'what\\s+happens\\s+if\\s+(.+)',\n",
    "                r'(outcome|result|effect|implication)\\s+of\\s+(.+)'\n",
    "            ],\n",
    "            'JURISDICTION': [\n",
    "                r'(who|which|what)\\s+(has|have|holds)\\s+(jurisdiction|authority|power)',\n",
    "                r'(which|what)\\s+(court|tribunal|forum)',\n",
    "                r'(under|within)\\s+(.+?)\\s+jurisdiction'\n",
    "            ],\n",
    "            'TIMEFRAME': [\n",
    "                r'(what|which|how\\s+long)\\s+(is|are)\\s+the\\s+(timeframe|period|duration)',\n",
    "                r'(deadline|time\\s+limit|limitation\\s+period)',\n",
    "                r'within\\s+what\\s+(time|period)',\n",
    "                r'(when|by\\s+when)\\s+(.+?)\\s+(must|should|can|need)'\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "    def preprocess_question(self, question):\n",
    "        \"\"\"\n",
    "        Preprocess the input question\n",
    "        \n",
    "        Args:\n",
    "            question (str): Raw question text\n",
    "            \n",
    "        Returns:\n",
    "            str: Preprocessed question\n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        question = question.lower()\n",
    "        \n",
    "        # Remove punctuation except question marks\n",
    "        question = re.sub(r'[^\\w\\s?]', ' ', question)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        question = re.sub(r'\\s+', ' ', question).strip()\n",
    "        \n",
    "        return question\n",
    "    \n",
    "    def rule_based_classification(self, question):\n",
    "        \"\"\"\n",
    "        Perform rule-based classification using keywords and syntactic patterns\n",
    "        \n",
    "        Args:\n",
    "            question (str): Preprocessed question\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary of probabilities for each question type\n",
    "        \"\"\"\n",
    "        # Initialize probabilities\n",
    "        probabilities = {qtype: 0.0 for qtype in self.question_types}\n",
    "        \n",
    "        # Check for keywords\n",
    "        for qtype, keywords in self.keywords.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in question:\n",
    "                    probabilities[qtype] += 0.2  # Increment score for each keyword match\n",
    "        \n",
    "        # Check for syntactic patterns\n",
    "        for qtype, patterns in self.syntactic_patterns.items():\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern, question, re.IGNORECASE):\n",
    "                    probabilities[qtype] += 0.5  # Higher weight for syntactic pattern matches\n",
    "        \n",
    "        # Normalize probabilities\n",
    "        total = sum(probabilities.values())\n",
    "        if total > 0:\n",
    "            for qtype in probabilities:\n",
    "                probabilities[qtype] /= total\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def prepare_training_data(self, processed_data_path, label_column=None):\n",
    "        \"\"\"\n",
    "        Prepare training data from preprocessed QA pairs\n",
    "        \n",
    "        Args:\n",
    "            processed_data_path (str): Path to preprocessed data\n",
    "            label_column (str, optional): Column name with existing labels\n",
    "            \n",
    "        Returns:\n",
    "            tuple: X (questions) and y (labels) for training\n",
    "        \"\"\"\n",
    "        # Load processed data\n",
    "        try:\n",
    "            with open(processed_data_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            if 'processed_df' in data:\n",
    "                processed_df = pd.DataFrame(data['processed_df'])\n",
    "            else:\n",
    "                raise ValueError(\"Processed data not found in expected format\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading processed data: {str(e)}\")\n",
    "        \n",
    "        # If labels already exist, use them\n",
    "        if label_column and label_column in processed_df.columns:\n",
    "            X = processed_df['normalized_question'].tolist()\n",
    "            y = processed_df[label_column].tolist()\n",
    "            return X, y\n",
    "        \n",
    "        # Generate synthetic labels for training using rule-based approach\n",
    "        print(\"No existing labels found. Generating synthetic labels for training...\")\n",
    "        labels = []\n",
    "        \n",
    "        for question in processed_df['normalized_question']:\n",
    "            probs = self.rule_based_classification(question)\n",
    "            # Assign the question type with highest probability\n",
    "            label = max(probs.items(), key=lambda x: x[1])[0]\n",
    "            labels.append(label)\n",
    "        \n",
    "        X = processed_df['normalized_question'].tolist()\n",
    "        y = labels\n",
    "        \n",
    "        # Save the labeled data for future use\n",
    "        processed_df['question_type'] = labels\n",
    "        data['processed_df'] = processed_df.to_dict(orient='records')\n",
    "        \n",
    "        with open(processed_data_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f)\n",
    "            \n",
    "        print(f\"Generated {len(labels)} labels for training. Distribution:\")\n",
    "        print(pd.Series(labels).value_counts())\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train_classifier(self, X, y, test_size=0.2, random_state=42):\n",
    "        \"\"\"\n",
    "        Train the Naive Bayes classifier\n",
    "        \n",
    "        Args:\n",
    "            X (list): List of preprocessed questions\n",
    "            y (list): List of question type labels\n",
    "            test_size (float): Proportion of data to use for testing\n",
    "            random_state (int): Random seed for reproducibility\n",
    "            \n",
    "        Returns:\n",
    "            Pipeline: Trained classifier pipeline\n",
    "        \"\"\"\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "        \n",
    "        # Create pipeline with vectorizer and classifier\n",
    "        # Note: 'stop_words' is now a string instead of a set\n",
    "        self.classifier = Pipeline([\n",
    "            ('vectorizer', CountVectorizer(stop_words=self.stop_words)),\n",
    "            ('classifier', MultinomialNB())\n",
    "        ])\n",
    "        \n",
    "        # Train the model\n",
    "        self.classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = self.classifier.predict(X_test)\n",
    "        print(\"Classification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        # Store vectorizer for later use\n",
    "        self.vectorizer = self.classifier.named_steps['vectorizer']\n",
    "        \n",
    "        return self.classifier\n",
    "    \n",
    "    def classify_question(self, question):\n",
    "        \"\"\"\n",
    "        Classify a question using both rule-based and ML approaches\n",
    "        \n",
    "        Args:\n",
    "            question (str): User's question\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (question_type, confidence, probabilities)\n",
    "        \"\"\"\n",
    "        # Preprocess the question\n",
    "        preprocessed_question = self.preprocess_question(question)\n",
    "        \n",
    "        # Get rule-based probabilities\n",
    "        rule_based_probs = self.rule_based_classification(preprocessed_question)\n",
    "        \n",
    "        # If classifier is available, use it\n",
    "        if self.classifier is not None:\n",
    "            # Get ML-based probabilities\n",
    "            ml_probs = dict(zip(\n",
    "                self.classifier.classes_,\n",
    "                self.classifier.predict_proba([preprocessed_question])[0]\n",
    "            ))\n",
    "            \n",
    "            # Combine probabilities (giving more weight to ML model)\n",
    "            combined_probs = {}\n",
    "            for qtype in self.question_types:\n",
    "                ml_prob = ml_probs.get(qtype, 0.0)\n",
    "                rule_prob = rule_based_probs.get(qtype, 0.0)\n",
    "                combined_probs[qtype] = 0.7 * ml_prob + 0.3 * rule_prob\n",
    "        else:\n",
    "            # Use only rule-based if no classifier is available\n",
    "            combined_probs = rule_based_probs\n",
    "        \n",
    "        # Get the most likely question type\n",
    "        question_type = max(combined_probs.items(), key=lambda x: x[1])[0]\n",
    "        confidence = combined_probs[question_type]\n",
    "        \n",
    "        return {\n",
    "            'question_type': question_type,\n",
    "            'confidence': confidence,\n",
    "            'probabilities': combined_probs\n",
    "        }\n",
    "    \n",
    "    def save_classifier(self, output_path):\n",
    "        \"\"\"\n",
    "        Save the trained classifier to disk\n",
    "        \n",
    "        Args:\n",
    "            output_path (str): Path to save the classifier\n",
    "        \"\"\"\n",
    "        if self.classifier is None:\n",
    "            raise ValueError(\"No trained classifier available. Train the model first.\")\n",
    "        \n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'classifier': self.classifier,\n",
    "                'question_types': self.question_types,\n",
    "                'keywords': self.keywords,\n",
    "                'syntactic_patterns': self.syntactic_patterns\n",
    "            }, f)\n",
    "            \n",
    "        print(f\"Classifier saved to {output_path}\")\n",
    "    \n",
    "    def load_classifier(self, input_path):\n",
    "        \"\"\"\n",
    "        Load a trained classifier from disk\n",
    "        \n",
    "        Args:\n",
    "            input_path (str): Path to load the classifier from\n",
    "            \n",
    "        Returns:\n",
    "            QuestionClassifier: Self with loaded classifier\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(input_path, 'rb') as f:\n",
    "                data = pickle.load(f)\n",
    "                \n",
    "            self.classifier = data['classifier']\n",
    "            self.question_types = data['question_types']\n",
    "            self.keywords = data['keywords']\n",
    "            self.syntactic_patterns = data['syntactic_patterns']\n",
    "            \n",
    "            # Extract vectorizer from pipeline\n",
    "            if hasattr(self.classifier, 'named_steps') and 'vectorizer' in self.classifier.named_steps:\n",
    "                self.vectorizer = self.classifier.named_steps['vectorizer']\n",
    "                \n",
    "            print(f\"Classifier loaded from {input_path}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading classifier: {str(e)}\")\n",
    "            \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import time\n",
    " \n",
    "class QuestionRetrievalSystem:\n",
    "    def __init__(self, use_sentence_transformer=True, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the Question Retrieval Component that uses Tanimoto Similarity\n",
    "        \n",
    "        Args:\n",
    "            use_sentence_transformer (bool): Whether to use SentenceTransformer for embedding\n",
    "            model_name (str): Name of the SentenceTransformer model to use\n",
    "        \"\"\"\n",
    "        self.processed_data = None\n",
    "        self.question_history = {}\n",
    "        self.embeddings = None\n",
    "        self.use_sentence_transformer = use_sentence_transformer\n",
    "        \n",
    "        if use_sentence_transformer:\n",
    "            self.sentence_model = SentenceTransformer(model_name)\n",
    "    \n",
    "    def load_processed_data(self, processed_data_path, embeddings_path=None):\n",
    "        \"\"\"\n",
    "        Load the preprocessed QA dataset and embeddings\n",
    "        \n",
    "        Args:\n",
    "            processed_data_path (str): Path to the processed data JSON\n",
    "            embeddings_path (str, optional): Path to the embeddings NPY file\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Loaded data\n",
    "        \"\"\"\n",
    "        # Load processed data\n",
    "        try:\n",
    "            with open(processed_data_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            if 'processed_df' in data:\n",
    "                self.processed_data = pd.DataFrame(data['processed_df'])\n",
    "                print(f\"Loaded {len(self.processed_data)} QA pairs from {processed_data_path}\")\n",
    "            else:\n",
    "                raise ValueError(\"Processed data not found in expected format\")\n",
    "                \n",
    "            # Load embeddings if provided\n",
    "            if embeddings_path:\n",
    "                try:\n",
    "                    self.embeddings = np.load(embeddings_path, allow_pickle=True).item()\n",
    "                    print(f\"Loaded embeddings from {embeddings_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading embeddings: {str(e)}\")\n",
    "                    print(\"Will generate embeddings on-the-fly if needed.\")\n",
    "            \n",
    "            return self.processed_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading processed data: {str(e)}\")\n",
    "    \n",
    "    def calculate_tanimoto_similarity(self, set_a, set_b):\n",
    "        \"\"\"\n",
    "        Calculate Tanimoto coefficient (Jaccard similarity) between two sets\n",
    "        \n",
    "        Args:\n",
    "            set_a (set): First set of tokens\n",
    "            set_b (set): Second set of tokens\n",
    "            \n",
    "        Returns:\n",
    "            float: Tanimoto similarity score [0-1]\n",
    "        \"\"\"\n",
    "        # Handle empty sets\n",
    "        if not set_a or not set_b:\n",
    "            return 0.0\n",
    "            \n",
    "        # Calculate intersection and union\n",
    "        intersection = len(set_a.intersection(set_b))\n",
    "        union = len(set_a) + len(set_b) - intersection\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if union == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return intersection / union\n",
    "    \n",
    "    def calculate_tanimoto_weighted_similarity(self, question, question_type, top_k=5):\n",
    "        \"\"\"\n",
    "        Calculate weighted Tanimoto similarity for a question based on question type\n",
    "        \n",
    "        Args:\n",
    "            question (str): User's question\n",
    "            question_type (str): Classified question type\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            list: Top-k similar questions with similarity scores\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Load data first.\")\n",
    "            \n",
    "        # Tokenize and create set from user question\n",
    "        # Simple space-based tokenization for demonstration\n",
    "        user_question_set = set(question.lower().split())\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        # Calculate similarity with each question in the dataset\n",
    "        for idx, row in self.processed_data.iterrows():\n",
    "            # Get tokens from processed data, converting list back to set if needed\n",
    "            if 'tokenized_question' in row:\n",
    "                if isinstance(row['tokenized_question'], list):\n",
    "                    db_question_set = set(row['tokenized_question'])\n",
    "                else:\n",
    "                    # If tokenized_question is not available or not a list, fallback\n",
    "                    db_question_set = set(str(row['normalized_question']).lower().split())\n",
    "            else:\n",
    "                db_question_set = set(str(row['normalized_question']).lower().split())\n",
    "            \n",
    "            # Calculate base Tanimoto similarity\n",
    "            tanimoto_score = self.calculate_tanimoto_similarity(user_question_set, db_question_set)\n",
    "            \n",
    "            # Apply weighting based on question type match\n",
    "            weight = 1.0\n",
    "            if 'question_type' in row and row['question_type'] == question_type:\n",
    "                weight = 1.2  # Boost score for matching question types\n",
    "                \n",
    "            # Final weighted score\n",
    "            weighted_score = tanimoto_score * weight\n",
    "            \n",
    "            similarities.append({\n",
    "                'idx': idx,\n",
    "                'question': row['question'],\n",
    "                'answer': row['answer'],\n",
    "                'similarity': weighted_score\n",
    "            })\n",
    "        \n",
    "        # Sort by similarity and get top-k\n",
    "        similarities.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "    \n",
    "    def embedding_similarity(self, question, top_k=5):\n",
    "        \"\"\"\n",
    "        Calculate similarity using embedding vectors\n",
    "        \n",
    "        Args:\n",
    "            question (str): User's question\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            list: Top-k similar questions with similarity scores\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Load data first.\")\n",
    "            \n",
    "        # Generate embedding for the user question\n",
    "        user_question_embedding = self.sentence_model.encode([question])[0]\n",
    "        \n",
    "        similarities = []\n",
    "        \n",
    "        # If we have precomputed embeddings, use them\n",
    "        if self.embeddings is not None and 'question' in self.embeddings:\n",
    "            # Calculate cosine similarity with all question embeddings\n",
    "            question_embeddings = self.embeddings['question']\n",
    "            cosine_similarities = cosine_similarity([user_question_embedding], question_embeddings)[0]\n",
    "            \n",
    "            # Create results with similarity scores\n",
    "            for idx, score in enumerate(cosine_similarities):\n",
    "                similarities.append({\n",
    "                    'idx': idx,\n",
    "                    'question': self.processed_data.iloc[idx]['question'],\n",
    "                    'answer': self.processed_data.iloc[idx]['answer'],\n",
    "                    'similarity': float(score)\n",
    "                })\n",
    "        else:\n",
    "            # No precomputed embeddings, calculate one by one\n",
    "            for idx, row in self.processed_data.iterrows():\n",
    "                # Generate embedding for database question\n",
    "                db_question = str(row['normalized_question'])\n",
    "                db_question_embedding = self.sentence_model.encode([db_question])[0]\n",
    "                \n",
    "                # Calculate cosine similarity\n",
    "                similarity = cosine_similarity([user_question_embedding], [db_question_embedding])[0][0]\n",
    "                \n",
    "                similarities.append({\n",
    "                    'idx': idx,\n",
    "                    'question': row['question'],\n",
    "                    'answer': row['answer'],\n",
    "                    'similarity': float(similarity)\n",
    "                })\n",
    "        \n",
    "        # Sort by similarity and get top-k\n",
    "        similarities.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        return similarities[:top_k]\n",
    "    \n",
    "    def get_answer_from_history(self, question, threshold=0.85):\n",
    "        \"\"\"\n",
    "        Check if a similar question exists in history and return previous answer\n",
    "        \n",
    "        Args:\n",
    "            question (str): User's question\n",
    "            threshold (float): Similarity threshold to consider questions as same\n",
    "            \n",
    "        Returns:\n",
    "            dict: Previous answer info if similarity > threshold, else None\n",
    "        \"\"\"\n",
    "        # Simple implementation - in a production system, \n",
    "        # you might want to use a database for question history\n",
    "        \n",
    "        # No history yet\n",
    "        if not self.question_history:\n",
    "            return None\n",
    "            \n",
    "        # Normalize question\n",
    "        question = question.lower().strip()\n",
    "        \n",
    "        # Tokenize question\n",
    "        question_tokens = set(question.split())\n",
    "        \n",
    "        # Check each question in history\n",
    "        for q, answer_info in self.question_history.items():\n",
    "            q_tokens = set(q.lower().split())\n",
    "            similarity = self.calculate_tanimoto_similarity(question_tokens, q_tokens)\n",
    "            \n",
    "            if similarity >= threshold:\n",
    "                # Return cached answer along with similarity\n",
    "                return {\n",
    "                    'question': q,\n",
    "                    'answer': answer_info['answer'],\n",
    "                    'similarity': similarity,\n",
    "                    'timestamp': answer_info['timestamp']\n",
    "                }\n",
    "                \n",
    "        return None\n",
    "    \n",
    "    def add_to_history(self, question, answer):\n",
    "        \"\"\"\n",
    "        Add a question-answer pair to history\n",
    "        \n",
    "        Args:\n",
    "            question (str): User's question\n",
    "            answer (str): Provided answer\n",
    "        \"\"\"\n",
    "        # Normalize question\n",
    "        question = question.lower().strip()\n",
    "        \n",
    "        # Add to history with timestamp\n",
    "        self.question_history[question] = {\n",
    "            'answer': answer,\n",
    "            'timestamp': time.time()\n",
    "        }\n",
    "        \n",
    "        # Keep history size manageable (e.g., keep last 1000 questions)\n",
    "        if len(self.question_history) > 1000:\n",
    "            # Remove oldest entry\n",
    "            oldest_question = min(self.question_history.items(), \n",
    "                                key=lambda x: x[1]['timestamp'])[0]\n",
    "            del self.question_history[oldest_question]\n",
    "    \n",
    "    def save_history(self, output_path):\n",
    "        \"\"\"\n",
    "        Save question history to disk\n",
    "        \n",
    "        Args:\n",
    "            output_path (str): Path to save history\n",
    "        \"\"\"\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump(self.question_history, f)\n",
    "            \n",
    "        print(f\"Question history saved to {output_path}\")\n",
    "    \n",
    "    def load_history(self, input_path):\n",
    "        \"\"\"\n",
    "        Load question history from disk\n",
    "        \n",
    "        Args:\n",
    "            input_path (str): Path to load history from\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(input_path, 'rb') as f:\n",
    "                self.question_history = pickle.load(f)\n",
    "                \n",
    "            print(f\"Loaded {len(self.question_history)} historical Q&A pairs from {input_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading history: {str(e)}\")\n",
    "            self.question_history = {}\n",
    "    \n",
    "    def retrieve_answer(self, question, question_type, similarity_threshold=0.85, min_acceptable_similarity=0.6):\n",
    "        \"\"\"\n",
    "        Retrieve answer for a question using Tanimoto similarity\n",
    "        \n",
    "        Args:\n",
    "            question (str): User's question\n",
    "            question_type (str): Classified question type\n",
    "            similarity_threshold (float): Threshold to return existing answer\n",
    "            min_acceptable_similarity (float): Minimum similarity to consider valid\n",
    "            \n",
    "        Returns:\n",
    "            dict: Result containing best answer match or None\n",
    "        \"\"\"\n",
    "        # Check question history first\n",
    "        history_result = self.get_answer_from_history(question, threshold=similarity_threshold)\n",
    "        \n",
    "        if history_result:\n",
    "            print(f\"Found answer in history with similarity {history_result['similarity']:.2f}\")\n",
    "            return {\n",
    "                'source': 'history',\n",
    "                'question': history_result['question'],\n",
    "                'answer': history_result['answer'],\n",
    "                'similarity': history_result['similarity']\n",
    "            }\n",
    "        \n",
    "        # No match in history, search in dataset\n",
    "        print(\"No match in history, searching dataset...\")\n",
    "        \n",
    "        # Determine which similarity method to use\n",
    "        if self.use_sentence_transformer:\n",
    "            top_results = self.embedding_similarity(question, top_k=5)\n",
    "        else:\n",
    "            top_results = self.calculate_tanimoto_weighted_similarity(question, question_type, top_k=5)\n",
    "        \n",
    "        # If we have results with good similarity\n",
    "        if top_results and top_results[0]['similarity'] >= min_acceptable_similarity:\n",
    "            best_match = top_results[0]\n",
    "            \n",
    "            # If similarity is very high, add to history\n",
    "            if best_match['similarity'] >= similarity_threshold:\n",
    "                self.add_to_history(question, best_match['answer'])\n",
    "                \n",
    "            return {\n",
    "                'source': 'database',\n",
    "                'question': best_match['question'],\n",
    "                'answer': best_match['answer'],\n",
    "                'similarity': best_match['similarity'],\n",
    "                'alternatives': top_results[1:3]  # Return a couple of alternatives\n",
    "            }\n",
    "        \n",
    "        # No good match found\n",
    "        return {\n",
    "            'source': None,\n",
    "            'message': 'No similar question found in database',\n",
    "            'top_results': top_results\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    " \n",
    "class ContextRetriever:\n",
    "    def __init__(self, use_gpu=False, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the Context Retrieval Component with BM25 and Neural Retrieval\n",
    "        \n",
    "        Args:\n",
    "            use_gpu (bool): Whether to use GPU for neural models if available\n",
    "            model_name (str): Name of the SentenceTransformer model to use\n",
    "        \"\"\"\n",
    "        self.processed_data = None\n",
    "        self.bm25_index = None\n",
    "        self.corpus = None\n",
    "        self.passage_embeddings = None\n",
    "        self.use_gpu = use_gpu and torch.cuda.is_available()\n",
    "        \n",
    "        # Initialize the sentence transformer model\n",
    "        self.device = 'cuda' if self.use_gpu else 'cpu'\n",
    "        self.model = SentenceTransformer(model_name, device=self.device)\n",
    "        \n",
    "        # Initialize NLTK resources\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        self.stemmer = PorterStemmer()\n",
    "        \n",
    "        # Initialize the TF-IDF vectorizer\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            stop_words='english',\n",
    "            max_df=0.85,\n",
    "            min_df=2\n",
    "        )\n",
    "        \n",
    "        print(f\"Initialized Context Retriever with model {model_name} on {self.device}\")\n",
    "    \n",
    "    def load_processed_data(self, processed_data_path, embeddings_path=None):\n",
    "        \"\"\"\n",
    "        Load the preprocessed QA dataset and pre-computed embeddings if available\n",
    "        \n",
    "        Args:\n",
    "            processed_data_path (str): Path to the processed data JSON\n",
    "            embeddings_path (str, optional): Path to the embeddings NPY file\n",
    "            \n",
    "        Returns:\n",
    "            pandas.DataFrame: Loaded data\n",
    "        \"\"\"\n",
    "        # Load processed data\n",
    "        try:\n",
    "            with open(processed_data_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                \n",
    "            if 'processed_df' in data:\n",
    "                self.processed_data = pd.DataFrame(data['processed_df'])\n",
    "                print(f\"Loaded {len(self.processed_data)} QA pairs from {processed_data_path}\")\n",
    "                \n",
    "                # Extract context passages for retrieval\n",
    "                self.prepare_context_passages()\n",
    "            else:\n",
    "                raise ValueError(\"Processed data not found in expected format\")\n",
    "            \n",
    "            # Load embeddings if provided\n",
    "            if embeddings_path:\n",
    "                try:\n",
    "                    embeddings_data = np.load(embeddings_path, allow_pickle=True).item()\n",
    "                    if 'answer' in embeddings_data:\n",
    "                        self.passage_embeddings = embeddings_data['answer']\n",
    "                        print(f\"Loaded {len(self.passage_embeddings)} passage embeddings\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading embeddings: {str(e)}\")\n",
    "                    print(\"Will compute passage embeddings when needed\")\n",
    "            \n",
    "            return self.processed_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Error loading processed data: {str(e)}\")\n",
    "    \n",
    "    def prepare_context_passages(self):\n",
    "        \"\"\"\n",
    "        Extract and prepare context passages from processed data\n",
    "        \n",
    "        Returns:\n",
    "            list: Preprocessed context passages\n",
    "        \"\"\"\n",
    "        if self.processed_data is None:\n",
    "            raise ValueError(\"No processed data available. Load data first.\")\n",
    "        \n",
    "        # Create a corpus of documents for retrieval\n",
    "        # Combining question and answer content for better context\n",
    "        contexts = []\n",
    "        \n",
    "        for _, row in self.processed_data.iterrows():\n",
    "            # Create context from question and answer\n",
    "            if 'normalized_question' in row and 'normalized_answer' in row:\n",
    "                context = f\"{row['normalized_question']} {row['normalized_answer']}\"\n",
    "            else:\n",
    "                # Fallback to original text if normalized versions aren't available\n",
    "                context = f\"{row['question']} {row['answer']}\"\n",
    "            \n",
    "            contexts.append(context)\n",
    "        \n",
    "        self.corpus = contexts\n",
    "        print(f\"Prepared {len(contexts)} context passages for retrieval\")\n",
    "        \n",
    "        return contexts\n",
    "    \n",
    "    def build_bm25_index(self):\n",
    "        \"\"\"\n",
    "        Build BM25 index for fast lexical retrieval\n",
    "        \n",
    "        Returns:\n",
    "            BM25Okapi: BM25 index for the corpus\n",
    "        \"\"\"\n",
    "        if self.corpus is None:\n",
    "            if self.processed_data is not None:\n",
    "                self.prepare_context_passages()\n",
    "            else:\n",
    "                raise ValueError(\"No processed data available. Load data first.\")\n",
    "        \n",
    "        # Tokenize the corpus for BM25\n",
    "        tokenized_corpus = []\n",
    "        for doc in self.corpus:\n",
    "            # Tokenize, remove stopwords and stem\n",
    "            tokens = word_tokenize(doc.lower())\n",
    "            tokens = [self.stemmer.stem(token) for token in tokens if token.isalnum() and token not in self.stop_words]\n",
    "            tokenized_corpus.append(tokens)\n",
    "        \n",
    "        # Create BM25 index\n",
    "        self.bm25_index = BM25Okapi(tokenized_corpus)\n",
    "        print(\"BM25 index built successfully\")\n",
    "        \n",
    "        return self.bm25_index\n",
    "    \n",
    "    def compute_passage_embeddings(self):\n",
    "        \"\"\"\n",
    "        Compute dense embeddings for all passages in the corpus\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Matrix of passage embeddings\n",
    "        \"\"\"\n",
    "        if self.corpus is None:\n",
    "            if self.processed_data is not None:\n",
    "                self.prepare_context_passages()\n",
    "            else:\n",
    "                raise ValueError(\"No processed data available. Load data first.\")\n",
    "        \n",
    "        print(\"Computing passage embeddings...\")\n",
    "        self.passage_embeddings = self.model.encode(\n",
    "            self.corpus,\n",
    "            show_progress_bar=True,\n",
    "            convert_to_tensor=True,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        print(f\"Computed embeddings for {len(self.corpus)} passages\")\n",
    "        return self.passage_embeddings\n",
    "    \n",
    "    def save_indices(self, output_path):\n",
    "        \"\"\"\n",
    "        Save BM25 index and passage embeddings\n",
    "        \n",
    "        Args:\n",
    "            output_path (str): Base path for saving indices\n",
    "        \"\"\"\n",
    "        # Save BM25 index\n",
    "        with open(f\"{output_path}_bm25.pkl\", 'wb') as f:\n",
    "            pickle.dump(self.bm25_index, f)\n",
    "        \n",
    "        # Save passage embeddings\n",
    "        if isinstance(self.passage_embeddings, torch.Tensor):\n",
    "            # Convert to numpy for saving\n",
    "            embeddings_np = self.passage_embeddings.cpu().numpy()\n",
    "        else:\n",
    "            embeddings_np = self.passage_embeddings\n",
    "            \n",
    "        np.save(f\"{output_path}_embeddings.npy\", embeddings_np)\n",
    "        \n",
    "        print(f\"Indices saved to {output_path}_bm25.pkl and {output_path}_embeddings.npy\")\n",
    "    \n",
    "    def load_indices(self, bm25_path, embeddings_path):\n",
    "        \"\"\"\n",
    "        Load BM25 index and passage embeddings\n",
    "        \n",
    "        Args:\n",
    "            bm25_path (str): Path to BM25 index\n",
    "            embeddings_path (str): Path to passage embeddings\n",
    "        \"\"\"\n",
    "        # Load BM25 index\n",
    "        try:\n",
    "            with open(bm25_path, 'rb') as f:\n",
    "                self.bm25_index = pickle.load(f)\n",
    "            print(f\"Loaded BM25 index from {bm25_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading BM25 index: {str(e)}\")\n",
    "        \n",
    "        # Load passage embeddings\n",
    "        try:\n",
    "            embeddings = np.load(embeddings_path)\n",
    "            if self.use_gpu:\n",
    "                self.passage_embeddings = torch.tensor(embeddings).to(self.device)\n",
    "            else:\n",
    "                self.passage_embeddings = torch.tensor(embeddings)\n",
    "            print(f\"Loaded passage embeddings from {embeddings_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading passage embeddings: {str(e)}\")\n",
    "    \n",
    "    def preprocess_query(self, query):\n",
    "        \"\"\"\n",
    "        Preprocess a query for retrieval\n",
    "        \n",
    "        Args:\n",
    "            query (str): Raw query string\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (normalized query, tokenized query)\n",
    "        \"\"\"\n",
    "        # Normalize\n",
    "        normalized_query = query.lower()\n",
    "        normalized_query = re.sub(r'[^\\w\\s]', ' ', normalized_query)\n",
    "        normalized_query = re.sub(r'\\s+', ' ', normalized_query).strip()\n",
    "        \n",
    "        # Tokenize\n",
    "        tokens = word_tokenize(normalized_query)\n",
    "        \n",
    "        # Remove stopwords and stem\n",
    "        stemmed_tokens = [self.stemmer.stem(token) for token in tokens \n",
    "                          if token.isalnum() and token not in self.stop_words]\n",
    "        \n",
    "        return normalized_query, stemmed_tokens\n",
    "    \n",
    "    def retrieve_with_bm25(self, query, top_k=10):\n",
    "        \"\"\"\n",
    "        Retrieve passages using BM25 algorithm\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            list: Top-k passages with scores\n",
    "        \"\"\"\n",
    "        if self.bm25_index is None:\n",
    "            self.build_bm25_index()\n",
    "        \n",
    "        # Preprocess query\n",
    "        _, tokenized_query = self.preprocess_query(query)\n",
    "        \n",
    "        # Get BM25 scores\n",
    "        bm25_scores = self.bm25_index.get_scores(tokenized_query)\n",
    "        \n",
    "        # Get top-k indices and scores\n",
    "        top_indices = np.argsort(bm25_scores)[::-1][:top_k]\n",
    "        \n",
    "        results = []\n",
    "        for idx in top_indices:\n",
    "            # Skip entries with zero score\n",
    "            if bm25_scores[idx] > 0:\n",
    "                results.append({\n",
    "                    'idx': int(idx),\n",
    "                    'score': float(bm25_scores[idx]),\n",
    "                    'passage': self.corpus[idx],\n",
    "                    'question': self.processed_data.iloc[idx]['question'],\n",
    "                    'answer': self.processed_data.iloc[idx]['answer']\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def retrieve_with_dpr(self, query, top_k=10):\n",
    "        \"\"\"\n",
    "        Retrieve passages using Dense Passage Retrieval\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            list: Top-k passages with scores\n",
    "        \"\"\"\n",
    "        if self.passage_embeddings is None:\n",
    "            self.compute_passage_embeddings()\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.model.encode(\n",
    "            query,\n",
    "            convert_to_tensor=True,\n",
    "            device=self.device\n",
    "        )\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        if isinstance(self.passage_embeddings, torch.Tensor):\n",
    "            # Using torch for faster computation if available\n",
    "            scores = util.cos_sim(query_embedding, self.passage_embeddings)[0]\n",
    "            top_indices = torch.topk(scores, min(top_k, len(scores)), sorted=True).indices.cpu().numpy()\n",
    "            top_scores = torch.topk(scores, min(top_k, len(scores)), sorted=True).values.cpu().numpy()\n",
    "        else:\n",
    "            # Fallback to numpy\n",
    "            scores = cosine_similarity([query_embedding.cpu().numpy()], self.passage_embeddings)[0]\n",
    "            top_indices = np.argsort(scores)[::-1][:top_k]\n",
    "            top_scores = scores[top_indices]\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(top_indices):\n",
    "            results.append({\n",
    "                'idx': int(idx),\n",
    "                'score': float(top_scores[i]),\n",
    "                'passage': self.corpus[idx],\n",
    "                'question': self.processed_data.iloc[idx]['question'],\n",
    "                'answer': self.processed_data.iloc[idx]['answer']\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def hybrid_retrieval(self, query, question_type=None, top_k=10, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Perform hybrid retrieval combining BM25 and DPR scores\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            question_type (str, optional): Type of question for potential weighting\n",
    "            top_k (int): Number of top results to return\n",
    "            alpha (float): Weight of BM25 scores (1-alpha for DPR scores)\n",
    "            \n",
    "        Returns:\n",
    "            list: Top-k passages with combined scores\n",
    "        \"\"\"\n",
    "        # Get results from BM25\n",
    "        bm25_results = self.retrieve_with_bm25(query, top_k=top_k*2)  # Retrieve more for better combination\n",
    "        \n",
    "        # Get results from DPR\n",
    "        dpr_results = self.retrieve_with_dpr(query, top_k=top_k*2)\n",
    "        \n",
    "        # Create score maps for both methods\n",
    "        bm25_scores = {result['idx']: result['score'] for result in bm25_results}\n",
    "        dpr_scores = {result['idx']: result['score'] for result in dpr_results}\n",
    "        \n",
    "        # Normalize scores\n",
    "        if bm25_scores:\n",
    "            max_bm25 = max(bm25_scores.values())\n",
    "            bm25_scores = {k: v / max_bm25 for k, v in bm25_scores.items()}\n",
    "        \n",
    "        if dpr_scores:\n",
    "            max_dpr = max(dpr_scores.values())\n",
    "            dpr_scores = {k: v / max_dpr for k, v in dpr_scores.items()}\n",
    "        \n",
    "        # Combine unique indices from both methods\n",
    "        all_indices = set(bm25_scores.keys()) | set(dpr_scores.keys())\n",
    "        \n",
    "        # Calculate combined scores\n",
    "        combined_scores = {}\n",
    "        for idx in all_indices:\n",
    "            bm25_score = bm25_scores.get(idx, 0.0)\n",
    "            dpr_score = dpr_scores.get(idx, 0.0)\n",
    "            \n",
    "            # Apply question type specific weighting\n",
    "            if question_type:\n",
    "                # Example: For DEFINITION questions, give more weight to DPR\n",
    "                if question_type == \"DEFINITION\":\n",
    "                    combined_scores[idx] = 0.3 * bm25_score + 0.7 * dpr_score\n",
    "                # For LEGAL_PROVISION questions, give more weight to BM25\n",
    "                elif question_type == \"LEGAL_PROVISION\":\n",
    "                    combined_scores[idx] = 0.7 * bm25_score + 0.3 * dpr_score\n",
    "                else:\n",
    "                    combined_scores[idx] = alpha * bm25_score + (1 - alpha) * dpr_score\n",
    "            else:\n",
    "                combined_scores[idx] = alpha * bm25_score + (1 - alpha) * dpr_score\n",
    "        \n",
    "        # Sort by combined score\n",
    "        sorted_indices = sorted(combined_scores.keys(), key=lambda idx: combined_scores[idx], reverse=True)[:top_k]\n",
    "        \n",
    "        # Prepare final results\n",
    "        results = []\n",
    "        for idx in sorted_indices:\n",
    "            results.append({\n",
    "                'idx': int(idx),\n",
    "                'bm25_score': bm25_scores.get(idx, 0.0),\n",
    "                'dpr_score': dpr_scores.get(idx, 0.0),\n",
    "                'combined_score': combined_scores[idx],\n",
    "                'passage': self.corpus[idx],\n",
    "                'question': self.processed_data.iloc[idx]['question'],\n",
    "                'answer': self.processed_data.iloc[idx]['answer']\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def retrieve_contexts(self, query, question_type=None, retrieval_method='hybrid', top_k=5):\n",
    "        \"\"\"\n",
    "        Main method to retrieve context passages based on a query\n",
    "        \n",
    "        Args:\n",
    "            query (str): User query\n",
    "            question_type (str, optional): Type of question for specialized retrieval\n",
    "            retrieval_method (str): Method to use ('bm25', 'dpr', or 'hybrid')\n",
    "            top_k (int): Number of top results to return\n",
    "            \n",
    "        Returns:\n",
    "            list: Top-k retrieved contexts\n",
    "        \"\"\"\n",
    "        if retrieval_method == 'bm25':\n",
    "            return self.retrieve_with_bm25(query, top_k=top_k)\n",
    "        elif retrieval_method == 'dpr':\n",
    "            return self.retrieve_with_dpr(query, top_k=top_k)\n",
    "        elif retrieval_method == 'hybrid':\n",
    "            # Adjust alpha based on question type\n",
    "            alpha = 0.5  # Default equal weighting\n",
    "            \n",
    "            if question_type:\n",
    "                # Question-type specific weighting\n",
    "                if question_type in ['FACTUAL', 'LEGAL_PROVISION']:\n",
    "                    alpha = 0.7  # More weight to BM25 for factual questions\n",
    "                elif question_type in ['DEFINITION', 'CONCEPT', 'COMPARISON']:\n",
    "                    alpha = 0.3  # More weight to semantic search for conceptual questions\n",
    "            \n",
    "            return self.hybrid_retrieval(query, question_type, top_k=top_k, alpha=alpha)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown retrieval method: {retrieval_method}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import re\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import datetime\n",
    " \n",
    " \n",
    "class BiLSTMAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Bidirectional LSTM with Attention mechanism for extractive QA\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_size, embedding_dim, num_layers=2, dropout=0.2):\n",
    "        super(BiLSTMAttention, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        # Bidirectional LSTM\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size * 2, 2)  # 2 outputs: start and end positions\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x shape: (batch_size, seq_len, embedding_dim)\n",
    "        \n",
    "        # LSTM forward pass\n",
    "        lstm_out, (hidden, cell) = self.lstm(x, hidden)\n",
    "        # lstm_out shape: (batch_size, seq_len, hidden_size*2)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        attention_scores = self.attention(lstm_out)\n",
    "        # attention_scores shape: (batch_size, seq_len, 1)\n",
    "        \n",
    "        attention_weights = F.softmax(attention_scores, dim=1)\n",
    "        # attention_weights shape: (batch_size, seq_len, 1)\n",
    "        \n",
    "        # Apply attention weights\n",
    "        context_vector = torch.sum(lstm_out * attention_weights, dim=1)\n",
    "        # context_vector shape: (batch_size, hidden_size*2)\n",
    "        \n",
    "        # Output layer - raw logits, not probabilities\n",
    "        output = self.fc(context_vector)\n",
    "        # output shape: (batch_size, 2)\n",
    "        \n",
    "        return output, attention_weights\n",
    " \n",
    " \n",
    "class LegalQADataset(Dataset):\n",
    "    \"\"\"Dataset for training QA models with legal data\"\"\"\n",
    "    def __init__(self, questions, contexts, answer_starts, answer_ends, tokenizer, max_length=512):\n",
    "        self.questions = questions\n",
    "        self.contexts = contexts\n",
    "        self.answer_starts = answer_starts\n",
    "        self.answer_ends = answer_ends\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        question = self.questions[idx]\n",
    "        context = self.contexts[idx]\n",
    "        answer_start = self.answer_starts[idx]\n",
    "        answer_end = self.answer_ends[idx]\n",
    "        \n",
    "        # Tokenize for BERT/T5\n",
    "        encoding = self.tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension\n",
    "        inputs = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        # Add answer positions\n",
    "        inputs['answer_start'] = answer_start\n",
    "        inputs['answer_end'] = answer_end\n",
    "        \n",
    "        return inputs\n",
    " \n",
    " \n",
    "class AnswerExtractorGenerator:\n",
    "    def __init__(self, device=None, extractive_model_path=None, generative_model_path=None):\n",
    "        \"\"\"\n",
    "        Initialize Answer Extraction and Generation Component\n",
    "        \n",
    "        Args:\n",
    "            device (str): Device to use (cpu or cuda)\n",
    "            extractive_model_path (str): Path to load the extractive model\n",
    "            generative_model_path (str): Path to load the generative model\n",
    "        \"\"\"\n",
    "        # Set device\n",
    "        self.device = device if device else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Initialize tokenizers and models\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.bert_model = BertModel.from_pretrained('bert-base-uncased').to(self.device)\n",
    "        \n",
    "        # Initialize extractive model\n",
    "        self.extractive_model = None\n",
    "        if extractive_model_path:\n",
    "            self.load_extractive_model(extractive_model_path)\n",
    "        \n",
    "        # Initialize generative model (T5)\n",
    "        self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "        self.t5_model = None\n",
    "        \n",
    "        if generative_model_path:\n",
    "            self.load_generative_model(generative_model_path)\n",
    "        else:\n",
    "            print(\"Loading default T5 model...\")\n",
    "            self.t5_model = T5ForConditionalGeneration.from_pretrained('t5-small').to(self.device)\n",
    "    \n",
    "    def prepare_training_data(self, processed_data_path, test_size=0.2):\n",
    "        \"\"\"\n",
    "        Prepare training data from processed dataset\n",
    "        \n",
    "        Args:\n",
    "            processed_data_path (str): Path to processed data\n",
    "            test_size (float): Proportion of data for testing\n",
    "            \n",
    "        Returns:\n",
    "            tuple: Train and test data as DataLoader objects\n",
    "        \"\"\"\n",
    "        # Load processed data\n",
    "        with open(processed_data_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        if 'processed_df' in data:\n",
    "            processed_df = pd.DataFrame(data['processed_df'])\n",
    "        else:\n",
    "            raise ValueError(\"Processed data not found in expected format\")\n",
    "        \n",
    "        questions = processed_df['question'].tolist()\n",
    "        answers = processed_df['answer'].tolist()\n",
    "        \n",
    "        # Simulate context by combining question with answer\n",
    "        # In a real application, this would come from retrieved passages\n",
    "        contexts = []\n",
    "        answer_starts = []\n",
    "        answer_ends = []\n",
    "        \n",
    "        for q, a in zip(questions, answers):\n",
    "            # Create a simple context by joining question and answer\n",
    "            # This is for demonstration; in production, use retrieved passages\n",
    "            context = f\"Question: {q} Answer: {a}\"\n",
    "            contexts.append(context)\n",
    "            \n",
    "            # Find the start position of answer in context\n",
    "            start_pos = context.lower().find(a.lower())\n",
    "            if start_pos >= 0:\n",
    "                answer_starts.append(start_pos)\n",
    "                answer_ends.append(start_pos + len(a))\n",
    "            else:\n",
    "                # Fallback if answer not found in context\n",
    "                answer_starts.append(0)\n",
    "                answer_ends.append(len(a))\n",
    "        \n",
    "        # Split data into train and test sets\n",
    "        train_questions, test_questions, train_contexts, test_contexts, \\\n",
    "        train_starts, test_starts, train_ends, test_ends = train_test_split(\n",
    "            questions, contexts, answer_starts, answer_ends, \n",
    "            test_size=test_size, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = LegalQADataset(\n",
    "            train_questions, train_contexts, train_starts, train_ends, \n",
    "            self.bert_tokenizer\n",
    "        )\n",
    "        \n",
    "        test_dataset = LegalQADataset(\n",
    "            test_questions, test_contexts, test_starts, test_ends, \n",
    "            self.bert_tokenizer\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, batch_size=8, shuffle=True\n",
    "        )\n",
    "        \n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset, batch_size=8\n",
    "        )\n",
    "        \n",
    "        print(f\"Prepared {len(train_dataset)} training samples and {len(test_dataset)} test samples\")\n",
    "        \n",
    "        return train_dataloader, test_dataloader\n",
    "    \n",
    "    # Add these methods to the AnswerExtractorGenerator class definition\n",
    "\n",
    "    def prepare_t5_training_data(self, processed_data_path, test_size=0.2, batch_size=8):\n",
    "        \"\"\"\n",
    "        Prepare legal QA data in T5 format for training/fine-tuning\n",
    "        \"\"\"\n",
    "        # Load processed data\n",
    "        with open(processed_data_path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        if 'processed_df' in data:\n",
    "            processed_df = pd.DataFrame(data['processed_df'])\n",
    "        else:\n",
    "            raise ValueError(\"Processed data not found in expected format\")\n",
    "        \n",
    "        print(f\"Loaded {len(processed_df)} QA pairs for T5 preparation\")\n",
    "        \n",
    "        # Initialize T5 tokenizer if not already loaded\n",
    "        if self.t5_tokenizer is None:\n",
    "            self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "        \n",
    "        # Create a custom T5 dataset\n",
    "        class LegalT5Dataset(Dataset):\n",
    "            def __init__(self, questions, answers, tokenizer, max_length=512, max_answer_length=100):\n",
    "                self.questions = questions\n",
    "                self.answers = answers\n",
    "                self.tokenizer = tokenizer\n",
    "                self.max_length = max_length\n",
    "                self.max_answer_length = max_answer_length\n",
    "            \n",
    "            def __len__(self):\n",
    "                return len(self.questions)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                question = self.questions[idx]\n",
    "                answer = self.answers[idx]\n",
    "                \n",
    "                # Prepare input text\n",
    "                input_text = f\"question: {question}\"\n",
    "                \n",
    "                # Tokenize input\n",
    "                input_encodings = self.tokenizer(\n",
    "                    input_text,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Tokenize answer\n",
    "                target_encodings = self.tokenizer(\n",
    "                    answer,\n",
    "                    max_length=self.max_answer_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Remove batch dimension\n",
    "                input_ids = input_encodings.input_ids.squeeze()\n",
    "                attention_mask = input_encodings.attention_mask.squeeze()\n",
    "                target_ids = target_encodings.input_ids.squeeze()\n",
    "                \n",
    "                # Replace padding token id with -100 for loss calculation\n",
    "                target_ids[target_ids == self.tokenizer.pad_token_id] = -100\n",
    "                \n",
    "                return {\n",
    "                    'input_ids': input_ids,\n",
    "                    'attention_mask': attention_mask,\n",
    "                    'labels': target_ids,\n",
    "                    'question': question,\n",
    "                    'answer': answer\n",
    "                }\n",
    "        \n",
    "        # Extract questions and answers from processed data\n",
    "        questions = processed_df['question'].tolist()\n",
    "        answers = processed_df['answer'].tolist()\n",
    "        \n",
    "        # Create dataset\n",
    "        legal_dataset = LegalT5Dataset(questions, answers, self.t5_tokenizer)\n",
    "        \n",
    "        # Split into train and test\n",
    "        train_size = int((1 - test_size) * len(legal_dataset))\n",
    "        test_size = len(legal_dataset) - train_size\n",
    "        legal_train_dataset, legal_test_dataset = random_split(\n",
    "            legal_dataset, [train_size, test_size]\n",
    "        )\n",
    "        \n",
    "        # Create dataloaders\n",
    "        legal_train_dataloader = DataLoader(\n",
    "            legal_train_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "        legal_test_dataloader = DataLoader(\n",
    "            legal_test_dataset, batch_size=batch_size\n",
    "        )\n",
    "        \n",
    "        print(f\"Prepared {len(legal_train_dataset)} training samples and {len(legal_test_dataset)} test samples\")\n",
    "        \n",
    "        return legal_train_dataloader, legal_test_dataloader\n",
    "\n",
    "    def _train_t5_model(self, train_dataloader, test_dataloader, num_epochs, \n",
    "                    learning_rate, phase_name=\"Training\", save_best=True):\n",
    "        \"\"\"\n",
    "        Helper method to train the T5 model on a given dataset\n",
    "        \"\"\"\n",
    "        # Calculate steps\n",
    "        total_train_steps = len(train_dataloader) * num_epochs\n",
    "        warmup_steps = int(0.1 * total_train_steps)\n",
    "        \n",
    "        # Create optimizer\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.t5_model.named_parameters() \n",
    "                        if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.01\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in self.t5_model.named_parameters() \n",
    "                        if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=warmup_steps, \n",
    "            num_training_steps=total_train_steps\n",
    "        )\n",
    "        \n",
    "        # Training setup\n",
    "        start_time = time.time()\n",
    "        best_loss = float('inf')\n",
    "        all_train_losses = []\n",
    "        all_test_losses = []\n",
    "        \n",
    "        print(f\"Starting {phase_name} phase: {num_epochs} epochs, {len(train_dataloader)} steps per epoch\")\n",
    "        print(f\"Learning rate: {learning_rate}, Warmup steps: {warmup_steps}\")\n",
    "        \n",
    "        # Create output directory for checkpoints\n",
    "        os.makedirs(f\"t5_{phase_name.lower()}_checkpoints\", exist_ok=True)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            \n",
    "            # TRAINING\n",
    "            self.t5_model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            # Progress bar for training\n",
    "            train_bar = tqdm(enumerate(train_dataloader), \n",
    "                        total=len(train_dataloader),\n",
    "                        desc=f\"Epoch {epoch+1}/{num_epochs} [{phase_name} Train]\")\n",
    "            \n",
    "            for step, batch in train_bar:\n",
    "                # Move batch to device\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                labels = batch['labels'].to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.t5_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.t5_model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "                \n",
    "                # Update metrics\n",
    "                batch_loss = loss.item()\n",
    "                train_loss += batch_loss\n",
    "                \n",
    "                # Update progress bar\n",
    "                train_bar.set_postfix({\n",
    "                    'loss': f\"{batch_loss:.4f}\",\n",
    "                    'avg_loss': f\"{train_loss/(step+1):.4f}\",\n",
    "                    'lr': f\"{scheduler.get_last_lr()[0]:.6f}\"\n",
    "                })\n",
    "            \n",
    "            # Calculate average training loss\n",
    "            avg_train_loss = train_loss / len(train_dataloader)\n",
    "            all_train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # EVALUATION\n",
    "            self.t5_model.eval()\n",
    "            test_loss = 0\n",
    "            \n",
    "            # Progress bar for evaluation\n",
    "            test_bar = tqdm(enumerate(test_dataloader),\n",
    "                        total=len(test_dataloader),\n",
    "                        desc=f\"Epoch {epoch+1}/{num_epochs} [{phase_name} Test]\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for step, batch in test_bar:\n",
    "                    # Move batch to device\n",
    "                    input_ids = batch['input_ids'].to(self.device)\n",
    "                    attention_mask = batch['attention_mask'].to(self.device)\n",
    "                    labels = batch['labels'].to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = self.t5_model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=labels\n",
    "                    )\n",
    "                    \n",
    "                    # Update metrics\n",
    "                    batch_loss = outputs.loss.item()\n",
    "                    test_loss += batch_loss\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    test_bar.set_postfix({\n",
    "                        'loss': f\"{batch_loss:.4f}\",\n",
    "                        'avg_loss': f\"{test_loss/(step+1):.4f}\"\n",
    "                    })\n",
    "            \n",
    "            # Calculate average test loss\n",
    "            avg_test_loss = test_loss / len(test_dataloader)\n",
    "            all_test_losses.append(avg_test_loss)\n",
    "            \n",
    "            # Save best model\n",
    "            if save_best and avg_test_loss < best_loss:\n",
    "                best_loss = avg_test_loss\n",
    "                checkpoint_path = f\"t5_{phase_name.lower()}_checkpoints/best_epoch_{epoch+1}_loss_{avg_test_loss:.4f}\"\n",
    "                self.t5_model.save_pretrained(checkpoint_path)\n",
    "                self.t5_tokenizer.save_pretrained(checkpoint_path)\n",
    "                print(f\"✓ New best model saved to {checkpoint_path}\")\n",
    "            \n",
    "            # Print epoch summary\n",
    "            epoch_time = time.time() - epoch_start\n",
    "            total_time = time.time() - start_time\n",
    "            \n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"  Test Loss: {avg_test_loss:.4f}\")\n",
    "            print(f\"  Epoch Time: {datetime.timedelta(seconds=int(epoch_time))}\")\n",
    "            print(f\"  Total Time: {datetime.timedelta(seconds=int(total_time))}\")\n",
    "            \n",
    "            # Estimate remaining time\n",
    "            if epoch < num_epochs - 1:\n",
    "                avg_epoch_time = total_time / (epoch + 1)\n",
    "                remaining = avg_epoch_time * (num_epochs - epoch - 1)\n",
    "                print(f\"  Est. Time Remaining: {datetime.timedelta(seconds=int(remaining))}\")\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        # Print phase summary\n",
    "        print(f\"\\n{phase_name} phase completed in {datetime.timedelta(seconds=int(time.time() - start_time))}\")\n",
    "        print(f\"Final Train Loss: {all_train_losses[-1]:.4f}\")\n",
    "        print(f\"Final Test Loss: {all_test_losses[-1]:.4f}\")\n",
    "        print(f\"Best Test Loss: {best_loss:.4f}\")\n",
    "        \n",
    "        return all_train_losses, all_test_losses\n",
    "\n",
    "    def train_on_squad_and_finetune(self, legal_train_dataloader, legal_test_dataloader, \n",
    "                                squad_batch_size=8, squad_epochs=3, finetune_epochs=3, \n",
    "                                learning_rate=3e-5, save_best=True, squad_file_path=None):\n",
    "        \"\"\"\n",
    "        Train T5 on SQuAD dataset first, then fine-tune on legal QA data\n",
    "        \n",
    "        Args:\n",
    "            legal_train_dataloader: DataLoader for legal training data\n",
    "            legal_test_dataloader: DataLoader for legal test data\n",
    "            squad_batch_size: Batch size for SQuAD training\n",
    "            squad_epochs: Number of epochs for SQuAD training\n",
    "            finetune_epochs: Number of epochs for legal data fine-tuning\n",
    "            learning_rate: Learning rate for both training phases\n",
    "            save_best: Whether to save checkpoints of the best model\n",
    "            squad_file_path: Path to the SQuAD JSON file (train-v1.1.json)\n",
    "        \n",
    "        Returns:\n",
    "            T5ForConditionalGeneration: Fine-tuned model\n",
    "        \"\"\"\n",
    "        print(\"Loading SQuAD dataset...\")\n",
    "        \n",
    "        # Attempt to load SQuAD from the specified file path\n",
    "        if squad_file_path and os.path.exists(squad_file_path):\n",
    "            try:\n",
    "                with open(squad_file_path, 'r', encoding='utf-8') as f:\n",
    "                    squad_json = json.load(f)\n",
    "                    squad_data = squad_json['data']\n",
    "                    print(f\"Loaded SQuAD from {squad_file_path}: {len(squad_data)} articles\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading from {squad_file_path}: {str(e)}\")\n",
    "                squad_data = None\n",
    "        else:\n",
    "            try:\n",
    "                # Try to load SQuAD from HuggingFace datasets\n",
    "                from datasets import load_dataset\n",
    "                squad_dataset = load_dataset(\"squad\", split=\"train\")\n",
    "                squad_data = squad_dataset.to_dict()\n",
    "                print(f\"Loaded {len(squad_dataset)} SQuAD examples from HuggingFace datasets\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading from HuggingFace: {str(e)}\")\n",
    "                # Fallback: Download SQuAD from web\n",
    "                print(\"SQuAD dataset not found locally. Downloading from web...\")\n",
    "                import urllib.request\n",
    "                url = \"https://rajpurkar.github.io/SQuAD-explorer/dataset/train-v1.1.json\"\n",
    "                local_file = 'squad_train-v1.1.json'\n",
    "                urllib.request.urlretrieve(url, local_file)\n",
    "                \n",
    "                with open(local_file, 'r', encoding='utf-8') as f:\n",
    "                    squad_json = json.load(f)\n",
    "                    squad_data = squad_json['data']\n",
    "                    print(f\"Downloaded SQuAD. Loaded {len(squad_data)} articles\")\n",
    "        \n",
    "        if not squad_data:\n",
    "            raise ValueError(\"Failed to load SQuAD dataset\")\n",
    "        \n",
    "        # Create SQuAD dataset\n",
    "        class SQuADT5Dataset(Dataset):\n",
    "            \"\"\"Dataset for training T5 on SQuAD\"\"\"\n",
    "            def __init__(self, squad_data, tokenizer, max_length=512, max_answer_length=100):\n",
    "                self.examples = []\n",
    "                self.tokenizer = tokenizer\n",
    "                self.max_length = max_length\n",
    "                self.max_answer_length = max_answer_length\n",
    "                \n",
    "                # Process SQuAD data\n",
    "                for article in squad_data:\n",
    "                    title = article.get('title', '')\n",
    "                    for paragraph in article['paragraphs']:\n",
    "                        context = paragraph['context']\n",
    "                        for qa in paragraph['qas']:\n",
    "                            question = qa['question']\n",
    "                            \n",
    "                            if not qa['answers']:\n",
    "                                continue\n",
    "                                \n",
    "                            answer = qa['answers'][0]['text']\n",
    "                            \n",
    "                            # Create T5 input format: \"question: {question} context: {context}\"\n",
    "                            self.examples.append({\n",
    "                                'question': question,\n",
    "                                'context': context,\n",
    "                                'answer': answer\n",
    "                            })\n",
    "            \n",
    "            def __len__(self):\n",
    "                return len(self.examples)\n",
    "            \n",
    "            def __getitem__(self, idx):\n",
    "                example = self.examples[idx]\n",
    "                \n",
    "                # Prepare input text for T5\n",
    "                input_text = f\"question: {example['question']} context: {example['context']}\"\n",
    "                \n",
    "                # Tokenize input\n",
    "                input_encodings = self.tokenizer(\n",
    "                    input_text,\n",
    "                    max_length=self.max_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Tokenize answer\n",
    "                target_encodings = self.tokenizer(\n",
    "                    example['answer'],\n",
    "                    max_length=self.max_answer_length,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                )\n",
    "                \n",
    "                # Remove batch dimension\n",
    "                input_ids = input_encodings.input_ids.squeeze()\n",
    "                attention_mask = input_encodings.attention_mask.squeeze()\n",
    "                target_ids = target_encodings.input_ids.squeeze()\n",
    "                \n",
    "                # Replace padding token id with -100 for loss calculation\n",
    "                target_ids[target_ids == self.tokenizer.pad_token_id] = -100\n",
    "                \n",
    "                return {\n",
    "                    'input_ids': input_ids,\n",
    "                    'attention_mask': attention_mask,\n",
    "                    'labels': target_ids,\n",
    "                    'question': example['question'],\n",
    "                    'answer': example['answer']\n",
    "                }\n",
    "        \n",
    "        # Initialize or load T5 model\n",
    "        print(\"Initializing T5 model...\")\n",
    "        if self.t5_model is None:\n",
    "            self.t5_model = T5ForConditionalGeneration.from_pretrained('t5-small').to(self.device)\n",
    "        if self.t5_tokenizer is None:\n",
    "            self.t5_tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "        \n",
    "        # Create SQuAD dataset\n",
    "        squad_dataset = SQuADT5Dataset(squad_data, self.t5_tokenizer)\n",
    "        \n",
    "        # Split SQuAD into train and validation sets (90/10 split)\n",
    "        train_size = int(0.9 * len(squad_dataset))\n",
    "        val_size = len(squad_dataset) - train_size\n",
    "        squad_train_dataset, squad_val_dataset = random_split(\n",
    "            squad_dataset, [train_size, val_size]\n",
    "        )\n",
    "        \n",
    "        # Create DataLoaders for SQuAD\n",
    "        squad_train_dataloader = DataLoader(\n",
    "            squad_train_dataset, batch_size=squad_batch_size, shuffle=True\n",
    "        )\n",
    "        squad_val_dataloader = DataLoader(\n",
    "            squad_val_dataset, batch_size=squad_batch_size\n",
    "        )\n",
    "        \n",
    "        print(f\"SQuAD training set: {len(squad_train_dataset)} examples\")\n",
    "        print(f\"SQuAD validation set: {len(squad_val_dataset)} examples\")\n",
    "        \n",
    "        # PHASE 1: Train on SQuAD\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PHASE 1: Training on SQuAD dataset\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Train the model on SQuAD\n",
    "        self._train_t5_model(\n",
    "            train_dataloader=squad_train_dataloader,\n",
    "            test_dataloader=squad_val_dataloader,\n",
    "            num_epochs=squad_epochs,\n",
    "            learning_rate=learning_rate,\n",
    "            phase_name=\"SQuAD\",\n",
    "            save_best=save_best\n",
    "        )\n",
    "        \n",
    "        # PHASE 2: Fine-tune on legal data\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"PHASE 2: Fine-tuning on legal dataset\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # Fine-tune the model on legal data\n",
    "        self._train_t5_model(\n",
    "            train_dataloader=legal_train_dataloader,\n",
    "            test_dataloader=legal_test_dataloader,\n",
    "            num_epochs=finetune_epochs,\n",
    "            learning_rate=learning_rate/2,  # Smaller learning rate for fine-tuning\n",
    "            phase_name=\"Legal\",\n",
    "            save_best=save_best\n",
    "        )\n",
    "        \n",
    "        # Save the final model\n",
    "        model_dir = \"t5_squad_legal_model\"\n",
    "        self.t5_model.save_pretrained(model_dir)\n",
    "        self.t5_tokenizer.save_pretrained(model_dir)\n",
    "        print(f\"Final model saved to {model_dir}\")\n",
    "        \n",
    "        return self.t5_model\n",
    "    \n",
    "    def train_extractive_model(self, train_dataloader, test_dataloader, \n",
    "                               hidden_size=256, embedding_dim=768, num_layers=2,\n",
    "                               num_epochs=5, learning_rate=3e-5):\n",
    "        \"\"\"\n",
    "        Train the BiLSTM with Attention model for extractive QA with progress tracking\n",
    "        \n",
    "        Args:\n",
    "            train_dataloader (DataLoader): Training data\n",
    "            test_dataloader (DataLoader): Test data\n",
    "            hidden_size (int): Size of LSTM hidden layer\n",
    "            embedding_dim (int): Size of word embeddings\n",
    "            num_layers (int): Number of LSTM layers\n",
    "            num_epochs (int): Number of training epochs\n",
    "            learning_rate (float): Learning rate\n",
    "            \n",
    "        Returns:\n",
    "            BiLSTMAttention: Trained model\n",
    "        \"\"\"\n",
    "        # Initialize model\n",
    "        model = BiLSTMAttention(\n",
    "            hidden_size=hidden_size,\n",
    "            embedding_dim=embedding_dim,\n",
    "            num_layers=num_layers\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        # Loss function - use MSELoss instead of CrossEntropyLoss for regression task\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        # Calculate total steps for progress tracking\n",
    "        total_train_steps = len(train_dataloader)\n",
    "        total_test_steps = len(test_dataloader)\n",
    "        \n",
    "        print(f\"Starting training: {num_epochs} epochs, {total_train_steps} steps per epoch\")\n",
    "        print(f\"Training on device: {self.device}\")\n",
    "        \n",
    "        # Track training metrics\n",
    "        all_train_losses = []\n",
    "        all_test_losses = []\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # TRAINING PHASE\n",
    "            model.train()\n",
    "            train_loss = 0\n",
    "            batch_losses = []\n",
    "            \n",
    "            # Create progress bar for training\n",
    "            train_progress_bar = tqdm(enumerate(train_dataloader), \n",
    "                                     total=total_train_steps, \n",
    "                                     desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\",\n",
    "                                     leave=True)\n",
    "            \n",
    "            for batch_idx, batch in train_progress_bar:\n",
    "                # Get input embeddings from BERT\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    bert_outputs = self.bert_model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask\n",
    "                    )\n",
    "                    \n",
    "                    bert_embeddings = bert_outputs.last_hidden_state\n",
    "                \n",
    "                # Get answer positions and convert to float for MSELoss\n",
    "                start_positions = batch['answer_start'].float().to(self.device)\n",
    "                end_positions = batch['answer_end'].float().to(self.device)\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                output, _ = model(bert_embeddings)\n",
    "                \n",
    "                # Calculate loss with MSELoss (requires float targets)\n",
    "                start_loss = criterion(output[:, 0], start_positions)\n",
    "                end_loss = criterion(output[:, 1], end_positions)\n",
    "                loss = start_loss + end_loss\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                batch_loss = loss.item()\n",
    "                train_loss += batch_loss\n",
    "                batch_losses.append(batch_loss)\n",
    "                \n",
    "                # Update progress bar with current loss\n",
    "                train_progress_bar.set_postfix({\n",
    "                    'loss': f\"{batch_loss:.4f}\",\n",
    "                    'avg_loss': f\"{train_loss/(batch_idx+1):.4f}\"\n",
    "                })\n",
    "            \n",
    "            # Calculate average training loss\n",
    "            avg_train_loss = train_loss / total_train_steps\n",
    "            all_train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # EVALUATION PHASE\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            \n",
    "            # Create progress bar for evaluation\n",
    "            test_progress_bar = tqdm(enumerate(test_dataloader), \n",
    "                                    total=total_test_steps, \n",
    "                                    desc=f\"Epoch {epoch+1}/{num_epochs} [Test]\",\n",
    "                                    leave=True)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, batch in test_progress_bar:\n",
    "                    # Get input embeddings from BERT\n",
    "                    input_ids = batch['input_ids'].to(self.device)\n",
    "                    attention_mask = batch['attention_mask'].to(self.device)\n",
    "                    \n",
    "                    bert_outputs = self.bert_model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask\n",
    "                    )\n",
    "                    \n",
    "                    bert_embeddings = bert_outputs.last_hidden_state\n",
    "                    \n",
    "                    # Get answer positions as float for MSELoss\n",
    "                    start_positions = batch['answer_start'].float().to(self.device)\n",
    "                    end_positions = batch['answer_end'].float().to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    output, _ = model(bert_embeddings)\n",
    "                    \n",
    "                    # Calculate loss with MSELoss\n",
    "                    start_loss = criterion(output[:, 0], start_positions)\n",
    "                    end_loss = criterion(output[:, 1], end_positions)\n",
    "                    loss = start_loss + end_loss\n",
    "                    \n",
    "                    batch_loss = loss.item()\n",
    "                    test_loss += batch_loss\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    test_progress_bar.set_postfix({\n",
    "                        'loss': f\"{batch_loss:.4f}\",\n",
    "                        'avg_loss': f\"{test_loss/(batch_idx+1):.4f}\"\n",
    "                    })\n",
    "            \n",
    "            # Calculate average test loss\n",
    "            avg_test_loss = test_loss / total_test_steps\n",
    "            all_test_losses.append(avg_test_loss)\n",
    "            \n",
    "            # Calculate epoch duration\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            total_duration = time.time() - start_time\n",
    "            \n",
    "            # Format as hours:minutes:seconds\n",
    "            epoch_time_str = str(datetime.timedelta(seconds=int(epoch_duration)))\n",
    "            total_time_str = str(datetime.timedelta(seconds=int(total_duration)))\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"  Test Loss: {avg_test_loss:.4f}\")\n",
    "            print(f\"  Epoch Time: {epoch_time_str}\")\n",
    "            print(f\"  Total Time: {total_time_str}\")\n",
    "            \n",
    "            # Estimate remaining time\n",
    "            if epoch < num_epochs - 1:\n",
    "                avg_epoch_time = total_duration / (epoch + 1)\n",
    "                remaining_epochs = num_epochs - (epoch + 1)\n",
    "                est_remaining_time = avg_epoch_time * remaining_epochs\n",
    "                est_remaining_str = str(datetime.timedelta(seconds=int(est_remaining_time)))\n",
    "                print(f\"  Estimated Time Remaining: {est_remaining_str}\")\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        # Print training summary\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print(f\"\\nTraining completed in {total_time_str}\")\n",
    "        print(f\"Final Train Loss: {all_train_losses[-1]:.4f}\")\n",
    "        print(f\"Final Test Loss: {all_test_losses[-1]:.4f}\")\n",
    "        \n",
    "        # Save the trained model\n",
    "        self.extractive_model = model\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def save_extractive_model(self, path):\n",
    "        \"\"\"\n",
    "        Save the trained extractive model\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to save the model\n",
    "        \"\"\"\n",
    "        if self.extractive_model is None:\n",
    "            raise ValueError(\"No extractive model available to save\")\n",
    "            \n",
    "        torch.save({\n",
    "            'model_state_dict': self.extractive_model.state_dict(),\n",
    "            'hidden_size': self.extractive_model.hidden_size,\n",
    "            'num_layers': self.extractive_model.num_layers,\n",
    "            'dropout': self.extractive_model.dropout\n",
    "        }, path)\n",
    "        \n",
    "        print(f\"Extractive model saved to {path}\")\n",
    "    \n",
    "    def load_extractive_model(self, path):\n",
    "        \"\"\"\n",
    "        Load a trained extractive model\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to load the model from\n",
    "        \"\"\"\n",
    "        try:\n",
    "            checkpoint = torch.load(path, map_location=self.device)\n",
    "            \n",
    "            model = BiLSTMAttention(\n",
    "                hidden_size=checkpoint['hidden_size'],\n",
    "                embedding_dim=768,  # BERT embedding size\n",
    "                num_layers=checkpoint['num_layers'],\n",
    "                dropout=checkpoint['dropout']\n",
    "            ).to(self.device)\n",
    "            \n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            model.eval()\n",
    "            \n",
    "            self.extractive_model = model\n",
    "            print(f\"Extractive model loaded from {path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "                print(f\"Error loading extractive model: {str(e)}\")\n",
    "        \n",
    "    def fine_tune_t5(self, train_dataloader, test_dataloader, num_epochs=5, learning_rate=3e-5):\n",
    "        \"\"\"\n",
    "        Fine-tune T5 model for answer generation with progress tracking and improved\n",
    "        training parameters\n",
    "        \n",
    "        Args:\n",
    "            train_dataloader (DataLoader): Training data\n",
    "            test_dataloader (DataLoader): Test data\n",
    "            num_epochs (int): Number of training epochs (increased from 2 to 5)\n",
    "            learning_rate (float): Learning rate (adjusted from 5e-5 to 3e-5)\n",
    "            \n",
    "        Returns:\n",
    "            T5ForConditionalGeneration: Fine-tuned model\n",
    "        \"\"\"\n",
    "        # Initialize model if not already loaded\n",
    "        if self.t5_model is None:\n",
    "            self.t5_model = T5ForConditionalGeneration.from_pretrained('t5-small').to(self.device)\n",
    "        \n",
    "        # Initialize optimizer with weight decay and warmup\n",
    "        from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "        \n",
    "        # Create parameter groups with different learning rates\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.t5_model.named_parameters() \n",
    "                        if not any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.01\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in self.t5_model.named_parameters() \n",
    "                        if any(nd in n for nd in no_decay)],\n",
    "                'weight_decay': 0.0\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
    "        \n",
    "        # Create a learning rate scheduler with warmup\n",
    "        total_steps = len(train_dataloader) * num_epochs\n",
    "        warmup_steps = int(0.1 * total_steps)  # 10% of total steps for warmup\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, \n",
    "            num_warmup_steps=warmup_steps, \n",
    "            num_training_steps=total_steps\n",
    "        )\n",
    "        \n",
    "        # Calculate total steps for progress tracking\n",
    "        total_train_steps = len(train_dataloader)\n",
    "        total_test_steps = len(test_dataloader)\n",
    "        \n",
    "        print(f\"Starting T5 fine-tuning: {num_epochs} epochs, {total_train_steps} steps per epoch\")\n",
    "        print(f\"Training on device: {self.device}\")\n",
    "        print(f\"Learning rate: {learning_rate}, Warmup steps: {warmup_steps}\")\n",
    "        \n",
    "        # Track training metrics\n",
    "        all_train_losses = []\n",
    "        all_test_losses = []\n",
    "        best_test_loss = float('inf')\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            # TRAINING PHASE\n",
    "            self.t5_model.train()\n",
    "            train_loss = 0\n",
    "            \n",
    "            # Create progress bar for training\n",
    "            train_progress_bar = tqdm(enumerate(train_dataloader), \n",
    "                                    total=total_train_steps, \n",
    "                                    desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\",\n",
    "                                    leave=True)\n",
    "            \n",
    "            for batch_idx, batch in train_progress_bar:\n",
    "                # Prepare inputs for T5\n",
    "                input_ids = batch['input_ids'].to(self.device)\n",
    "                attention_mask = batch['attention_mask'].to(self.device)\n",
    "                \n",
    "                # Extract context and question text from the batch\n",
    "                contexts = self.bert_tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "                \n",
    "                # Create a list to store target texts\n",
    "                target_texts = []\n",
    "\n",
    "                # For each sample in the batch, extract the answer from the context\n",
    "                for i, context in enumerate(contexts):\n",
    "                    # Get answer start and end positions\n",
    "                    start_pos = batch['answer_start'][i].item()\n",
    "                    end_pos = batch['answer_end'][i].item()\n",
    "                    \n",
    "                    # Extract answer directly from the context string\n",
    "                    answer_text = context[start_pos:end_pos]\n",
    "                    \n",
    "                    # If answer extraction failed, use a placeholder\n",
    "                    if not answer_text or len(answer_text) < 2:\n",
    "                        answer_text = \"No answer found\"\n",
    "                        \n",
    "                    target_texts.append(answer_text)\n",
    "                \n",
    "                # Tokenize target texts (answers) for T5\n",
    "                target_encodings = self.t5_tokenizer(\n",
    "                    target_texts,\n",
    "                    max_length=100,\n",
    "                    padding='max_length',\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                ).to(self.device)\n",
    "                \n",
    "                target_ids = target_encodings.input_ids\n",
    "                \n",
    "                # Replace pad tokens with -100 so they're ignored in loss calculation\n",
    "                target_ids[target_ids == self.t5_tokenizer.pad_token_id] = -100\n",
    "                \n",
    "                # Forward pass\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.t5_model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=target_ids\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward pass and optimization\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping to prevent exploding gradients\n",
    "                torch.nn.utils.clip_grad_norm_(self.t5_model.parameters(), max_norm=1.0)\n",
    "                \n",
    "                optimizer.step()\n",
    "                scheduler.step()  # Update learning rate\n",
    "                \n",
    "                batch_loss = loss.item()\n",
    "                train_loss += batch_loss\n",
    "                \n",
    "                # Update progress bar with current loss and learning rate\n",
    "                current_lr = scheduler.get_last_lr()[0]\n",
    "                train_progress_bar.set_postfix({\n",
    "                    'loss': f\"{batch_loss:.4f}\",\n",
    "                    'avg_loss': f\"{train_loss/(batch_idx+1):.4f}\",\n",
    "                    'lr': f\"{current_lr:.6f}\"\n",
    "                })\n",
    "            \n",
    "            # Calculate average training loss\n",
    "            avg_train_loss = train_loss / total_train_steps\n",
    "            all_train_losses.append(avg_train_loss)\n",
    "            \n",
    "            # EVALUATION PHASE\n",
    "            self.t5_model.eval()\n",
    "            test_loss = 0\n",
    "            \n",
    "            # Create progress bar for evaluation\n",
    "            test_progress_bar = tqdm(enumerate(test_dataloader), \n",
    "                                    total=total_test_steps, \n",
    "                                    desc=f\"Epoch {epoch+1}/{num_epochs} [Test]\",\n",
    "                                    leave=True)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for batch_idx, batch in test_progress_bar:\n",
    "                    # Same preprocessing as training\n",
    "                    # ... [identical code for preparing inputs and targets] ...\n",
    "                    \n",
    "                    # Prepare inputs for T5\n",
    "                    input_ids = batch['input_ids'].to(self.device)\n",
    "                    attention_mask = batch['attention_mask'].to(self.device)\n",
    "                    \n",
    "                    # Extract context and question text from the batch\n",
    "                    contexts = self.bert_tokenizer.batch_decode(input_ids, skip_special_tokens=True)\n",
    "                    \n",
    "                    # Create a list to store target texts\n",
    "                    target_texts = []\n",
    "                    \n",
    "                    # For each sample in the batch, extract the answer from the context\n",
    "                    for i, context in enumerate(contexts):\n",
    "                        # Get answer start and end positions\n",
    "                        start_pos = batch['answer_start'][i].item()\n",
    "                        end_pos = batch['answer_end'][i].item()\n",
    "                        \n",
    "                        # Extract answer from the context string\n",
    "                        answer_text = context[start_pos:end_pos]\n",
    "                        \n",
    "                        # If answer extraction failed, use a placeholder\n",
    "                        if not answer_text or len(answer_text) < 2:\n",
    "                            answer_text = \"No answer found\"\n",
    "                            \n",
    "                        target_texts.append(answer_text)\n",
    "                    \n",
    "                    # Tokenize target texts for T5\n",
    "                    target_encodings = self.t5_tokenizer(\n",
    "                        target_texts,\n",
    "                        max_length=100,\n",
    "                        padding='max_length',\n",
    "                        truncation=True,\n",
    "                        return_tensors='pt'\n",
    "                    ).to(self.device)\n",
    "                    \n",
    "                    target_ids = target_encodings.input_ids\n",
    "                    \n",
    "                    # Replace pad tokens with -100 so they're ignored in loss calculation\n",
    "                    target_ids[target_ids == self.t5_tokenizer.pad_token_id] = -100\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    outputs = self.t5_model(\n",
    "                        input_ids=input_ids,\n",
    "                        attention_mask=attention_mask,\n",
    "                        labels=target_ids\n",
    "                    )\n",
    "                    \n",
    "                    loss = outputs.loss\n",
    "                    batch_loss = loss.item()\n",
    "                    test_loss += batch_loss\n",
    "                    \n",
    "                    # Update progress bar\n",
    "                    test_progress_bar.set_postfix({\n",
    "                        'loss': f\"{batch_loss:.4f}\",\n",
    "                        'avg_loss': f\"{test_loss/(batch_idx+1):.4f}\"\n",
    "                    })\n",
    "            \n",
    "            # Calculate average test loss\n",
    "            avg_test_loss = test_loss / total_test_steps\n",
    "            all_test_losses.append(avg_test_loss)\n",
    "            \n",
    "            # Save checkpoint if best model so far\n",
    "            if avg_test_loss < best_test_loss:\n",
    "                best_test_loss = avg_test_loss\n",
    "                # Save best model checkpoint\n",
    "                checkpoint_path = f\"t5_model_best_epoch_{epoch+1}_loss_{avg_test_loss:.4f}\"\n",
    "                self.t5_model.save_pretrained(checkpoint_path)\n",
    "                self.t5_tokenizer.save_pretrained(checkpoint_path)\n",
    "                print(f\"✓ Saved best model checkpoint to {checkpoint_path}\")\n",
    "            \n",
    "            # Calculate epoch duration\n",
    "            epoch_duration = time.time() - epoch_start_time\n",
    "            total_duration = time.time() - start_time\n",
    "            \n",
    "            # Format as hours:minutes:seconds\n",
    "            epoch_time_str = str(datetime.timedelta(seconds=int(epoch_duration)))\n",
    "            total_time_str = str(datetime.timedelta(seconds=int(total_duration)))\n",
    "            \n",
    "            # Print epoch summary\n",
    "            print(f\"\\nEpoch {epoch+1}/{num_epochs} Summary:\")\n",
    "            print(f\"  Train Loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"  Test Loss: {avg_test_loss:.4f}\")\n",
    "            print(f\"  Epoch Time: {epoch_time_str}\")\n",
    "            print(f\"  Total Time: {total_time_str}\")\n",
    "            \n",
    "            # Estimate remaining time\n",
    "            if epoch < num_epochs - 1:\n",
    "                avg_epoch_time = total_duration / (epoch + 1)\n",
    "                remaining_epochs = num_epochs - (epoch + 1)\n",
    "                est_remaining_time = avg_epoch_time * remaining_epochs\n",
    "                est_remaining_str = str(datetime.timedelta(seconds=int(est_remaining_time)))\n",
    "                print(f\"  Estimated Time Remaining: {est_remaining_str}\")\n",
    "            \n",
    "            print(\"-\" * 50)\n",
    "        \n",
    "        # Print training summary\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        print(f\"\\nT5 fine-tuning completed in {total_time_str}\")\n",
    "        print(f\"Final Train Loss: {all_train_losses[-1]:.4f}\")\n",
    "        print(f\"Final Test Loss: {all_test_losses[-1]:.4f}\")\n",
    "        print(f\"Best Test Loss: {best_test_loss:.4f}\")\n",
    "        \n",
    "        # Load the best model for the final save\n",
    "        best_checkpoint = f\"t5_model_best_epoch_{all_test_losses.index(min(all_test_losses))+1}_loss_{min(all_test_losses):.4f}\"\n",
    "        try:\n",
    "            self.t5_model = T5ForConditionalGeneration.from_pretrained(best_checkpoint).to(self.device)\n",
    "            print(f\"Loaded best model from {best_checkpoint} for final saving\")\n",
    "        except:\n",
    "            print(\"Using current model for final saving (best checkpoint not found)\")\n",
    "        \n",
    "        return self.t5_model\n",
    "\n",
    "    def save_generative_model(self, path):\n",
    "        \"\"\"\n",
    "        Save the fine-tuned T5 model\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to save the model\n",
    "        \"\"\"\n",
    "        if self.t5_model is None:\n",
    "            raise ValueError(\"No generative model available to save\")\n",
    "            \n",
    "        self.t5_model.save_pretrained(path)\n",
    "        self.t5_tokenizer.save_pretrained(path)\n",
    "        \n",
    "        print(f\"Generative model saved to {path}\")\n",
    "    \n",
    "    def load_generative_model(self, path):\n",
    "        \"\"\"\n",
    "        Load a fine-tuned T5 model\n",
    "        \n",
    "        Args:\n",
    "            path (str): Path to load the model from\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.t5_model = T5ForConditionalGeneration.from_pretrained(path).to(self.device)\n",
    "            self.t5_tokenizer = T5Tokenizer.from_pretrained(path)\n",
    "            \n",
    "            print(f\"Generative model loaded from {path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading generative model: {str(e)}\")\n",
    "            print(\"Loading default T5 model instead...\")\n",
    "            self.t5_model = T5ForConditionalGeneration.from_pretrained('t5-small').to(self.device)\n",
    "    \n",
    "    def extract_answer(self, question, context, confidence_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Extract answer from context using BiLSTM with Attention\n",
    "        \n",
    "        Args:\n",
    "            question (str): User question\n",
    "            context (str): Retrieved passage\n",
    "            confidence_threshold (float): Threshold for extraction confidence\n",
    "            \n",
    "        Returns:\n",
    "            dict: Extracted answer with confidence score\n",
    "        \"\"\"\n",
    "        if self.extractive_model is None:\n",
    "            return {'answer': None, 'confidence': 0.0, 'message': 'Extractive model not available'}\n",
    "        \n",
    "        # Tokenize input\n",
    "        encoding = self.bert_tokenizer(\n",
    "            question,\n",
    "            context,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Get BERT embeddings\n",
    "        with torch.no_grad():\n",
    "            bert_outputs = self.bert_model(\n",
    "                input_ids=encoding['input_ids'],\n",
    "                attention_mask=encoding['attention_mask']\n",
    "            )\n",
    "            \n",
    "            bert_embeddings = bert_outputs.last_hidden_state\n",
    "        \n",
    "        # Get predictions from extractive model\n",
    "        self.extractive_model.eval()\n",
    "        with torch.no_grad():\n",
    "            output, attention_weights = self.extractive_model(bert_embeddings)\n",
    "            \n",
    "            # Get start and end positions\n",
    "            start_logits = output[0, 0].item()\n",
    "            end_logits = output[0, 1].item()\n",
    "            \n",
    "            # Convert logits to probabilities\n",
    "            start_prob = torch.sigmoid(torch.tensor(start_logits)).item()\n",
    "            end_prob = torch.sigmoid(torch.tensor(end_logits)).item()\n",
    "            \n",
    "            confidence = (start_prob + end_prob) / 2\n",
    "            \n",
    "            # If confidence is below threshold, return no answer\n",
    "            if confidence < confidence_threshold:\n",
    "                return {\n",
    "                    'answer': None,\n",
    "                    'confidence': confidence,\n",
    "                    'message': 'Low confidence in extraction'\n",
    "                }\n",
    "            \n",
    "            # Get token with highest attention weight\n",
    "            attention = attention_weights.squeeze().cpu().numpy()\n",
    "            max_attention_idx = np.argmax(attention)\n",
    "            \n",
    "            # Extract tokens around the highest attention point\n",
    "            # Convert to original tokens\n",
    "            tokens = self.bert_tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "            \n",
    "            # Take a window around the highest attention token\n",
    "            window_size = 5\n",
    "            start_idx = max(0, max_attention_idx - window_size)\n",
    "            end_idx = min(len(tokens), max_attention_idx + window_size)\n",
    "            \n",
    "            # Get the extracted tokens\n",
    "            extracted_tokens = tokens[start_idx:end_idx]\n",
    "            \n",
    "            # Convert back to text\n",
    "            extracted_text = self.bert_tokenizer.convert_tokens_to_string(extracted_tokens)\n",
    "            \n",
    "            # Clean up the extracted text\n",
    "            extracted_text = re.sub(r'\\[CLS\\]|\\[SEP\\]|\\[PAD\\]', '', extracted_text).strip()\n",
    "            \n",
    "            return {\n",
    "                'answer': extracted_text,\n",
    "                'confidence': confidence,\n",
    "                'start_idx': start_idx,\n",
    "                'end_idx': end_idx\n",
    "            }\n",
    "    \n",
    "    # In the AnswerExtractorGenerator class\n",
    "    def generate_answer(self, question, context, max_length=100):\n",
    "        \"\"\"\n",
    "        Generate answer using T5 model with improved prompting\n",
    "        \"\"\"\n",
    "        if self.t5_model is None:\n",
    "            return {'answer': None, 'message': 'Generative model not available'}\n",
    "        \n",
    "        # Identify question intent for better prompting\n",
    "        question_lower = question.lower()\n",
    "        \n",
    "        # Create more targeted prompts based on question type\n",
    "        if any(word in question_lower for word in ['what happens', 'punishment', 'penalty', 'sentence', 'consequences']):\n",
    "            instruction = \"Explain the legal penalties or consequences according to Indian law: \"\n",
    "        elif 'define' in question_lower or 'what is' in question_lower or 'meaning' in question_lower:\n",
    "            instruction = \"Provide the legal definition according to Indian law: \"\n",
    "        elif 'how' in question_lower:\n",
    "            instruction = \"Explain the legal procedure according to Indian law: \"\n",
    "        elif 'rights' in question_lower or 'entitled' in question_lower:\n",
    "            instruction = \"Explain the legal rights according to Indian law: \"\n",
    "        else:\n",
    "            instruction = \"Answer the legal question according to Indian law: \"\n",
    "        \n",
    "        # Prepare input for T5 with more structured format\n",
    "        input_text = f\"{instruction} {question}\\n\\nRelevant legal context: {context}\\n\\nAnswer: \"\n",
    "        \n",
    "        # Tokenize input\n",
    "        input_ids = self.t5_tokenizer.encode(input_text, return_tensors='pt').to(self.device)\n",
    "        \n",
    "        # Generate answer with improved parameters\n",
    "        self.t5_model.eval()\n",
    "        with torch.no_grad():\n",
    "            output_ids = self.t5_model.generate(\n",
    "                input_ids,\n",
    "                max_length=max_length,\n",
    "                num_beams=5,             # Increased from 4\n",
    "                length_penalty=1.0,      # Encourage slightly longer outputs\n",
    "                no_repeat_ngram_size=2,  # Avoid repetition\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            # Decode the output\n",
    "            answer = self.t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "            \n",
    "            return {\n",
    "                'answer': answer,\n",
    "                'model': 't5'\n",
    "            }\n",
    "    \n",
    "    def get_best_answer(self, question, contexts, min_confidence=0.6):\n",
    "        \"\"\"\n",
    "        Get the best answer using both extractive and generative approaches\n",
    "        \n",
    "        Args:\n",
    "            question (str): User question\n",
    "            contexts (list): List of retrieved passages\n",
    "            min_confidence (float): Minimum confidence for extractive answers\n",
    "            \n",
    "        Returns:\n",
    "            dict: Best answer with metadata\n",
    "        \"\"\"\n",
    "        if not contexts:\n",
    "            return {\n",
    "                'answer': None,\n",
    "                'message': 'No contexts provided',\n",
    "                'method': None\n",
    "            }\n",
    "        \n",
    "        extractive_results = []\n",
    "        \n",
    "        # Try extractive approach on each context\n",
    "        for context in contexts:\n",
    "            result = self.extract_answer(question, context, min_confidence)\n",
    "            if result['answer']:\n",
    "                extractive_results.append({\n",
    "                    'answer': result['answer'],\n",
    "                    'confidence': result['confidence'],\n",
    "                    'context': context\n",
    "                })\n",
    "        \n",
    "        # Sort extractive results by confidence\n",
    "        extractive_results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        # If we have good extractive answers, return the best one\n",
    "        if extractive_results and extractive_results[0]['confidence'] >= min_confidence:\n",
    "            return {\n",
    "                'answer': extractive_results[0]['answer'],\n",
    "                'confidence': extractive_results[0]['confidence'],\n",
    "                'context': extractive_results[0]['context'],\n",
    "                'method': 'extractive'\n",
    "            }\n",
    "        \n",
    "        # No good extractive answer, try generative approach\n",
    "        # Combine contexts for better context\n",
    "        combined_context = \" \".join(contexts[:3])  # Use top 3 contexts\n",
    "        \n",
    "        generative_result = self.generate_answer(question, combined_context)\n",
    "        \n",
    "        if generative_result['answer']:\n",
    "            return {\n",
    "                'answer': generative_result['answer'],\n",
    "                'method': 'generative',\n",
    "                'context': combined_context\n",
    "            }\n",
    "        \n",
    "        # No good answer from either method\n",
    "        return {\n",
    "            'answer': None,\n",
    "            'message': 'Failed to find or generate answer',\n",
    "            'method': None\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Dict, List, Tuple, Any, Optional, Union\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import json\n",
    "import re\n",
    " \n",
    "class AnswerRankingSelector:\n",
    "    def __init__(self, sentence_model_name: str = 'paraphrase-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize the Answer Ranking & Selection Component\n",
    "        \n",
    "        Args:\n",
    "            sentence_model_name: Name of the SentenceTransformer model to use for embedding\n",
    "        \"\"\"\n",
    "        self.sentence_model = SentenceTransformer(sentence_model_name)\n",
    "        \n",
    "    def calculate_semantic_similarity(self, question: str, answers: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate semantic similarity between a question and multiple answers\n",
    "        \n",
    "        Args:\n",
    "            question: The user's question\n",
    "            answers: List of candidate answers\n",
    "            \n",
    "        Returns:\n",
    "            Array of similarity scores\n",
    "        \"\"\"\n",
    "        # Encode question and answers\n",
    "        question_embedding = self.sentence_model.encode([question])[0]\n",
    "        answer_embeddings = self.sentence_model.encode(answers)\n",
    "        \n",
    "        # Calculate cosine similarities\n",
    "        similarities = cosine_similarity([question_embedding], answer_embeddings)[0]\n",
    "        \n",
    "        return similarities\n",
    "    \n",
    "    def calculate_contextual_relevance(self, \n",
    "                                       question: str, \n",
    "                                       answers: List[str], \n",
    "                                       legal_contexts: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Calculate how well each answer aligns with its legal context\n",
    "        \n",
    "        Args:\n",
    "            question: The user's question\n",
    "            answers: List of candidate answers\n",
    "            legal_contexts: Corresponding legal passages for each answer\n",
    "            \n",
    "        Returns:\n",
    "            Array of relevance scores\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        \n",
    "        for answer, context in zip(answers, legal_contexts):\n",
    "            # Calculate alignment between answer and context\n",
    "            answer_embedding = self.sentence_model.encode([answer])[0]\n",
    "            context_embedding = self.sentence_model.encode([context])[0]\n",
    "            alignment_score = cosine_similarity([answer_embedding], [context_embedding])[0][0]\n",
    "            \n",
    "            # Check factual consistency (simple check for legal citations)\n",
    "            factual_consistency = 0.0\n",
    "            \n",
    "            # Look for section numbers, articles, acts mentioned in both\n",
    "            context_refs = set(re.findall(r'section\\s+\\d+|article\\s+\\d+|\\w+\\s+act', context.lower()))\n",
    "            answer_refs = set(re.findall(r'section\\s+\\d+|article\\s+\\d+|\\w+\\s+act', answer.lower()))\n",
    "            \n",
    "            # Calculate Jaccard similarity between references\n",
    "            if context_refs or answer_refs:\n",
    "                intersection = len(context_refs.intersection(answer_refs))\n",
    "                union = len(context_refs.union(answer_refs))\n",
    "                if union > 0:\n",
    "                    factual_consistency = intersection / union\n",
    "            \n",
    "            # Combined relevance score\n",
    "            relevance = 0.7 * alignment_score + 0.3 * factual_consistency\n",
    "            scores.append(relevance)\n",
    "            \n",
    "        return np.array(scores)\n",
    "    \n",
    "    def calculate_answer_quality(self, answers: List[str]) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Evaluate the quality of answers based on multiple factors\n",
    "        \n",
    "        Args:\n",
    "            answers: List of candidate answers\n",
    "            \n",
    "        Returns:\n",
    "            Array of quality scores\n",
    "        \"\"\"\n",
    "        quality_scores = []\n",
    "        \n",
    "        for answer in answers:\n",
    "            # Reward informative answers (approximated by length)\n",
    "            length_score = min(len(answer.split()) / 100, 1.0)\n",
    "            \n",
    "            # Reward structured answers with legal citations\n",
    "            citation_score = 0.0\n",
    "            if re.search(r'section\\s+\\d+|article\\s+\\d+|\\w+\\s+act', answer.lower()):\n",
    "                citation_score = 0.5\n",
    "                \n",
    "            # Reward answers with clear organization\n",
    "            structure_score = 0.0\n",
    "            if re.search(r'firstly|secondly|finally|however|therefore|accordingly', answer.lower()):\n",
    "                structure_score = 0.3\n",
    "                \n",
    "            # Check for coherence (simplistic approach - could be improved)\n",
    "            coherence_score = 0.5  # Default medium score\n",
    "            \n",
    "            # Combined quality score\n",
    "            quality = (0.3 * length_score + \n",
    "                       0.3 * citation_score + \n",
    "                       0.2 * structure_score + \n",
    "                       0.2 * coherence_score)\n",
    "            \n",
    "            quality_scores.append(quality)\n",
    "            \n",
    "        return np.array(quality_scores)\n",
    "    \n",
    "    def calculate_confidence_scores(self, \n",
    "                                    question: str, \n",
    "                                    question_type: str,\n",
    "                                    bayesian_probs: Dict[str, float],\n",
    "                                    answers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Calculate confidence scores for each answer using a hybrid approach\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            question_type: Classified question type\n",
    "            bayesian_probs: Probabilities from Bayesian classifier\n",
    "            answers: List of answer candidates with metadata\n",
    "            \n",
    "        Returns:\n",
    "            List of answers with added confidence scores\n",
    "        \"\"\"\n",
    "        # Extract answer texts and sources\n",
    "        answer_texts = [a['text'] for a in answers]\n",
    "        answer_sources = [a.get('source', 'unknown') for a in answers]\n",
    "        contexts = [a.get('context', '') for a in answers]\n",
    "        \n",
    "        # Calculate different score components\n",
    "        semantic_scores = self.calculate_semantic_similarity(question, answer_texts)\n",
    "        quality_scores = self.calculate_answer_quality(answer_texts)\n",
    "        \n",
    "        # Only calculate contextual relevance if contexts available\n",
    "        if all(c != '' for c in contexts):\n",
    "            relevance_scores = self.calculate_contextual_relevance(question, answer_texts, contexts)\n",
    "        else:\n",
    "            relevance_scores = np.ones_like(semantic_scores) * 0.5  # neutral score\n",
    "        \n",
    "        # Combine scores with weights\n",
    "        results = []\n",
    "        for i, answer in enumerate(answers):\n",
    "            # Base confidence from semantic similarity\n",
    "            confidence = 0.4 * semantic_scores[i]\n",
    "            \n",
    "            # Add quality component\n",
    "            confidence += 0.25 * quality_scores[i]\n",
    "            \n",
    "            # Add relevance component\n",
    "            confidence += 0.25 * relevance_scores[i]\n",
    "            \n",
    "            # Add source-specific boost\n",
    "            source_boost = 0.0\n",
    "            \n",
    "            if answer_sources[i] == 'extractive':\n",
    "                # Boost extractive answers for fact-based questions\n",
    "                if question_type in ['FACTUAL', 'LEGAL_PROVISION', 'RIGHTS']:\n",
    "                    source_boost = 0.1\n",
    "            elif answer_sources[i] == 'generative':\n",
    "                # Boost generative answers for complex questions\n",
    "                if question_type in ['COMPARISON', 'CONSEQUENCE', 'PROCEDURE']:\n",
    "                    source_boost = 0.1\n",
    "            \n",
    "            confidence += source_boost\n",
    "            \n",
    "            # Optional: Use Bayesian probability as an additional factor\n",
    "            if bayesian_probs and question_type in bayesian_probs:\n",
    "                # Slight confidence boost if question type is highly certain\n",
    "                confidence += 0.1 * bayesian_probs[question_type]\n",
    "            \n",
    "            # Clip confidence to [0, 1] range\n",
    "            confidence = min(max(confidence, 0.0), 1.0)\n",
    "            \n",
    "            # Add to results\n",
    "            results.append({\n",
    "                **answer,\n",
    "                'confidence': confidence,\n",
    "                'semantic_score': float(semantic_scores[i]),\n",
    "                'quality_score': float(quality_scores[i]),\n",
    "                'relevance_score': float(relevance_scores[i]),\n",
    "                'source_boost': source_boost\n",
    "            })\n",
    "        \n",
    "        # Sort by confidence (descending)\n",
    "        results.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def tanimoto_similarity(self, question: str, retrieved_question: str) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Tanimoto similarity between two questions\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            retrieved_question: Similar question from database\n",
    "            \n",
    "        Returns:\n",
    "            Tanimoto similarity score\n",
    "        \"\"\"\n",
    "        # Tokenize questions (simple approach)\n",
    "        q1_tokens = set(question.lower().split())\n",
    "        q2_tokens = set(retrieved_question.lower().split())\n",
    "        \n",
    "        # Calculate intersection and union\n",
    "        intersection = len(q1_tokens.intersection(q2_tokens))\n",
    "        union = len(q1_tokens.union(q2_tokens))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if union == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return intersection / union\n",
    "    \n",
    "    def rank_answers(self, \n",
    "                     question: str,\n",
    "                     question_type: str,\n",
    "                     bayesian_probs: Dict[str, float],\n",
    "                     candidate_answers: List[Dict[str, Any]],\n",
    "                     extractive_threshold: float = 0.75) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Rank answers and select the best one based on confidence scores\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            question_type: Classified question type\n",
    "            bayesian_probs: Probabilities from Bayesian classifier\n",
    "            candidate_answers: List of candidate answers (extractive and generative)\n",
    "            extractive_threshold: Threshold for choosing extractive over generative\n",
    "            \n",
    "        Returns:\n",
    "            Selected answer with metadata\n",
    "        \"\"\"\n",
    "        # Calculate confidence scores for all answers\n",
    "        ranked_answers = self.calculate_confidence_scores(\n",
    "            question, question_type, bayesian_probs, candidate_answers\n",
    "        )\n",
    "        \n",
    "        # Categorize answers by type\n",
    "        extractive_answers = [a for a in ranked_answers if a.get('source') == 'extractive']\n",
    "        generative_answers = [a for a in ranked_answers if a.get('source') == 'generative']\n",
    "        similarity_answers = [a for a in ranked_answers if a.get('source') == 'similarity']\n",
    "        \n",
    "        # Logic for selecting the best answer\n",
    "        best_answer = None\n",
    "        answer_source = None\n",
    "        \n",
    "        # First check if we have a high-confidence similar question match\n",
    "        if similarity_answers:\n",
    "            best_similar = max(similarity_answers, key=lambda x: x.get('confidence', 0))\n",
    "            tanimoto_score = self.tanimoto_similarity(question, best_similar.get('question', ''))\n",
    "            \n",
    "            # If the similarity is high enough, use this answer\n",
    "            if tanimoto_score >= 0.8:\n",
    "                best_answer = best_similar\n",
    "                answer_source = 'similarity'\n",
    "        \n",
    "        # If no similar question match, check extractive vs generative\n",
    "        if best_answer is None:\n",
    "            # Get best extractive and generative answers if available\n",
    "            best_extractive = max(extractive_answers, key=lambda x: x.get('confidence', 0)) if extractive_answers else None\n",
    "            best_generative = max(generative_answers, key=lambda x: x.get('confidence', 0)) if generative_answers else None\n",
    "            \n",
    "            # Compare extractive vs generative\n",
    "            if best_extractive and best_generative:\n",
    "                # If extractive confidence exceeds threshold, prefer it\n",
    "                if best_extractive['confidence'] >= extractive_threshold:\n",
    "                    best_answer = best_extractive\n",
    "                    answer_source = 'extractive'\n",
    "                else:\n",
    "                    # Otherwise use the generative answer\n",
    "                    best_answer = best_generative\n",
    "                    answer_source = 'generative'\n",
    "            elif best_extractive:\n",
    "                best_answer = best_extractive\n",
    "                answer_source = 'extractive'\n",
    "            elif best_generative:\n",
    "                best_answer = best_generative\n",
    "                answer_source = 'generative'\n",
    "        \n",
    "        # If we couldn't find any answer, use the highest confidence one\n",
    "        if best_answer is None and ranked_answers:\n",
    "            best_answer = ranked_answers[0]\n",
    "            answer_source = best_answer.get('source', 'unknown')\n",
    "        \n",
    "        # Prepare final result\n",
    "        if best_answer:\n",
    "            result = {\n",
    "                'selected_answer': best_answer['text'],\n",
    "                'confidence': best_answer['confidence'],\n",
    "                'source': answer_source,\n",
    "                'question_type': question_type,\n",
    "                'answer_metadata': best_answer,\n",
    "                'all_candidates': ranked_answers[:3]  # Top 3 alternatives\n",
    "            }\n",
    "        else:\n",
    "            # No answer found\n",
    "            result = {\n",
    "                'selected_answer': \"I could not find a suitable answer to your question.\",\n",
    "                'confidence': 0.0,\n",
    "                'source': None,\n",
    "                'question_type': question_type,\n",
    "                'all_candidates': []\n",
    "            }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def explain_answer_selection(self, ranking_result: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Generate an explanation of how the answer was selected\n",
    "        \n",
    "        Args:\n",
    "            ranking_result: Result from rank_answers method\n",
    "            \n",
    "        Returns:\n",
    "            Explanation text\n",
    "        \"\"\"\n",
    "        answer = ranking_result.get('selected_answer', '')\n",
    "        confidence = ranking_result.get('confidence', 0.0)\n",
    "        source = ranking_result.get('source', None)\n",
    "        question_type = ranking_result.get('question_type', '')\n",
    "        \n",
    "        explanation = []\n",
    "        \n",
    "        # Explain the source of the answer\n",
    "        if source == 'similarity':\n",
    "            explanation.append(\"This answer is based on a very similar question found in our legal database.\")\n",
    "        elif source == 'extractive':\n",
    "            explanation.append(\"This answer is extracted directly from relevant legal texts.\")\n",
    "        elif source == 'generative':\n",
    "            explanation.append(\"This answer is synthesized from multiple legal sources.\")\n",
    "        \n",
    "        # Explain confidence\n",
    "        if confidence >= 0.8:\n",
    "            explanation.append(\"The system has high confidence in this answer.\")\n",
    "        elif confidence >= 0.6:\n",
    "            explanation.append(\"The system has moderate confidence in this answer.\")\n",
    "        else:\n",
    "            explanation.append(\"The system has low confidence in this answer. Consider consulting a legal professional for more accurate information.\")\n",
    "        \n",
    "        # Mention question type if useful\n",
    "        if question_type in ['LEGAL_PROVISION', 'RIGHTS', 'PROCEDURE']:\n",
    "            type_explanations = {\n",
    "                'LEGAL_PROVISION': \"Your question is about specific legal provisions.\",\n",
    "                'RIGHTS': \"Your question is about legal rights.\",\n",
    "                'PROCEDURE': \"Your question is about legal procedures.\",\n",
    "            }\n",
    "            explanation.append(type_explanations.get(question_type))\n",
    "        \n",
    "        return \" \".join(explanation)\n",
    "    \n",
    "    def save_ranking(self, output_path: str, ranking_data: Dict[str, Any]):\n",
    "        \"\"\"\n",
    "        Save ranking data to disk for analysis\n",
    "        \n",
    "        Args:\n",
    "            output_path: Path to save data\n",
    "            ranking_data: Data to save\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(ranking_data, f, indent=2)\n",
    "                \n",
    "            print(f\"Ranking data saved to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving ranking data: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\tarus\\AppData\\Local\\Temp\\ipykernel_17340\\2338637581.py:6: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  'constitution': 'archive\\constitution_qa.json',\n",
      "C:\\Users\\tarus\\AppData\\Local\\Temp\\ipykernel_17340\\2338637581.py:7: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  'crpc': 'archive\\crpc_qa.json',\n",
      "C:\\Users\\tarus\\AppData\\Local\\Temp\\ipykernel_17340\\2338637581.py:8: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  'ipc': 'archive\\ipc_qa.json'\n",
      "c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 4082 QA pairs from constitution\n",
      "Successfully loaded 8194 QA pairs from crpc\n",
      "Successfully loaded 2267 QA pairs from ipc\n",
      "Combined dataset contains 14543 QA pairs\n",
      "Generating embeddings for questions...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca689cc8c124941b09f6bee4197c01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for answers...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49907f8138c648ee9d2301ee4e01ad51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data saved to legal_qa_processed.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize preprocessor\n",
    "preprocessor = DataPreprocessor()\n",
    " \n",
    "# Load datasets\n",
    "file_paths = {\n",
    "    'constitution': 'archive\\constitution_qa.json',\n",
    "    'crpc': 'archive\\crpc_qa.json',\n",
    "    'ipc': 'archive\\ipc_qa.json'\n",
    "}\n",
    "qa_data = preprocessor.load_dataset(file_paths)\n",
    " \n",
    "# Preprocess data\n",
    "processed_data = preprocessor.preprocess_dataset(qa_data)\n",
    " \n",
    "# Generate embeddings\n",
    "embeddings = preprocessor.generate_embeddings()\n",
    " \n",
    "# Build TF-IDF index\n",
    "tfidf_index = preprocessor.build_tfidf_index()\n",
    " \n",
    "# Build BM25 index\n",
    "bm25_index = preprocessor.build_bm25_index()\n",
    " \n",
    "# Save processed data\n",
    "preprocessor.save_processed_data('legal_qa_processed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing labels found. Generating synthetic labels for training...\n",
      "Generated 14543 labels for training. Distribution:\n",
      "FACTUAL            4197\n",
      "DEFINITION         4093\n",
      "LEGAL_PROVISION    3404\n",
      "CONSEQUENCE        1507\n",
      "JURISDICTION        596\n",
      "RIGHTS              196\n",
      "EXCEPTION           183\n",
      "PROCEDURE           169\n",
      "TIMEFRAME           155\n",
      "COMPARISON           43\n",
      "Name: count, dtype: int64\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "     COMPARISON       0.00      0.00      0.00         6\n",
      "    CONSEQUENCE       0.62      0.83      0.71       298\n",
      "     DEFINITION       0.68      0.60      0.64       797\n",
      "      EXCEPTION       1.00      0.14      0.24        29\n",
      "        FACTUAL       0.55      0.59      0.57       874\n",
      "   JURISDICTION       0.51      0.28      0.36       130\n",
      "LEGAL_PROVISION       0.67      0.77      0.71       670\n",
      "      PROCEDURE       0.00      0.00      0.00        37\n",
      "         RIGHTS       0.50      0.16      0.24        31\n",
      "      TIMEFRAME       0.43      0.08      0.14        37\n",
      "\n",
      "       accuracy                           0.62      2909\n",
      "      macro avg       0.50      0.34      0.36      2909\n",
      "   weighted avg       0.61      0.62      0.61      2909\n",
      "\n",
      "Classifier saved to question_classifier.pkl\n",
      "Question: What is the definition of culpable homicide?\n",
      "Classification: DEFINITION (Confidence: 0.97)\n",
      "---\n",
      "Question: How do I file a bail application?\n",
      "Classification: FACTUAL (Confidence: 0.35)\n",
      "---\n",
      "Question: Under which section is robbery defined in IPC?\n",
      "Classification: LEGAL_PROVISION (Confidence: 0.60)\n",
      "---\n",
      "Question: What are the fundamental rights in the Indian Constitution?\n",
      "Classification: LEGAL_PROVISION (Confidence: 0.40)\n",
      "---\n",
      "Question: What are the exceptions to the rule of strict liability?\n",
      "Classification: EXCEPTION (Confidence: 0.66)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier\n",
    "classifier = QuestionClassifier()\n",
    " \n",
    "# Load processed data and prepare for training\n",
    "X, y = classifier.prepare_training_data('legal_qa_processed.json')\n",
    " \n",
    "# Train the classifier\n",
    "classifier.train_classifier(X, y)\n",
    " \n",
    "# Save the trained classifier\n",
    "classifier.save_classifier('question_classifier.pkl')\n",
    " \n",
    "# Test classification\n",
    "test_questions = [\n",
    "    \"What is the definition of culpable homicide?\",\n",
    "    \"How do I file a bail application?\",\n",
    "    \"Under which section is robbery defined in IPC?\",\n",
    "    \"What are the fundamental rights in the Indian Constitution?\",\n",
    "    \"What are the exceptions to the rule of strict liability?\"\n",
    "]\n",
    " \n",
    "for question in test_questions:\n",
    "    result = classifier.classify_question(question)\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Classification: {result['question_type']} (Confidence: {result['confidence']:.2f})\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Loaded embeddings from legal_qa_processed.json_embeddings.npy\n",
      "Classifier loaded from question_classifier.pkl\n",
      "\n",
      "Question: What is the definition of culpable homicide?\n",
      "Classification: DEFINITION (Confidence: 0.97)\n",
      "No match in history, searching dataset...\n",
      "Answer found from database with similarity 0.94\n",
      "Similar question: What is culpable homicide?\n",
      "Answer: Culpable homicide is where someone causes death by doing an act with the intention of causing death, or with the intention of causing such bodily injury as is likely to cause death, or with the knowledge that he is likely by such act to cause death.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: How do I file a bail application?\n",
      "Classification: FACTUAL (Confidence: 0.35)\n",
      "No match in history, searching dataset...\n",
      "Answer found from database with similarity 0.72\n",
      "Similar question: Who can file an application for the cancellation of the bail if a person is released on it?\n",
      "Answer: The Public Prosecutor can file an application for the cancellation of the bail.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: What are the rights of an arrested person in India?\n",
      "Classification: FACTUAL (Confidence: 0.48)\n",
      "No match in history, searching dataset...\n",
      "Answer found from database with similarity 0.74\n",
      "Similar question: What would make someone liable to be apprehended or detained in custody in India?\n",
      "Answer: If a reasonable suspicion exists that they have been involved in any act committed at any place out of India which, if committed in India, would have been punishable as an offence. They are also liable if they are a released convict who commits a breach of any rule made under sub-section (5) of section 356.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: Can a minor be tried as an adult?\n",
      "Classification: DEFINITION (Confidence: 0.29)\n",
      "No match in history, searching dataset...\n",
      "Answer found from database with similarity 0.60\n",
      "Similar question: At what age does a male and female stop being considered a minor?\n",
      "Answer: A male stops being considered a minor at sixteen years of age, and a female at eighteen years of age.\n",
      "--------------------------------------------------\n",
      "\n",
      "Question: What is the punishment for robbery under IPC?\n",
      "Classification: CONSEQUENCE (Confidence: 0.65)\n",
      "No match in history, searching dataset...\n",
      "Answer found from database with similarity 0.69\n",
      "Similar question: Under which section of the Indian Penal Code is robbery punishable?\n",
      "Answer: Section 392\n",
      "--------------------------------------------------\n",
      "Question history saved to question_history.pkl\n"
     ]
    }
   ],
   "source": [
    "# Initialize retrieval system\n",
    "retrieval_system = QuestionRetrievalSystem(use_sentence_transformer=True)\n",
    " \n",
    "# Load processed data and embeddings\n",
    "retrieval_system.load_processed_data(\n",
    "    'legal_qa_processed.json',\n",
    "    'legal_qa_processed.json_embeddings.npy'\n",
    ")\n",
    " \n",
    "# Load question classifier (from previous component)\n",
    "#from question_classifier import QuestionClassifier\n",
    "classifier = QuestionClassifier()\n",
    "classifier.load_classifier('question_classifier.pkl')\n",
    " \n",
    "# Test retrieval\n",
    "test_questions = [\n",
    "    \"What is the definition of culpable homicide?\",\n",
    "    \"How do I file a bail application?\",\n",
    "    \"What are the rights of an arrested person in India?\",\n",
    "    \"Can a minor be tried as an adult?\",\n",
    "    \"What is the punishment for robbery under IPC?\"\n",
    "]\n",
    " \n",
    "for question in test_questions:\n",
    "    # Classify the question\n",
    "    classification = classifier.classify_question(question)\n",
    "    question_type = classification['question_type']\n",
    "    \n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Classification: {question_type} (Confidence: {classification['confidence']:.2f})\")\n",
    "    \n",
    "    # Retrieve answer\n",
    "    result = retrieval_system.retrieve_answer(question, question_type)\n",
    "    \n",
    "    if result['source']:\n",
    "        print(f\"Answer found from {result['source']} with similarity {result['similarity']:.2f}\")\n",
    "        print(f\"Similar question: {result['question']}\")\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "    else:\n",
    "        print(\"No similar question found. Proceeding to context retrieval...\")\n",
    "        \n",
    "    print(\"-\" * 50)\n",
    " \n",
    "# Save question history\n",
    "retrieval_system.save_history('question_history.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized Context Retriever with model paraphrase-MiniLM-L6-v2 on cuda\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Prepared 14543 context passages for retrieval\n",
      "BM25 index built successfully\n",
      "Computing passage embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30ab139658f4223805aea903dddf7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/455 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed embeddings for 14543 passages\n",
      "Indices saved to legal_qa_retrieval_indices_bm25.pkl and legal_qa_retrieval_indices_embeddings.npy\n",
      "Classifier loaded from question_classifier.pkl\n",
      "\n",
      "Query: What is the definition of culpable homicide?\n",
      "Classification: DEFINITION\n",
      "\n",
      "BM25 Results:\n",
      "1. Score: 17.7761\n",
      "   Question: What is the expected consequence of attempting to commit culpable homicide?\n",
      "   Answer: The expected consequence of attempting to commit culpable homicide is imprisonment....\n",
      "2. Score: 17.7761\n",
      "   Question: Who is guilty of culpable homicide in the case where A attacks Z under grave provocation and B assists A?\n",
      "   Answer: A is guilty of culpable homicide....\n",
      "3. Score: 17.7761\n",
      "   Question: What is the potential punishment for attempting to commit culpable homicide?\n",
      "   Answer: The potential punishment for attempting to commit culpable homicide is imprisonment....\n",
      "\n",
      "DPR Results:\n",
      "1. Score: 0.8482\n",
      "   Question: What is defined by Section 299?\n",
      "   Answer: Culpable homicide...\n",
      "2. Score: 0.8121\n",
      "   Question: Which section defines culpable homicide?\n",
      "   Answer: Section 299...\n",
      "3. Score: 0.7933\n",
      "   Question: Can culpable homicide be considered as murder if it is committed by a public servant in the advancement of public justice?\n",
      "   Answer: No...\n",
      "\n",
      "Hybrid Results:\n",
      "1. BM25: 0.9424, DPR: 1.0000, Combined: 0.9827\n",
      "   Question: What is defined by Section 299?\n",
      "   Answer: Culpable homicide...\n",
      "2. BM25: 0.9095, DPR: 0.9574, Combined: 0.9430\n",
      "   Question: Which section defines culpable homicide?\n",
      "   Answer: Section 299...\n",
      "3. BM25: 0.0000, DPR: 0.9352, Combined: 0.6547\n",
      "   Question: Can culpable homicide be considered as murder if it is committed by a public servant in the advancement of public justice?\n",
      "   Answer: No...\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: How do I file a bail application?\n",
      "Classification: FACTUAL\n",
      "\n",
      "BM25 Results:\n",
      "1. Score: 21.3463\n",
      "   Question: Who can file an application for the cancellation of the bail if a person is released on it?\n",
      "   Answer: The Public Prosecutor can file an application for the cancellation of the bail....\n",
      "2. Score: 18.3928\n",
      "   Question: What can be done if a person is released on bail?\n",
      "   Answer: The Public Prosecutor can file an application for the cancellation of the bail....\n",
      "3. Score: 13.0500\n",
      "   Question: What will the Court do if it finds that the application was filed involuntarily by the accused or he has been previously convicted for the same offence, under sub-section (1)?\n",
      "   Answer: The Court shall proceed further in accordance with the provisions of this Code from the stage such a...\n",
      "\n",
      "DPR Results:\n",
      "1. Score: 0.7191\n",
      "   Question: What can be done if a person is released on bail?\n",
      "   Answer: The Public Prosecutor can file an application for the cancellation of the bail....\n",
      "2. Score: 0.6859\n",
      "   Question: Who can file an application for the cancellation of the bail if a person is released on it?\n",
      "   Answer: The Public Prosecutor can file an application for the cancellation of the bail....\n",
      "3. Score: 0.5975\n",
      "   Question: In what cases is bail to be taken?\n",
      "   Answer: 436...\n",
      "\n",
      "Hybrid Results:\n",
      "1. BM25: 1.0000, DPR: 0.9538, Combined: 0.9769\n",
      "   Question: Who can file an application for the cancellation of the bail if a person is released on it?\n",
      "   Answer: The Public Prosecutor can file an application for the cancellation of the bail....\n",
      "2. BM25: 0.8616, DPR: 1.0000, Combined: 0.9308\n",
      "   Question: What can be done if a person is released on bail?\n",
      "   Answer: The Public Prosecutor can file an application for the cancellation of the bail....\n",
      "3. BM25: 0.0000, DPR: 0.8309, Combined: 0.4155\n",
      "   Question: In what cases is bail to be taken?\n",
      "   Answer: 436...\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What are the rights of an arrested person in India?\n",
      "Classification: FACTUAL\n",
      "\n",
      "BM25 Results:\n",
      "1. Score: 13.3592\n",
      "   Question: Who should the officer inform about their rights if the memorandum is attested by a member of the arrested person's family?\n",
      "   Answer: The officer should inform the person arrested that he has a right to have....\n",
      "2. Score: 13.2773\n",
      "   Question: What rights are informed to a person arrested as per section 50?\n",
      "   Answer: According to section 50, a person arrested must be informed of the grounds of their arrest and of th...\n",
      "3. Score: 12.5134\n",
      "   Question: What rights does a person have when arrested or detained, including the duration of detention without a magistrate's authority?\n",
      "   Answer: When arrested or detained, a person has the right to be informed of the grounds for arrest, the righ...\n",
      "\n",
      "DPR Results:\n",
      "1. Score: 0.6995\n",
      "   Question: What would make someone liable to be apprehended or detained in custody in India?\n",
      "   Answer: If a reasonable suspicion exists that they have been involved in any act committed at any place out ...\n",
      "2. Score: 0.6738\n",
      "   Question: Which section of the Indian Penal Code pertains to compensation to persons groundlessly arrested?\n",
      "   Answer: Section 358...\n",
      "3. Score: 0.6696\n",
      "   Question: What are the conditions under which the Indian Penal Code allows a person accused or suspected of an offence to be released on bail according to sub-section (1)?\n",
      "   Answer: The accused or suspected person can be released on bail under sub-section (1) if the offence is puni...\n",
      "\n",
      "Hybrid Results:\n",
      "1. BM25: 1.0000, DPR: 0.0000, Combined: 0.5000\n",
      "   Question: Who should the officer inform about their rights if the memorandum is attested by a member of the arrested person's family?\n",
      "   Answer: The officer should inform the person arrested that he has a right to have....\n",
      "2. BM25: 0.0000, DPR: 1.0000, Combined: 0.5000\n",
      "   Question: What would make someone liable to be apprehended or detained in custody in India?\n",
      "   Answer: If a reasonable suspicion exists that they have been involved in any act committed at any place out ...\n",
      "3. BM25: 0.9939, DPR: 0.0000, Combined: 0.4969\n",
      "   Question: What rights are informed to a person arrested as per section 50?\n",
      "   Answer: According to section 50, a person arrested must be informed of the grounds of their arrest and of th...\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What is Section 302 of IPC?\n",
      "Classification: LEGAL_PROVISION\n",
      "\n",
      "BM25 Results:\n",
      "1. Score: 11.7822\n",
      "   Question: Which section of the Indian Penal Code is murder punishable under?\n",
      "   Answer: Section 302...\n",
      "2. Score: 11.2527\n",
      "   Question: What offence is punishable under section 302 of the Indian Penal Code?\n",
      "   Answer: Murder...\n",
      "3. Score: 10.5181\n",
      "   Question: How is permission to conduct prosecution obtained?\n",
      "   Answer: 302...\n",
      "\n",
      "DPR Results:\n",
      "1. Score: 0.6094\n",
      "   Question: What does section 291A pertain to?\n",
      "   Answer: Section 291A pertains to the identification report of a Magistrate....\n",
      "2. Score: 0.6063\n",
      "   Question: What does section 290 pertain to?\n",
      "   Answer: Section 290 pertains to the execution of foreign commissions. It states that the provisions of secti...\n",
      "3. Score: 0.6016\n",
      "   Question: What does section 233 entail?\n",
      "   Answer: Section 233 is about entering upon defence....\n",
      "\n",
      "Hybrid Results:\n",
      "1. BM25: 1.0000, DPR: 0.0000, Combined: 0.7000\n",
      "   Question: Which section of the Indian Penal Code is murder punishable under?\n",
      "   Answer: Section 302...\n",
      "2. BM25: 0.9551, DPR: 0.0000, Combined: 0.6685\n",
      "   Question: What offence is punishable under section 302 of the Indian Penal Code?\n",
      "   Answer: Murder...\n",
      "3. BM25: 0.8927, DPR: 0.0000, Combined: 0.6249\n",
      "   Question: How is permission to conduct prosecution obtained?\n",
      "   Answer: 302...\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: What is the punishment for robbery under IPC?\n",
      "Classification: CONSEQUENCE\n",
      "\n",
      "BM25 Results:\n",
      "1. Score: 11.0636\n",
      "   Question: Under which section of the Indian Penal Code is robbery punishable?\n",
      "   Answer: Section 392...\n",
      "2. Score: 11.0636\n",
      "   Question: What offense is punishable under section 392 of the Indian Penal Code?\n",
      "   Answer: Robbery...\n",
      "3. Score: 10.4484\n",
      "   Question: What is the definition of robbery according to this text?\n",
      "   Answer: The text does not provide a specific definition of robbery....\n",
      "\n",
      "DPR Results:\n",
      "1. Score: 0.6707\n",
      "   Question: What is the punishment for harbouring robbers or dacoits?\n",
      "   Answer: Rigorous imprisonment for 7 years and fine....\n",
      "2. Score: 0.6568\n",
      "   Question: What is the punishment when the valuable security is a promissory note of the Central Government?\n",
      "   Answer: Imprisonment for 7 years and fine....\n",
      "3. Score: 0.6464\n",
      "   Question: What offense is punishable under section 392 of the Indian Penal Code?\n",
      "   Answer: Robbery...\n",
      "\n",
      "Hybrid Results:\n",
      "1. BM25: 1.0000, DPR: 0.9637, Combined: 0.9819\n",
      "   Question: What offense is punishable under section 392 of the Indian Penal Code?\n",
      "   Answer: Robbery...\n",
      "2. BM25: 1.0000, DPR: 0.9567, Combined: 0.9783\n",
      "   Question: Under which section of the Indian Penal Code is robbery punishable?\n",
      "   Answer: Section 392...\n",
      "3. BM25: 0.0000, DPR: 1.0000, Combined: 0.5000\n",
      "   Question: What is the punishment for harbouring robbers or dacoits?\n",
      "   Answer: Rigorous imprisonment for 7 years and fine....\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize context retriever\n",
    "retriever = ContextRetriever(use_gpu=True)\n",
    " \n",
    "# Load processed data\n",
    "retriever.load_processed_data('legal_qa_processed.json')\n",
    " \n",
    "# Build indices\n",
    "retriever.build_bm25_index()\n",
    "retriever.compute_passage_embeddings()\n",
    " \n",
    "# Save indices for future use\n",
    "retriever.save_indices('legal_qa_retrieval_indices')\n",
    " \n",
    "# Test retrieval\n",
    "test_queries = [\n",
    "    \"What is the definition of culpable homicide?\",\n",
    "    \"How do I file a bail application?\",\n",
    "    \"What are the rights of an arrested person in India?\",\n",
    "    \"What is Section 302 of IPC?\",\n",
    "    \"What is the punishment for robbery under IPC?\"\n",
    "]\n",
    " \n",
    "# Load question classifier (from previous component)\n",
    "#from question_classifier import QuestionClassifier\n",
    "classifier = QuestionClassifier()\n",
    "classifier.load_classifier('question_classifier.pkl')\n",
    " \n",
    "for query in test_queries:\n",
    "    # Classify the question\n",
    "    classification = classifier.classify_question(query)\n",
    "    question_type = classification['question_type']\n",
    "    \n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    print(f\"Classification: {question_type}\")\n",
    "    \n",
    "    # Try different retrieval methods\n",
    "    print(\"\\nBM25 Results:\")\n",
    "    bm25_results = retriever.retrieve_with_bm25(query, top_k=3)\n",
    "    for i, result in enumerate(bm25_results):\n",
    "        print(f\"{i+1}. Score: {result['score']:.4f}\")\n",
    "        print(f\"   Question: {result['question']}\")\n",
    "        print(f\"   Answer: {result['answer'][:100]}...\")\n",
    "    \n",
    "    print(\"\\nDPR Results:\")\n",
    "    dpr_results = retriever.retrieve_with_dpr(query, top_k=3)\n",
    "    for i, result in enumerate(dpr_results):\n",
    "        print(f\"{i+1}. Score: {result['score']:.4f}\")\n",
    "        print(f\"   Question: {result['question']}\")\n",
    "        print(f\"   Answer: {result['answer'][:100]}...\")\n",
    "    \n",
    "    print(\"\\nHybrid Results:\")\n",
    "    hybrid_results = retriever.hybrid_retrieval(query, question_type, top_k=3)\n",
    "    for i, result in enumerate(hybrid_results):\n",
    "        print(f\"{i+1}. BM25: {result['bm25_score']:.4f}, DPR: {result['dpr_score']:.4f}, Combined: {result['combined_score']:.4f}\")\n",
    "        print(f\"   Question: {result['question']}\")\n",
    "        print(f\"   Answer: {result['answer'][:100]}...\")\n",
    "    \n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default T5 model...\n",
      "Prepared 11634 training samples and 2909 test samples\n",
      "Starting training: 3 epochs, 1455 steps per epoch\n",
      "Training on device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Train]: 100%|██████████| 1455/1455 [45:13<00:00,  1.86s/it, loss=142022.6094, avg_loss=78630.4539] \n",
      "Epoch 1/3 [Test]: 100%|██████████| 364/364 [10:18<00:00,  1.70s/it, loss=127149.5391, avg_loss=66261.6117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3 Summary:\n",
      "  Train Loss: 78630.4539\n",
      "  Test Loss: 66261.6117\n",
      "  Epoch Time: 0:55:31\n",
      "  Total Time: 0:55:31\n",
      "  Estimated Time Remaining: 1:51:02\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Train]: 100%|██████████| 1455/1455 [44:28<00:00,  1.83s/it, loss=47814.3750, avg_loss=65143.0148] \n",
      "Epoch 2/3 [Test]: 100%|██████████| 364/364 [10:19<00:00,  1.70s/it, loss=112840.0859, avg_loss=54931.6477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/3 Summary:\n",
      "  Train Loss: 65143.0148\n",
      "  Test Loss: 54931.6477\n",
      "  Epoch Time: 0:54:47\n",
      "  Total Time: 1:50:18\n",
      "  Estimated Time Remaining: 0:55:09\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Train]: 100%|██████████| 1455/1455 [50:19<00:00,  2.08s/it, loss=25117.7539, avg_loss=54611.2222] \n",
      "Epoch 3/3 [Test]: 100%|██████████| 364/364 [12:30<00:00,  2.06s/it, loss=100669.4453, avg_loss=45655.1334]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/3 Summary:\n",
      "  Train Loss: 54611.2222\n",
      "  Test Loss: 45655.1334\n",
      "  Epoch Time: 1:02:49\n",
      "  Total Time: 2:53:08\n",
      "--------------------------------------------------\n",
      "\n",
      "Training completed in 2:53:08\n",
      "Final Train Loss: 54611.2222\n",
      "Final Test Loss: 45655.1334\n",
      "Extractive model saved to extractive_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"\"\\n# Fine-tune T5 for answer generation\\nt5_model = answer_component.fine_tune_t5(\\n    train_loader, test_loader, num_epochs=2\\n)\\n \\n# Save generative model\\nanswer_component.save_generative_model(\\'generative_model\\')\\n\\n# Test with sample question and contexts\\nquestion = \"What are the fundamental rights in the Indian Constitution?\"\\ncontexts = [\\n    \"The Constitution of India provides six fundamental rights to Indian citizens. These are: Right to Equality, Right to Freedom, Right against Exploitation, Right to Freedom of Religion, Cultural and Educational Rights, and Right to Constitutional Remedies.\",\\n    \"Fundamental Rights is a charter of rights contained in the Constitution of India. It guarantees civil liberties such that all Indians can lead their lives in peace and harmony as citizens of India.\",\\n    \"The Fundamental Rights in India are contained in Part III of the Constitution from Articles 12 to 35.\"\\n]\\n \\n# Get best answer\\nresult = answer_component.get_best_answer(question, contexts)\\nprint(f\"Question: {question}\")\\nprint(f\"Answer: {result[\\'answer\\']}\")\\nprint(f\"Method: {result[\\'method\\']}\")\\nif \\'confidence\\' in result:\\n    print(f\"Confidence: {result[\\'confidence\\']:.2f}\")\\n '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Answer Extractor/Generator\n",
    "answer_component = AnswerExtractorGenerator()\n",
    " \n",
    "# Load processed data and prepare for training\n",
    "train_loader, test_loader = answer_component.prepare_training_data('legal_qa_processed.json')\n",
    " \n",
    "# Train extractive model\n",
    "extractive_model = answer_component.train_extractive_model(\n",
    "    train_loader, test_loader, num_epochs=3\n",
    ")\n",
    " \n",
    "# Save extractive model\n",
    "answer_component.save_extractive_model('extractive_model.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting T5 model re-training with increased epochs\n",
      "Using device: cuda\n",
      "Loading default T5 model...\n",
      "Prepared 11634 training samples and 2909 test samples\n",
      "Starting T5 fine-tuning: 10 epochs, 1455 steps per epoch\n",
      "Training on device: cuda\n",
      "Learning rate: 3e-05, Warmup steps: 1455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 1455/1455 [05:58<00:00,  4.06it/s, loss=3.2024, avg_loss=4.7264, lr=0.000030]\n",
      "Epoch 1/10 [Test]: 100%|██████████| 364/364 [00:33<00:00, 10.97it/s, loss=3.0526, avg_loss=3.3811]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_1_loss_3.3811\n",
      "\n",
      "Epoch 1/10 Summary:\n",
      "  Train Loss: 4.7264\n",
      "  Test Loss: 3.3811\n",
      "  Epoch Time: 0:06:31\n",
      "  Total Time: 0:06:31\n",
      "  Estimated Time Remaining: 0:58:46\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 1455/1455 [05:47<00:00,  4.19it/s, loss=3.4723, avg_loss=3.4556, lr=0.000027]\n",
      "Epoch 2/10 [Test]: 100%|██████████| 364/364 [00:31<00:00, 11.55it/s, loss=2.7346, avg_loss=3.1186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_2_loss_3.1186\n",
      "\n",
      "Epoch 2/10 Summary:\n",
      "  Train Loss: 3.4556\n",
      "  Test Loss: 3.1186\n",
      "  Epoch Time: 0:06:18\n",
      "  Total Time: 0:12:50\n",
      "  Estimated Time Remaining: 0:51:22\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 1455/1455 [05:43<00:00,  4.24it/s, loss=3.2527, avg_loss=3.2683, lr=0.000023]\n",
      "Epoch 3/10 [Test]: 100%|██████████| 364/364 [00:32<00:00, 11.10it/s, loss=2.5910, avg_loss=3.0016]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_3_loss_3.0016\n",
      "\n",
      "Epoch 3/10 Summary:\n",
      "  Train Loss: 3.2683\n",
      "  Test Loss: 3.0016\n",
      "  Epoch Time: 0:06:16\n",
      "  Total Time: 0:19:07\n",
      "  Estimated Time Remaining: 0:44:36\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 1455/1455 [05:51<00:00,  4.14it/s, loss=2.5587, avg_loss=3.1609, lr=0.000020]\n",
      "Epoch 4/10 [Test]: 100%|██████████| 364/364 [00:32<00:00, 11.03it/s, loss=2.4984, avg_loss=2.9144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_4_loss_2.9144\n",
      "\n",
      "Epoch 4/10 Summary:\n",
      "  Train Loss: 3.1609\n",
      "  Test Loss: 2.9144\n",
      "  Epoch Time: 0:06:24\n",
      "  Total Time: 0:25:31\n",
      "  Estimated Time Remaining: 0:38:17\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 1455/1455 [05:50<00:00,  4.15it/s, loss=2.8541, avg_loss=3.0811, lr=0.000017]\n",
      "Epoch 5/10 [Test]: 100%|██████████| 364/364 [00:32<00:00, 11.15it/s, loss=2.4226, avg_loss=2.8452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_5_loss_2.8452\n",
      "\n",
      "Epoch 5/10 Summary:\n",
      "  Train Loss: 3.0811\n",
      "  Test Loss: 2.8452\n",
      "  Epoch Time: 0:06:23\n",
      "  Total Time: 0:31:55\n",
      "  Estimated Time Remaining: 0:31:55\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 1455/1455 [05:55<00:00,  4.10it/s, loss=2.8766, avg_loss=3.0223, lr=0.000013]\n",
      "Epoch 6/10 [Test]: 100%|██████████| 364/364 [00:33<00:00, 10.89it/s, loss=2.3867, avg_loss=2.8062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_6_loss_2.8062\n",
      "\n",
      "Epoch 6/10 Summary:\n",
      "  Train Loss: 3.0223\n",
      "  Test Loss: 2.8062\n",
      "  Epoch Time: 0:06:28\n",
      "  Total Time: 0:38:23\n",
      "  Estimated Time Remaining: 0:25:35\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 1455/1455 [05:43<00:00,  4.24it/s, loss=2.9608, avg_loss=2.9781, lr=0.000010]\n",
      "Epoch 7/10 [Test]: 100%|██████████| 364/364 [00:31<00:00, 11.50it/s, loss=2.3611, avg_loss=2.7674]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_7_loss_2.7674\n",
      "\n",
      "Epoch 7/10 Summary:\n",
      "  Train Loss: 2.9781\n",
      "  Test Loss: 2.7674\n",
      "  Epoch Time: 0:06:15\n",
      "  Total Time: 0:44:39\n",
      "  Estimated Time Remaining: 0:19:08\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 1455/1455 [05:39<00:00,  4.28it/s, loss=3.3321, avg_loss=2.9392, lr=0.000007]\n",
      "Epoch 8/10 [Test]: 100%|██████████| 364/364 [00:31<00:00, 11.49it/s, loss=2.3416, avg_loss=2.7426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_8_loss_2.7426\n",
      "\n",
      "Epoch 8/10 Summary:\n",
      "  Train Loss: 2.9392\n",
      "  Test Loss: 2.7426\n",
      "  Epoch Time: 0:06:12\n",
      "  Total Time: 0:50:51\n",
      "  Estimated Time Remaining: 0:12:42\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 1455/1455 [05:40<00:00,  4.28it/s, loss=2.8938, avg_loss=2.9169, lr=0.000003]\n",
      "Epoch 9/10 [Test]: 100%|██████████| 364/364 [00:31<00:00, 11.51it/s, loss=2.3260, avg_loss=2.7305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_9_loss_2.7305\n",
      "\n",
      "Epoch 9/10 Summary:\n",
      "  Train Loss: 2.9169\n",
      "  Test Loss: 2.7305\n",
      "  Epoch Time: 0:06:12\n",
      "  Total Time: 0:57:03\n",
      "  Estimated Time Remaining: 0:06:20\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 1455/1455 [05:39<00:00,  4.28it/s, loss=2.8106, avg_loss=2.9081, lr=0.000000]\n",
      "Epoch 10/10 [Test]: 100%|██████████| 364/364 [00:31<00:00, 11.47it/s, loss=2.3235, avg_loss=2.7238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved best model checkpoint to t5_model_best_epoch_10_loss_2.7238\n",
      "\n",
      "Epoch 10/10 Summary:\n",
      "  Train Loss: 2.9081\n",
      "  Test Loss: 2.7238\n",
      "  Epoch Time: 0:06:12\n",
      "  Total Time: 1:03:15\n",
      "--------------------------------------------------\n",
      "\n",
      "T5 fine-tuning completed in 1:03:15\n",
      "Final Train Loss: 2.9081\n",
      "Final Test Loss: 2.7238\n",
      "Best Test Loss: 2.7238\n",
      "Loaded best model from t5_model_best_epoch_10_loss_2.7238 for final saving\n",
      "Generative model saved to generative_model_improved\n",
      "T5 model re-training complete!\n",
      "\n",
      "Testing Improved Model:\n",
      "\n",
      "Question: What will happen to me if I murder a person?\n",
      "Answer: whoever commits murder shall be punished with death, or imprisonment for life,\n",
      "\n",
      "Question: What is the punishment for robbery under IPC?\n",
      "Answer: what is punishment for robbery?\n",
      "\n",
      "Question: What are my rights if I am arrested?\n",
      "Answer: if a person is arrested?\n",
      "\n",
      "Question: How do I file a bail application?\n",
      "Answer: how do I file a bail application?\n",
      "\n",
      "Question: What constitutes culpable homicide not amounting to murder?\n",
      "Answer: robbery\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting T5 model re-training with increased epochs\")\n",
    "\n",
    "# Initialize the Answer Extractor/Generator\n",
    "answer_component = AnswerExtractorGenerator()\n",
    "\n",
    "# Load processed data and prepare for training\n",
    "train_loader, test_loader = answer_component.prepare_training_data('legal_qa_processed.json')\n",
    "\n",
    "# Fine-tune T5 for answer generation with more epochs\n",
    "t5_model = answer_component.fine_tune_t5(\n",
    "    train_loader, \n",
    "    test_loader, \n",
    "    num_epochs=10,  # Increased from 2 to 5\n",
    "    learning_rate=3e-5  # Slightly lower learning rate for stability\n",
    ")\n",
    "\n",
    "# Save generative model\n",
    "answer_component.save_generative_model('generative_model_improved')\n",
    "\n",
    "print(\"T5 model re-training complete!\")\n",
    "\n",
    "# Test the improved model on some difficult questions\n",
    "test_questions = [\n",
    "    \"What will happen to me if I murder a person?\",\n",
    "    \"What is the punishment for robbery under IPC?\",\n",
    "    \"What are my rights if I am arrested?\",\n",
    "    \"How do I file a bail application?\",\n",
    "    \"What constitutes culpable homicide not amounting to murder?\"\n",
    "]\n",
    "\n",
    "contexts = [\n",
    "    \"Section 302 of the Indian Penal Code deals with punishment for murder. Whoever commits murder shall be punished with death, or imprisonment for life, and shall also be liable to fine.\",\n",
    "    \"Section 392 of the Indian Penal Code provides punishment for robbery. Whoever commits robbery shall be punished with rigorous imprisonment for a term which may extend to ten years, and shall also be liable to fine.\",\n",
    "    \"When a person is arrested, they have rights under Article 22 of the Constitution and CrPC provisions. These include the right to be informed of grounds of arrest, right to legal representation, and the right to be presented before a magistrate within 24 hours.\"\n",
    "]\n",
    "\n",
    "print(\"\\nTesting Improved Model:\")\n",
    "for question in test_questions:\n",
    "    result = answer_component.generate_answer(question, \" \".join(contexts))\n",
    "    print(f\"\\nQuestion: {question}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading default T5 model...\n",
      "Preparing legal dataset...\n",
      "Loaded 14543 QA pairs for T5 preparation\n",
      "Prepared 11634 training samples and 2909 test samples\n",
      "Starting SQuAD training and legal fine-tuning...\n",
      "Loading SQuAD dataset...\n",
      "Loaded SQuAD from C:\\Users\\tarus\\OneDrive\\Documents\\College Notes\\MAJOR PROJECT\\ATTEMPT3.5\\SQUAD DATASET\\train-v2.0.json: 442 articles\n",
      "Initializing T5 model...\n",
      "SQuAD training set: 78138 examples\n",
      "SQuAD validation set: 8683 examples\n",
      "\n",
      "==================================================\n",
      "PHASE 1: Training on SQuAD dataset\n",
      "==================================================\n",
      "Starting SQuAD phase: 2 epochs, 9768 steps per epoch\n",
      "Learning rate: 3e-05, Warmup steps: 1953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 [SQuAD Train]: 100%|██████████| 9768/9768 [37:23<00:00,  4.35it/s, loss=0.1665, avg_loss=0.4088, lr=0.000017]\n",
      "Epoch 1/2 [SQuAD Test]: 100%|██████████| 1086/1086 [01:17<00:00, 13.96it/s, loss=0.4324, avg_loss=0.2777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved to t5_squad_checkpoints/best_epoch_1_loss_0.2777\n",
      "\n",
      "Epoch 1/2 Summary:\n",
      "  Train Loss: 0.4088\n",
      "  Test Loss: 0.2777\n",
      "  Epoch Time: 0:38:41\n",
      "  Total Time: 0:38:41\n",
      "  Est. Time Remaining: 0:38:41\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2 [SQuAD Train]: 100%|██████████| 9768/9768 [37:43<00:00,  4.32it/s, loss=0.6825, avg_loss=0.3681, lr=0.000000]\n",
      "Epoch 2/2 [SQuAD Test]: 100%|██████████| 1086/1086 [01:23<00:00, 13.00it/s, loss=0.3930, avg_loss=0.2764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved to t5_squad_checkpoints/best_epoch_2_loss_0.2764\n",
      "\n",
      "Epoch 2/2 Summary:\n",
      "  Train Loss: 0.3681\n",
      "  Test Loss: 0.2764\n",
      "  Epoch Time: 0:39:19\n",
      "  Total Time: 1:18:01\n",
      "--------------------------------------------------\n",
      "\n",
      "SQuAD phase completed in 1:18:01\n",
      "Final Train Loss: 0.3681\n",
      "Final Test Loss: 0.2764\n",
      "Best Test Loss: 0.2764\n",
      "\n",
      "==================================================\n",
      "PHASE 2: Fine-tuning on legal dataset\n",
      "==================================================\n",
      "Starting Legal phase: 3 epochs, 1455 steps per epoch\n",
      "Learning rate: 1.5e-05, Warmup steps: 436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 [Legal Train]: 100%|██████████| 1455/1455 [05:42<00:00,  4.25it/s, loss=3.2569, avg_loss=3.2101, lr=0.000011]\n",
      "Epoch 1/3 [Legal Test]: 100%|██████████| 364/364 [00:26<00:00, 13.58it/s, loss=3.9601, avg_loss=2.6300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved to t5_legal_checkpoints/best_epoch_1_loss_2.6300\n",
      "\n",
      "Epoch 1/3 Summary:\n",
      "  Train Loss: 3.2101\n",
      "  Test Loss: 2.6300\n",
      "  Epoch Time: 0:06:09\n",
      "  Total Time: 0:06:09\n",
      "  Est. Time Remaining: 0:12:18\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 [Legal Train]: 100%|██████████| 1455/1455 [05:42<00:00,  4.25it/s, loss=2.2860, avg_loss=2.8268, lr=0.000006]\n",
      "Epoch 2/3 [Legal Test]: 100%|██████████| 364/364 [00:26<00:00, 13.73it/s, loss=3.8383, avg_loss=2.5284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved to t5_legal_checkpoints/best_epoch_2_loss_2.5284\n",
      "\n",
      "Epoch 2/3 Summary:\n",
      "  Train Loss: 2.8268\n",
      "  Test Loss: 2.5284\n",
      "  Epoch Time: 0:06:09\n",
      "  Total Time: 0:12:19\n",
      "  Est. Time Remaining: 0:06:09\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 [Legal Train]: 100%|██████████| 1455/1455 [05:37<00:00,  4.31it/s, loss=4.4521, avg_loss=2.7597, lr=0.000000]\n",
      "Epoch 3/3 [Legal Test]: 100%|██████████| 364/364 [00:24<00:00, 14.61it/s, loss=3.8143, avg_loss=2.5022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ New best model saved to t5_legal_checkpoints/best_epoch_3_loss_2.5022\n",
      "\n",
      "Epoch 3/3 Summary:\n",
      "  Train Loss: 2.7597\n",
      "  Test Loss: 2.5022\n",
      "  Epoch Time: 0:06:02\n",
      "  Total Time: 0:18:21\n",
      "--------------------------------------------------\n",
      "\n",
      "Legal phase completed in 0:18:21\n",
      "Final Train Loss: 2.7597\n",
      "Final Test Loss: 2.5022\n",
      "Best Test Loss: 2.5022\n",
      "Final model saved to t5_squad_legal_model\n",
      "Generative model saved to t5_squad_legal_model\n",
      "\n",
      "Testing the SQuAD + Legal Fine-tuned Model:\n",
      "\n",
      "Question: What will happen to me if I murder a person?\n",
      "Answer: If I murder a person, they have rights under Article 22 of the Constitution and CrPC.\n",
      "\n",
      "Question: What is the punishment for robbery under IPC?\n",
      "Answer: Section 392 of the IPC provides punishment for robbery.\n",
      "\n",
      "Question: What are my rights if I am arrested?\n",
      "Answer: They have rights under Article 22 of the Constitution and CrPC.\n",
      "\n",
      "Question: How do I file a bail application?\n",
      "Answer: Section 302 of the IPC deals with punishment for murder.\n",
      "\n",
      "Question: What constitutes culpable homicide not amounting to murder?\n",
      "Answer: Section 302 of the IPC deals with punishment for murder.\n"
     ]
    }
   ],
   "source": [
    "def run_squad_plus_legal_training():\n",
    "    # Initialize the Answer Extractor/Generator\n",
    "    answer_component = AnswerExtractorGenerator()\n",
    "    \n",
    "    # Specify the path to your SQuAD file if you have it locally\n",
    "    # If not provided, it will download from the web\n",
    "    squad_file_path = r\"C:\\Users\\tarus\\OneDrive\\Documents\\College Notes\\MAJOR PROJECT\\ATTEMPT3.5\\SQUAD DATASET\\train-v2.0.json\"  # Replace with your path if you have it\n",
    "    \n",
    "    # Prepare legal dataset in T5 format\n",
    "    print(\"Preparing legal dataset...\")\n",
    "    legal_train_dataloader, legal_test_dataloader = answer_component.prepare_t5_training_data(\n",
    "        'legal_qa_processed.json',\n",
    "        batch_size=8\n",
    "    )\n",
    "    \n",
    "    # Train on SQuAD, then fine-tune on legal data\n",
    "    print(\"Starting SQuAD training and legal fine-tuning...\")\n",
    "    t5_model = answer_component.train_on_squad_and_finetune(\n",
    "        legal_train_dataloader=legal_train_dataloader,\n",
    "        legal_test_dataloader=legal_test_dataloader,\n",
    "        squad_batch_size=8,\n",
    "        squad_epochs=2,       # Adjust based on available time/resources\n",
    "        finetune_epochs=3,    # More epochs for legal fine-tuning\n",
    "        learning_rate=3e-5,\n",
    "        save_best=True,\n",
    "        squad_file_path=squad_file_path if os.path.exists(squad_file_path) else None\n",
    "    )\n",
    "    \n",
    "    # Save the final model\n",
    "    answer_component.save_generative_model('t5_squad_legal_model')\n",
    "    \n",
    "    # Test the improved model\n",
    "    test_questions = [\n",
    "        \"What will happen to me if I murder a person?\",\n",
    "        \"What is the punishment for robbery under IPC?\",\n",
    "        \"What are my rights if I am arrested?\",\n",
    "        \"How do I file a bail application?\",\n",
    "        \"What constitutes culpable homicide not amounting to murder?\"\n",
    "    ]\n",
    "    \n",
    "    # Create a context with relevant legal information\n",
    "    contexts = [\n",
    "        \"Section 302 of the IPC deals with punishment for murder. Whoever commits murder shall be punished with death, or imprisonment for life, and shall also be liable to fine.\",\n",
    "        \"Section 392 of the IPC provides punishment for robbery. Whoever commits robbery shall be punished with rigorous imprisonment for a term which may extend to ten years, and shall also be liable to fine.\",\n",
    "        \"When a person is arrested, they have rights under Article 22 of the Constitution and CrPC. These include the right to know the grounds of arrest, right to legal counsel, and the right to be produced before a magistrate within 24 hours.\"\n",
    "    ]\n",
    "    \n",
    "    combined_context = \" \".join(contexts)\n",
    "    \n",
    "    print(\"\\nTesting the SQuAD + Legal Fine-tuned Model:\")\n",
    "    for question in test_questions:\n",
    "        # Test with improved formatting\n",
    "        instruction = \"Answer the legal question according to Indian law: \"\n",
    "        input_text = f\"{instruction} {question}\\n\\nRelevant legal context: {combined_context}\\n\\nAnswer: \"\n",
    "        \n",
    "        # Tokenize\n",
    "        input_ids = answer_component.t5_tokenizer.encode(input_text, return_tensors='pt').to(answer_component.device)\n",
    "        \n",
    "        # Generate answer\n",
    "        answer_component.t5_model.eval()\n",
    "        with torch.no_grad():\n",
    "            output_ids = answer_component.t5_model.generate(\n",
    "                input_ids,\n",
    "                max_length=100,\n",
    "                num_beams=5,\n",
    "                length_penalty=1.0,\n",
    "                no_repeat_ngram_size=2,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            # Decode\n",
    "            answer = answer_component.t5_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        print(f\"\\nQuestion: {question}\")\n",
    "        print(f\"Answer: {answer}\")\n",
    "\n",
    "# Run the training pipeline\n",
    "run_squad_plus_legal_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default T5 model...\n",
      "Question: What are the fundamental rights in the Indian Constitution?\n",
      "Answer: Right to Equality, Right to Freedom, Right against Exploitation, Right to Freedom of Religion, Cultural and Educational Rights\n",
      "Method: generative\n"
     ]
    }
   ],
   "source": [
    "answer_component = AnswerExtractorGenerator()\n",
    "# Test with sample question and contexts\n",
    "question = \"What are the fundamental rights in the Indian Constitution?\"\n",
    "contexts = [\n",
    "    \"The Constitution of India provides six fundamental rights to Indian citizens. These are: Right to Equality, Right to Freedom, Right against Exploitation, Right to Freedom of Religion, Cultural and Educational Rights, and Right to Constitutional Remedies.\",\n",
    "    \"Fundamental Rights is a charter of rights contained in the Constitution of India. It guarantees civil liberties such that all Indians can lead their lives in peace and harmony as citizens of India.\",\n",
    "    \"The Fundamental Rights in India are contained in Part III of the Constitution from Articles 12 to 35.\"\n",
    "]\n",
    " \n",
    "# Get best answer\n",
    "result = answer_component.get_best_answer(question, contexts)\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Method: {result['method']}\")\n",
    "if 'confidence' in result:\n",
    "    print(f\"Confidence: {result['confidence']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tarus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the rights of an arrested person in India?\n",
      "Selected Answer: In India, when someone is arrested, they have several fundamental rights. These include the right to know why they are being arrested, the right to legal representation, the right to inform a family member about their arrest, and the right to be presented before a judicial magistrate within 24 hours. Additionally, they have the right to medical examination, the right against self-incrimination, and the right to bail in bailable offenses.\n",
      "Confidence: 0.59\n",
      "Source: generative\n",
      "\n",
      "Explanation:\n",
      "This answer is synthesized from multiple legal sources. The system has low confidence in this answer. Consider consulting a legal professional for more accurate information. Your question is about legal rights.\n",
      "Ranking data saved to answer_ranking_example.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize ranker\n",
    "ranker = AnswerRankingSelector()\n",
    " \n",
    "# Example question and answers\n",
    "question = \"What are the rights of an arrested person in India?\"\n",
    "question_type = \"RIGHTS\"\n",
    "bayesian_probs = {\"RIGHTS\": 0.75, \"LEGAL_PROVISION\": 0.15, \"PROCEDURE\": 0.10}\n",
    " \n",
    "# Example candidate answers\n",
    "candidate_answers = [\n",
    "    {\n",
    "        'text': \"According to Section 22 of the Indian Constitution, an arrested person has the right to be informed of the grounds of arrest, the right to consult and be defended by a legal practitioner, and must be produced before a magistrate within 24 hours of arrest.\",\n",
    "        'source': 'extractive',\n",
    "        'context': \"Section 22 of the Indian Constitution guarantees certain rights to arrested persons. These include: the right to be informed of the grounds of arrest, the right to consult and be defended by a legal practitioner of his choice, and the requirement to be produced before the nearest magistrate within 24 hours of arrest, excluding travel time.\",\n",
    "        'span_confidence': 0.82\n",
    "    },\n",
    "    {\n",
    "        'text': \"In India, when someone is arrested, they have several fundamental rights. These include the right to know why they are being arrested, the right to legal representation, the right to inform a family member about their arrest, and the right to be presented before a judicial magistrate within 24 hours. Additionally, they have the right to medical examination, the right against self-incrimination, and the right to bail in bailable offenses.\",\n",
    "        'source': 'generative',\n",
    "        'context': \"Articles 20, 21, and 22 of the Constitution of India along with provisions in the Criminal Procedure Code (CrPC) outline rights of arrested persons.\",\n",
    "        'generation_confidence': 0.88\n",
    "    },\n",
    "    {\n",
    "        'text': \"The rights of an arrested person include the right to silence, right to be informed of charges, right to legal aid, right to be produced before a magistrate within 24 hours, and protection against torture.\",\n",
    "        'source': 'similarity',\n",
    "        'question': \"What rights do I have if I am arrested?\",\n",
    "        'similarity_score': 0.79\n",
    "    }\n",
    "]\n",
    " \n",
    "# Rank answers\n",
    "result = ranker.rank_answers(question, question_type, bayesian_probs, candidate_answers)\n",
    " \n",
    "# Print result\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Selected Answer: {result['selected_answer']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "print(f\"Source: {result['source']}\")\n",
    "print(\"\\nExplanation:\")\n",
    "print(ranker.explain_answer_selection(result))\n",
    " \n",
    "# Save ranking data for analysis\n",
    "ranker.save_ranking('answer_ranking_example.json', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Legal Question Answering System (Testing Mode)...\n",
      "Loading components...\n",
      "Classifier loaded from question_classifier.pkl\n",
      "✓ Question classifier loaded\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Loaded embeddings from legal_qa_processed.json_embeddings.npy\n",
      "Loaded 0 historical Q&A pairs from question_history.pkl\n",
      "✓ Question retrieval system loaded with history\n",
      "Initialized Context Retriever with model paraphrase-MiniLM-L6-v2 on cuda\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Prepared 14543 context passages for retrieval\n",
      "Loaded BM25 index from legal_qa_retrieval_indices_bm25.pkl\n",
      "Loaded passage embeddings from legal_qa_retrieval_indices_embeddings.npy\n",
      "✓ Context retriever loaded with indices\n",
      "Using device: cuda\n",
      "Extractive model loaded from extractive_model.pt\n",
      "Loading default T5 model...\n",
      "Generative model loaded from t5_squad_legal_model\n",
      "✓ Answer generator loaded with both extractive and generative models\n",
      "✓ Answer ranker loaded\n",
      "All components loaded successfully!\n",
      "\n",
      "======== Legal QA System - Testing Mode ========\n",
      "This mode shows all answer types for comparison\n",
      "Type 'exit' to quit the system\n",
      "\n",
      "==================================================\n",
      "Processing your question...\n",
      "Loading components for testing...\n",
      "Loading components...\n",
      "Classifier loaded from question_classifier.pkl\n",
      "✓ Question classifier loaded\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Loaded embeddings from legal_qa_processed.json_embeddings.npy\n",
      "Loaded 0 historical Q&A pairs from question_history.pkl\n",
      "✓ Question retrieval system loaded with history\n",
      "Initialized Context Retriever with model paraphrase-MiniLM-L6-v2 on cuda\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Prepared 14543 context passages for retrieval\n",
      "Loaded BM25 index from legal_qa_retrieval_indices_bm25.pkl\n",
      "Loaded passage embeddings from legal_qa_retrieval_indices_embeddings.npy\n",
      "✓ Context retriever loaded with indices\n",
      "Using device: cuda\n",
      "Extractive model loaded from extractive_model.pt\n",
      "Loading default T5 model...\n",
      "Generative model loaded from t5_squad_legal_model\n",
      "✓ Answer generator loaded with both extractive and generative models\n",
      "✓ Answer ranker loaded\n",
      "All components loaded successfully!\n",
      "\n",
      "Testing question: \"Is it illegal for a landlord to lock the property without informing the tenant?\"\n",
      "Question classified as: CONSEQUENCE (Confidence: 0.36)\n",
      "No match in history, searching dataset...\n",
      "No similar question found with high confidence. Retrieving context...\n",
      "Retrieved 5 context passages\n",
      "Ranking 3 candidate answers...\n",
      "Question history saved to question_history.pkl\n",
      "\n",
      "============================================================\n",
      "QUESTION: Is it illegal for a landlord to lock the property without informing the tenant?\n",
      "CLASSIFIED AS: CONSEQUENCE (Confidence: 0.60)\n",
      "============================================================\n",
      "\n",
      "📌 EXTRACTIVE ANSWERS:\n",
      "  1. Answer: tenant ?  what does the act of illegally con\n",
      "     Confidence: 1.0\n",
      "     Context: what does the act of illegally confining a person with the goal of forcing them to confess, provide information, or return property refer to this refe...\n",
      "\n",
      "  2. Answer: the tenant ?  what is forbidden until eviction\n",
      "     Confidence: 1.0\n",
      "     Context: what is forbidden until eviction in due course of law all disturbance of such possession is forbidden until eviction in due course of law....\n",
      "\n",
      "\n",
      "🤖 GENERATIVE ANSWERS:\n",
      "  1. Answer: It is illegal for a landlord to lock the property without informing the tenant.\n",
      "     Context: what is the meaning of wrongful confinement for the purpose of extorting confession or information, or of compelling restoration of property this refe...\n",
      "\n",
      "\n",
      "🔍 SIMILARITY MATCHES:\n",
      "  No similar questions found\n",
      "\n",
      "✅ CHOSEN ANSWER:\n",
      "Method: generative\n",
      "Answer: It is illegal for a landlord to lock the property without informing the tenant.\n",
      "Explanation: This answer is synthesized from multiple legal sources. The system has moderate confidence in this answer.\n",
      "\n",
      "Time taken: 0.94 seconds\n",
      "\n",
      "==================================================\n",
      "Thank you for using the Legal QA System. Goodbye!\n",
      "System shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load all required components\n",
    "def load_components():\n",
    "    print(\"Loading components...\")\n",
    "    \n",
    "    # 1. Load Question Classifier\n",
    "    classifier = QuestionClassifier()\n",
    "    classifier.load_classifier('question_classifier.pkl')\n",
    "    print(\"✓ Question classifier loaded\")\n",
    "    \n",
    "    # 2. Load Question Retrieval System\n",
    "    retrieval_system = QuestionRetrievalSystem(use_sentence_transformer=True)\n",
    "    retrieval_system.load_processed_data(\n",
    "        'legal_qa_processed.json',\n",
    "        'legal_qa_processed.json_embeddings.npy'\n",
    "    )\n",
    "    \n",
    "    # Load question history if it exists\n",
    "    try:\n",
    "        retrieval_system.load_history('question_history.pkl')\n",
    "        print(\"✓ Question retrieval system loaded with history\")\n",
    "    except:\n",
    "        print(\"✓ Question retrieval system loaded (no history)\")\n",
    "    \n",
    "    # 3. Load Context Retriever\n",
    "    context_retriever = ContextRetriever(use_gpu=torch.cuda.is_available())\n",
    "    context_retriever.load_processed_data('legal_qa_processed.json')\n",
    "    \n",
    "    # Load pre-computed indices\n",
    "    try:\n",
    "        context_retriever.load_indices(\n",
    "            'legal_qa_retrieval_indices_bm25.pkl', \n",
    "            'legal_qa_retrieval_indices_embeddings.npy'\n",
    "        )\n",
    "        print(\"✓ Context retriever loaded with indices\")\n",
    "    except:\n",
    "        print(\"! Context retriever indices not found, building indices...\")\n",
    "        context_retriever.build_bm25_index()\n",
    "        context_retriever.compute_passage_embeddings()\n",
    "        print(\"✓ Context retriever ready\")\n",
    "    \n",
    "    # 4. Load Answer Extractor/Generator\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    answer_component = AnswerExtractorGenerator(\n",
    "        device=device,\n",
    "        extractive_model_path='extractive_model.pt'\n",
    "    )\n",
    "    \n",
    "    # Try to load generative model if it exists\n",
    "    try:\n",
    "        answer_component.load_generative_model('t5_squad_legal_model')\n",
    "        print(\"✓ Answer generator loaded with both extractive and generative models\")\n",
    "    except:\n",
    "        print(\"✓ Answer generator loaded with extractive model only\")\n",
    "    \n",
    "    # 5. Load Answer Ranker\n",
    "    ranker = AnswerRankingSelector()\n",
    "    print(\"✓ Answer ranker loaded\")\n",
    "    \n",
    "    print(\"All components loaded successfully!\")\n",
    "    return classifier, retrieval_system, context_retriever, answer_component, ranker\n",
    "\n",
    "# Main function to process a question\n",
    "def answer_legal_question(question, components=None, debug=False, testing_mode=False):\n",
    "    if components is None:\n",
    "        classifier, retrieval_system, context_retriever, answer_component, ranker = load_components()\n",
    "    else:\n",
    "        classifier, retrieval_system, context_retriever, answer_component, ranker = components\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Classify the question\n",
    "    classification = classifier.classify_question(question)\n",
    "    question_type = classification['question_type']\n",
    "    bayesian_probs = classification['probabilities']\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Question classified as: {question_type} (Confidence: {classification['confidence']:.2f})\")\n",
    "    \n",
    "    # Step 2: Check if similar question exists in history\n",
    "    retrieval_result = retrieval_system.retrieve_answer(question, question_type)\n",
    "    \n",
    "    answer_method = \"unknown\"  # Initialize method tracking\n",
    "    \n",
    "    # Store all candidate answers for testing mode\n",
    "    all_candidates = {\n",
    "        'extractive': [],\n",
    "        'generative': [],\n",
    "        'similarity': []\n",
    "    }\n",
    "    \n",
    "    # If we found a similar question with high confidence\n",
    "    if retrieval_result['source'] == 'history' or (\n",
    "        retrieval_result['source'] == 'database' and retrieval_result['similarity'] > 0.85\n",
    "    ):\n",
    "        if debug:\n",
    "            print(f\"Similar question found ({retrieval_result['similarity']:.2f} similarity)\")\n",
    "            print(f\"Similar question: {retrieval_result['question']}\")\n",
    "        \n",
    "        answer_method = \"similarity\"  # Set method to similarity\n",
    "        \n",
    "        # Create candidate answers list with just this one answer\n",
    "        candidate_answers = [{\n",
    "            'text': retrieval_result['answer'],\n",
    "            'source': 'similarity',\n",
    "            'question': retrieval_result['question'],\n",
    "            'similarity_score': retrieval_result['similarity']\n",
    "        }]\n",
    "        \n",
    "        all_candidates['similarity'].append({\n",
    "            'text': retrieval_result['answer'],\n",
    "            'question': retrieval_result['question'],\n",
    "            'score': retrieval_result['similarity']\n",
    "        })\n",
    "        \n",
    "        # Add to history if not already there\n",
    "        if retrieval_result['source'] == 'database':\n",
    "            retrieval_system.add_to_history(question, retrieval_result['answer'])\n",
    "        \n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"No similar question found with high confidence. Retrieving context...\")\n",
    "        \n",
    "        # Step 3: Retrieve relevant contexts\n",
    "        contexts = context_retriever.retrieve_contexts(\n",
    "            question, \n",
    "            question_type=question_type,\n",
    "            retrieval_method='hybrid',\n",
    "            top_k=5\n",
    "        )\n",
    "        \n",
    "        context_passages = [ctx['passage'] for ctx in contexts]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Retrieved {len(context_passages)} context passages\")\n",
    "        \n",
    "        # Step 4: Generate candidate answers\n",
    "        candidate_answers = []\n",
    "        \n",
    "        # Try extractive approach (using top 3 passages)\n",
    "        if len(context_passages) > 0:\n",
    "            for i, context in enumerate(context_passages[:3]):\n",
    "                extracted = answer_component.extract_answer(question, context)\n",
    "                \n",
    "                if extracted.get('answer') and extracted.get('confidence', 0) > 0.3:\n",
    "                    candidate_answers.append({\n",
    "                        'text': extracted['answer'],\n",
    "                        'source': 'extractive',\n",
    "                        'context': context,\n",
    "                        'span_confidence': extracted['confidence']\n",
    "                    })\n",
    "                    \n",
    "                    # Save for testing mode\n",
    "                    all_candidates['extractive'].append({\n",
    "                        'text': extracted['answer'],\n",
    "                        'context': context[:200] + \"...\" if len(context) > 200 else context,\n",
    "                        'confidence': extracted.get('confidence', 0)\n",
    "                    })\n",
    "        \n",
    "        # Try generative approach\n",
    "        if len(context_passages) > 0:\n",
    "            # Combine top contexts for generation\n",
    "            combined_context = \" \".join(context_passages[:3])\n",
    "            generated = answer_component.generate_answer(question, combined_context)\n",
    "            \n",
    "            if generated.get('answer'):\n",
    "                candidate_answers.append({\n",
    "                    'text': generated['answer'],\n",
    "                    'source': 'generative',\n",
    "                    'context': combined_context\n",
    "                })\n",
    "                \n",
    "                # Save for testing mode\n",
    "                all_candidates['generative'].append({\n",
    "                    'text': generated['answer'],\n",
    "                    'context': combined_context[:200] + \"...\" if len(combined_context) > 200 else combined_context\n",
    "                })\n",
    "        \n",
    "        # If we have a good similarity match but below threshold, add it too\n",
    "        if retrieval_result['source'] == 'database' and retrieval_result['similarity'] > 0.6:\n",
    "            candidate_answers.append({\n",
    "                'text': retrieval_result['answer'],\n",
    "                'source': 'similarity',\n",
    "                'question': retrieval_result['question'],\n",
    "                'similarity_score': retrieval_result['similarity']\n",
    "            })\n",
    "            \n",
    "            all_candidates['similarity'].append({\n",
    "                'text': retrieval_result['answer'],\n",
    "                'question': retrieval_result['question'],\n",
    "                'score': retrieval_result['similarity']\n",
    "            })\n",
    "            \n",
    "        # If no answers found\n",
    "        if not candidate_answers:\n",
    "            if testing_mode:\n",
    "                return {\n",
    "                    'question': question,\n",
    "                    'answer': \"I couldn't find a suitable answer to your legal question.\",\n",
    "                    'confidence': 0.0,\n",
    "                    'question_type': question_type,\n",
    "                    'time_taken': time.time() - start_time,\n",
    "                    'method': \"none\",\n",
    "                    'all_candidates': all_candidates  # Include all candidates for testing\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'question': question,\n",
    "                    'answer': \"I couldn't find a suitable answer to your legal question. Please try rephrasing or ask a different question.\",\n",
    "                    'confidence': 0.0,\n",
    "                    'question_type': question_type,\n",
    "                    'time_taken': time.time() - start_time,\n",
    "                    'method': \"none\"\n",
    "                }\n",
    "    \n",
    "    # Step 5: Rank and select the best answer\n",
    "    if debug:\n",
    "        print(f\"Ranking {len(candidate_answers)} candidate answers...\")\n",
    "    \n",
    "    ranking_result = ranker.rank_answers(\n",
    "        question, \n",
    "        question_type,\n",
    "        bayesian_probs,\n",
    "        candidate_answers\n",
    "    )\n",
    "    \n",
    "    # Capture the method used for the final answer\n",
    "    if 'source' in ranking_result:\n",
    "        answer_method = ranking_result['source']\n",
    "    \n",
    "    # Add the best answer to history for future retrieval\n",
    "    if ranking_result['confidence'] > 0.6:\n",
    "        retrieval_system.add_to_history(question, ranking_result['selected_answer'])\n",
    "        retrieval_system.save_history('question_history.pkl')\n",
    "    \n",
    "    # Generate explanation\n",
    "    explanation = ranker.explain_answer_selection(ranking_result)\n",
    "    \n",
    "    # Prepare final result\n",
    "    final_result = {\n",
    "        'question': question,\n",
    "        'answer': ranking_result['selected_answer'],\n",
    "        'confidence': ranking_result['confidence'],\n",
    "        'question_type': question_type,\n",
    "        'explanation': explanation,\n",
    "        'time_taken': time.time() - start_time,\n",
    "        'method': answer_method\n",
    "    }\n",
    "    \n",
    "    # In testing mode, include all candidate answers\n",
    "    if testing_mode:\n",
    "        final_result['all_candidates'] = all_candidates\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "# Function specifically for testing and comparing answers\n",
    "def test_legal_qa(question):\n",
    "    print(\"Loading components for testing...\")\n",
    "    components = load_components()\n",
    "    print(f\"\\nTesting question: \\\"{question}\\\"\")\n",
    "    \n",
    "    # Get results with all candidate answers\n",
    "    result = answer_legal_question(question, components=components, debug=True, testing_mode=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"QUESTION: {result['question']}\")\n",
    "    print(f\"CLASSIFIED AS: {result['question_type']} (Confidence: {result.get('confidence', 0):.2f})\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Display extractive answers\n",
    "    print(\"\\n📌 EXTRACTIVE ANSWERS:\")\n",
    "    if result['all_candidates']['extractive']:\n",
    "        for i, answer in enumerate(result['all_candidates']['extractive']):\n",
    "            print(f\"  {i+1}. Answer: {answer['text']}\")\n",
    "            print(f\"     Confidence: {answer.get('confidence', 'N/A')}\")\n",
    "            print(f\"     Context: {answer['context'][:150]}...\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"  No extractive answers generated\")\n",
    "        \n",
    "    # Display generative answers\n",
    "    print(\"\\n🤖 GENERATIVE ANSWERS:\")\n",
    "    if result['all_candidates']['generative']:\n",
    "        for i, answer in enumerate(result['all_candidates']['generative']):\n",
    "            print(f\"  {i+1}. Answer: {answer['text']}\")\n",
    "            print(f\"     Context: {answer['context'][:150]}...\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"  No generative answers generated\")\n",
    "    \n",
    "    # Display similarity answers\n",
    "    print(\"\\n🔍 SIMILARITY MATCHES:\")\n",
    "    if result['all_candidates']['similarity']:\n",
    "        for i, answer in enumerate(result['all_candidates']['similarity']):\n",
    "            print(f\"  {i+1}. Answer: {answer['text']}\")\n",
    "            print(f\"     Similar Question: {answer['question']}\")\n",
    "            print(f\"     Similarity Score: {answer.get('score', 'N/A')}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"  No similar questions found\")\n",
    "    \n",
    "    # Display chosen answer\n",
    "    print(\"\\n✅ CHOSEN ANSWER:\")\n",
    "    print(f\"Method: {result['method']}\")\n",
    "    print(f\"Answer: {result['answer']}\")\n",
    "    if 'explanation' in result:\n",
    "        print(f\"Explanation: {result['explanation']}\")\n",
    "    \n",
    "    print(f\"\\nTime taken: {result['time_taken']:.2f} seconds\")\n",
    "    return result\n",
    "\n",
    "# Interactive testing function that shows all answer types\n",
    "def interactive_legal_qa_testing():\n",
    "    print(\"Loading the Legal Question Answering System (Testing Mode)...\")\n",
    "    components = load_components()\n",
    "    print(\"\\n======== Legal QA System - Testing Mode ========\")\n",
    "    print(\"This mode shows all answer types for comparison\")\n",
    "    print(\"Type 'exit' to quit the system\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        question = input(\"Enter your legal question: \")\n",
    "        \n",
    "        if question.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Thank you for using the Legal QA System. Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        if not question.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"Processing your question...\")\n",
    "        test_legal_qa(question)\n",
    "        \n",
    "    print(\"System shutdown complete.\")\n",
    "\n",
    "# Run the testing function\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_legal_qa_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRIVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the Legal Question Answering System...\n",
      "Loading components...\n",
      "Classifier loaded from question_classifier.pkl\n",
      "✓ Question classifier loaded\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Loaded embeddings from legal_qa_processed.json_embeddings.npy\n",
      "Loaded 0 historical Q&A pairs from question_history.pkl\n",
      "✓ Question retrieval system loaded with history\n",
      "Initialized Context Retriever with model paraphrase-MiniLM-L6-v2 on cuda\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Prepared 14543 context passages for retrieval\n",
      "Loaded BM25 index from legal_qa_retrieval_indices_bm25.pkl\n",
      "Loaded passage embeddings from legal_qa_retrieval_indices_embeddings.npy\n",
      "✓ Context retriever loaded with indices\n",
      "Using device: cuda\n",
      "Extractive model loaded from extractive_model.pt\n",
      "Loading default T5 model...\n",
      "Generative model loaded from t5_squad_legal_model\n",
      "✓ Answer generator loaded with both extractive and generative models\n",
      "✓ Answer ranker loaded\n",
      "All components loaded successfully!\n",
      "\n",
      "======== Legal Question Answering System ========\n",
      "Type 'exit' to quit the system\n",
      "\n",
      "==================================================\n",
      "Processing your question...\n",
      "No match in history, searching dataset...\n",
      "Question history saved to question_history.pkl\n",
      "\n",
      "Question: Is it illegal for a landlord to lock the property without informing the tenant?\n",
      "Question Type: CONSEQUENCE\n",
      "Confidence: 0.60\n",
      "Method: generative (Answer generated from multiple legal sources)\n",
      "Answer: It is illegal for a landlord to lock the property without informing the tenant.\n",
      "\n",
      "Explanation: This answer is synthesized from multiple legal sources. The system has moderate confidence in this answer.\n",
      "\n",
      "Time taken: 1.00 seconds\n",
      "\n",
      "==================================================\n",
      "Thank you for using the Legal QA System. Goodbye!\n",
      "System shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pickle\n",
    "import json\n",
    "import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load all required components\n",
    "def load_components():\n",
    "    print(\"Loading components...\")\n",
    "    \n",
    "    # 1. Load Question Classifier\n",
    "    classifier = QuestionClassifier()\n",
    "    classifier.load_classifier('question_classifier.pkl')\n",
    "    print(\"✓ Question classifier loaded\")\n",
    "    \n",
    "    # 2. Load Question Retrieval System\n",
    "    retrieval_system = QuestionRetrievalSystem(use_sentence_transformer=True)\n",
    "    retrieval_system.load_processed_data(\n",
    "        'legal_qa_processed.json',\n",
    "        'legal_qa_processed.json_embeddings.npy'\n",
    "    )\n",
    "    \n",
    "    # Load question history if it exists\n",
    "    try:\n",
    "        retrieval_system.load_history('question_history.pkl')\n",
    "        print(\"✓ Question retrieval system loaded with history\")\n",
    "    except:\n",
    "        print(\"✓ Question retrieval system loaded (no history)\")\n",
    "    \n",
    "    # 3. Load Context Retriever\n",
    "    context_retriever = ContextRetriever(use_gpu=torch.cuda.is_available())\n",
    "    context_retriever.load_processed_data('legal_qa_processed.json')\n",
    "    \n",
    "    # Load pre-computed indices\n",
    "    try:\n",
    "        context_retriever.load_indices(\n",
    "            'legal_qa_retrieval_indices_bm25.pkl', \n",
    "            'legal_qa_retrieval_indices_embeddings.npy'\n",
    "        )\n",
    "        print(\"✓ Context retriever loaded with indices\")\n",
    "    except:\n",
    "        print(\"! Context retriever indices not found, building indices...\")\n",
    "        context_retriever.build_bm25_index()\n",
    "        context_retriever.compute_passage_embeddings()\n",
    "        print(\"✓ Context retriever ready\")\n",
    "    \n",
    "    # 4. Load Answer Extractor/Generator\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    answer_component = AnswerExtractorGenerator(\n",
    "        device=device,\n",
    "        extractive_model_path='extractive_model.pt'\n",
    "    )\n",
    "    \n",
    "    # Try to load generative model if it exists\n",
    "    try:\n",
    "        answer_component.load_generative_model('t5_squad_legal_model')\n",
    "        print(\"✓ Answer generator loaded with both extractive and generative models\")\n",
    "    except:\n",
    "        print(\"✓ Answer generator loaded with extractive model only\")\n",
    "    \n",
    "    # 5. Load Answer Ranker\n",
    "    ranker = AnswerRankingSelector()\n",
    "    print(\"✓ Answer ranker loaded\")\n",
    "    \n",
    "    print(\"All components loaded successfully!\")\n",
    "    return classifier, retrieval_system, context_retriever, answer_component, ranker\n",
    "\n",
    "# Main function to process a question\n",
    "def answer_legal_question(question, components=None, debug=False):\n",
    "    if components is None:\n",
    "        classifier, retrieval_system, context_retriever, answer_component, ranker = load_components()\n",
    "    else:\n",
    "        classifier, retrieval_system, context_retriever, answer_component, ranker = components\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Step 1: Classify the question\n",
    "    classification = classifier.classify_question(question)\n",
    "    question_type = classification['question_type']\n",
    "    bayesian_probs = classification['probabilities']\n",
    "    \n",
    "    if debug:\n",
    "        print(f\"Question classified as: {question_type} (Confidence: {classification['confidence']:.2f})\")\n",
    "    \n",
    "    # Step 2: Check if similar question exists in history\n",
    "    retrieval_result = retrieval_system.retrieve_answer(question, question_type)\n",
    "    \n",
    "    answer_method = \"unknown\"  # Initialize method tracking\n",
    "    \n",
    "    # If we found a similar question with high confidence\n",
    "    if retrieval_result['source'] == 'history' or (\n",
    "        retrieval_result['source'] == 'database' and retrieval_result['similarity'] > 0.85\n",
    "    ):\n",
    "        if debug:\n",
    "            print(f\"Similar question found ({retrieval_result['similarity']:.2f} similarity)\")\n",
    "            print(f\"Similar question: {retrieval_result['question']}\")\n",
    "        \n",
    "        # Changed: Classify similarity method as extractive\n",
    "        answer_method = \"extractive\"\n",
    "        \n",
    "        # Create candidate answers list with just this one answer\n",
    "        candidate_answers = [{\n",
    "            'text': retrieval_result['answer'],\n",
    "            'source': 'extractive',  # Changed from 'similarity' to 'extractive'\n",
    "            'question': retrieval_result['question'],\n",
    "            'similarity_score': retrieval_result['similarity']\n",
    "        }]\n",
    "        \n",
    "        # Add to history if not already there\n",
    "        if retrieval_result['source'] == 'database':\n",
    "            retrieval_system.add_to_history(question, retrieval_result['answer'])\n",
    "        \n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"No similar question found with high confidence. Retrieving context...\")\n",
    "        \n",
    "        # Step 3: Retrieve relevant contexts\n",
    "        contexts = context_retriever.retrieve_contexts(\n",
    "            question, \n",
    "            question_type=question_type,\n",
    "            retrieval_method='hybrid',\n",
    "            top_k=5\n",
    "        )\n",
    "        \n",
    "        context_passages = [ctx['passage'] for ctx in contexts]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"Retrieved {len(context_passages)} context passages\")\n",
    "        \n",
    "        # Step 4: Generate candidate answers\n",
    "        candidate_answers = []\n",
    "        \n",
    "        # Try extractive approach (using top 3 passages)\n",
    "        if len(context_passages) > 0:\n",
    "            for i, context in enumerate(context_passages[:3]):\n",
    "                extracted = answer_component.extract_answer(question, context)\n",
    "                \n",
    "                if extracted.get('answer') and extracted.get('confidence', 0) > 0.3:\n",
    "                    candidate_answers.append({\n",
    "                        'text': extracted['answer'],\n",
    "                        'source': 'extractive',\n",
    "                        'context': context,\n",
    "                        'span_confidence': extracted['confidence']\n",
    "                    })\n",
    "        \n",
    "        # Try generative approach\n",
    "        if len(context_passages) > 0:\n",
    "            # Combine top contexts for generation\n",
    "            combined_context = \" \".join(context_passages[:3])\n",
    "            generated = answer_component.generate_answer(question, combined_context)\n",
    "            \n",
    "            if generated.get('answer'):\n",
    "                candidate_answers.append({\n",
    "                    'text': generated['answer'],\n",
    "                    'source': 'generative',\n",
    "                    'context': combined_context\n",
    "                })\n",
    "        \n",
    "        # If we have a good similarity match but below threshold, add it too\n",
    "        if retrieval_result['source'] == 'database' and retrieval_result['similarity'] > 0.6:\n",
    "            candidate_answers.append({\n",
    "                'text': retrieval_result['answer'],\n",
    "                'source': 'extractive',  # Changed from 'similarity' to 'extractive'\n",
    "                'question': retrieval_result['question'],\n",
    "                'similarity_score': retrieval_result['similarity']\n",
    "            })\n",
    "            \n",
    "        # If no answers found\n",
    "        if not candidate_answers:\n",
    "            return {\n",
    "                'question': question,\n",
    "                'answer': \"I couldn't find a suitable answer to your legal question. Please try rephrasing or ask a different question.\",\n",
    "                'confidence': 0.0,\n",
    "                'question_type': question_type,\n",
    "                'time_taken': time.time() - start_time,\n",
    "                'method': \"none\"\n",
    "            }\n",
    "    \n",
    "    # Step 5: Rank and select the best answer\n",
    "    if debug:\n",
    "        print(f\"Ranking {len(candidate_answers)} candidate answers...\")\n",
    "    \n",
    "    # Update source mapping for ranker\n",
    "    for candidate in candidate_answers:\n",
    "        if candidate.get('source') == 'similarity':\n",
    "            candidate['source'] = 'extractive'\n",
    "    \n",
    "    ranking_result = ranker.rank_answers(\n",
    "        question, \n",
    "        question_type,\n",
    "        bayesian_probs,\n",
    "        candidate_answers\n",
    "    )\n",
    "    \n",
    "    # Capture the method used for the final answer\n",
    "    if 'source' in ranking_result:\n",
    "        answer_method = ranking_result['source']\n",
    "        \n",
    "        # Ensure similarity is mapped to extractive\n",
    "        if answer_method == 'similarity':\n",
    "            answer_method = 'extractive'\n",
    "    \n",
    "    # Add the best answer to history for future retrieval\n",
    "    if ranking_result['confidence'] > 0.6:\n",
    "        retrieval_system.add_to_history(question, ranking_result['selected_answer'])\n",
    "        retrieval_system.save_history('question_history.pkl')\n",
    "    \n",
    "    # Generate explanation\n",
    "    explanation = ranker.explain_answer_selection(ranking_result)\n",
    "    \n",
    "    # Prepare final result\n",
    "    final_result = {\n",
    "        'question': question,\n",
    "        'answer': ranking_result['selected_answer'],\n",
    "        'confidence': ranking_result['confidence'],\n",
    "        'question_type': question_type,\n",
    "        'explanation': explanation,\n",
    "        'time_taken': time.time() - start_time,\n",
    "        'method': answer_method\n",
    "    }\n",
    "    \n",
    "    return final_result\n",
    "\n",
    "# Create an interactive query function\n",
    "def interactive_legal_qa():\n",
    "    print(\"Loading the Legal Question Answering System...\")\n",
    "    components = load_components()\n",
    "    print(\"\\n======== Legal Question Answering System ========\")\n",
    "    print(\"Type 'exit' to quit the system\")\n",
    "    \n",
    "    while True:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        question = input(\"Enter your legal question: \")\n",
    "        \n",
    "        if question.lower() in ['exit', 'quit', 'bye']:\n",
    "            print(\"Thank you for using the Legal QA System. Goodbye!\")\n",
    "            break\n",
    "            \n",
    "        if not question.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"Processing your question...\")\n",
    "        result = answer_legal_question(question, components=components)\n",
    "        \n",
    "        print(f\"\\nQuestion: {result['question']}\")\n",
    "        print(f\"Question Type: {result['question_type']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.2f}\")\n",
    "        \n",
    "        # Display the method used to generate the answer\n",
    "        method_descriptions = {\n",
    "            'extractive': \"Answer extracted directly from legal texts\",\n",
    "            'generative': \"Answer generated from multiple legal sources\",\n",
    "            'none': \"No suitable answer method found\",\n",
    "            'unknown': \"Method undetermined\"\n",
    "        }\n",
    "        \n",
    "        method = result['method']\n",
    "        method_description = method_descriptions.get(method, \"Method undetermined\")\n",
    "        print(f\"Method: {method} ({method_description})\")\n",
    "        \n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        \n",
    "        if 'explanation' in result:\n",
    "            print(f\"\\nExplanation: {result['explanation']}\")\n",
    "            \n",
    "        print(f\"\\nTime taken: {result['time_taken']:.2f} seconds\")\n",
    "        \n",
    "    print(\"System shutdown complete.\")\n",
    "\n",
    "# Run the interactive QA system\n",
    "if __name__ == \"__main__\":\n",
    "    interactive_legal_qa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PERFORMANCE METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legal QA System Evaluation\n",
      "=========================\n",
      "\n",
      "Found model: generative_model\n",
      "Found model: t5_squad_legal_model\n",
      "\n",
      "Evaluating model: generative_model\n",
      "Evaluating model: generative_model\n",
      "Loading components...\n",
      "Initialized Context Retriever with model paraphrase-MiniLM-L6-v2 on cuda\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Prepared 14543 context passages for retrieval\n",
      "Loaded BM25 index from legal_qa_retrieval_indices_bm25.pkl\n",
      "Loaded passage embeddings from legal_qa_retrieval_indices_embeddings.npy\n",
      "✓ Context retriever loaded\n",
      "Classifier loaded from question_classifier.pkl\n",
      "✓ Question classifier loaded\n",
      "Using device: cuda\n",
      "Loading default T5 model...\n",
      "Generative model loaded from generative_model\n",
      "✓ Answer generator loaded with model: generative_model\n",
      "✓ Loaded evaluation dataset with 100 questions\n",
      "\n",
      "Processing questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results saved to evaluation_results_generative_model.json\n",
      "\n",
      "========== EVALUATION SUMMARY ==========\n",
      "Model: generative_model\n",
      "Overall Accuracy: 0.20\n",
      "Average Score: 0.36\n",
      "\n",
      "Metrics:\n",
      "  term_precision: 0.2820\n",
      "  rouge1_f1: 0.3547\n",
      "  rouge2_f1: 0.2446\n",
      "  rougeL_f1: 0.3321\n",
      "  semantic_similarity: 0.5527\n",
      "\n",
      "Results by Question Type:\n",
      "  EXCEPTION: 1.00 accuracy (2/2), avg score: 0.88\n",
      "  PROCEDURE: 0.00 accuracy (0/2), avg score: 0.46\n",
      "  DEFINITION: 0.27 accuracy (8/30), avg score: 0.42\n",
      "  FACTUAL: 0.23 accuracy (7/30), avg score: 0.38\n",
      "  CONSEQUENCE: 0.10 accuracy (1/10), avg score: 0.31\n",
      "  JURISDICTION: 0.00 accuracy (0/4), avg score: 0.29\n",
      "  LEGAL_PROVISION: 0.10 accuracy (2/21), avg score: 0.24\n",
      "  TIMEFRAME: 0.00 accuracy (0/1), avg score: 0.04\n",
      "\n",
      "Evaluating model: t5_squad_legal_model\n",
      "Evaluating model: t5_squad_legal_model\n",
      "Loading components...\n",
      "Initialized Context Retriever with model paraphrase-MiniLM-L6-v2 on cuda\n",
      "Loaded 14543 QA pairs from legal_qa_processed.json\n",
      "Prepared 14543 context passages for retrieval\n",
      "Loaded BM25 index from legal_qa_retrieval_indices_bm25.pkl\n",
      "Loaded passage embeddings from legal_qa_retrieval_indices_embeddings.npy\n",
      "✓ Context retriever loaded\n",
      "Classifier loaded from question_classifier.pkl\n",
      "✓ Question classifier loaded\n",
      "Using device: cuda\n",
      "Loading default T5 model...\n",
      "Generative model loaded from t5_squad_legal_model\n",
      "✓ Answer generator loaded with model: t5_squad_legal_model\n",
      "✓ Loaded evaluation dataset with 100 questions\n",
      "\n",
      "Processing questions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [05:43<00:00,  3.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed results saved to evaluation_results_t5_squad_legal_model.json\n",
      "\n",
      "========== EVALUATION SUMMARY ==========\n",
      "Model: t5_squad_legal_model\n",
      "Overall Accuracy: 0.60\n",
      "Average Score: 0.62\n",
      "\n",
      "Metrics:\n",
      "  term_precision: 0.6492\n",
      "  rouge1_f1: 0.5656\n",
      "  rouge2_f1: 0.4766\n",
      "  rougeL_f1: 0.5350\n",
      "  semantic_similarity: 0.7176\n",
      "\n",
      "Results by Question Type:\n",
      "  CONSEQUENCE: 0.70 accuracy (7/10), avg score: 0.68\n",
      "  LEGAL_PROVISION: 0.67 accuracy (14/21), avg score: 0.67\n",
      "  PROCEDURE: 0.50 accuracy (1/2), avg score: 0.65\n",
      "  DEFINITION: 0.63 accuracy (19/30), avg score: 0.63\n",
      "  EXCEPTION: 0.50 accuracy (1/2), avg score: 0.59\n",
      "  FACTUAL: 0.53 accuracy (16/30), avg score: 0.59\n",
      "  JURISDICTION: 0.50 accuracy (2/4), avg score: 0.57\n",
      "  TIMEFRAME: 0.00 accuracy (0/1), avg score: 0.08\n",
      "\n",
      "========== MODEL COMPARISON ==========\n",
      "               Model  Overall Accuracy  Avg Score  Term Precision  ROUGE-1  ROUGE-L  Semantic Sim\n",
      "    generative_model            0.2000     0.3607          0.2820   0.3547   0.3321        0.5527\n",
      "t5_squad_legal_model            0.6000     0.6233          0.6492   0.5656   0.5350        0.7176\n",
      "Comparison visualization saved as model_comparison.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation complete!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Helper function to make results JSON serializable\n",
    "def make_json_serializable(obj):\n",
    "    \"\"\"Convert numpy types to Python native types for JSON serialization\"\"\"\n",
    "    if isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64,\n",
    "                         np.uint8, np.uint16, np.uint32, np.uint64)):\n",
    "        return int(obj)\n",
    "    elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "        return float(obj)\n",
    "    elif isinstance(obj, (np.bool_)):\n",
    "        return bool(obj)\n",
    "    elif isinstance(obj, (np.ndarray,)):\n",
    "        return obj.tolist()\n",
    "    elif isinstance(obj, dict):\n",
    "        return {k: make_json_serializable(v) for k, v in obj.items()}\n",
    "    elif isinstance(obj, list):\n",
    "        return [make_json_serializable(item) for item in obj]\n",
    "    elif isinstance(obj, tuple):\n",
    "        return tuple(make_json_serializable(item) for item in obj)\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "def extract_key_terms(text):\n",
    "    \"\"\"Extract key terms from ground truth text for comparison\"\"\"\n",
    "    # Remove common words and keep meaningful terms\n",
    "    tokens = text.lower().split()\n",
    "    # Filter out very common words\n",
    "    common_words = {'the', 'a', 'an', 'is', 'are', 'to', 'of', 'for', 'in', 'on', 'by', 'and', 'or', 'that', 'this', 'with', 'as', 'at', 'from', 'be', 'been', 'was', 'were', 'which', 'has', 'have', 'had'}\n",
    "    key_terms = [token for token in tokens if token not in common_words and len(token) > 2]\n",
    "    \n",
    "    # Add specific legal terms that might be important regardless of length\n",
    "    legal_terms = ['ipc', 'law', 'act', 'crpc', 'code', 'court', 'judge']\n",
    "    for term in legal_terms:\n",
    "        if term in text.lower() and term not in key_terms:\n",
    "            key_terms.append(term)\n",
    "    \n",
    "    # Handle numbers and section references specifically\n",
    "    section_refs = re.findall(r'section\\s+\\d+', text.lower())\n",
    "    for ref in section_refs:\n",
    "        if ref not in key_terms:\n",
    "            key_terms.append(ref)\n",
    "    \n",
    "    # Extract standalone numbers that might be important (like section numbers)\n",
    "    numbers = re.findall(r'\\b\\d+\\b', text)\n",
    "    for num in numbers:\n",
    "        if num not in key_terms and len(num) > 1:  # Only add significant numbers\n",
    "            key_terms.append(num)\n",
    "    \n",
    "    return key_terms\n",
    "\n",
    "def evaluate_answer(generated_answer, ground_truth):\n",
    "    \"\"\"\n",
    "    Evaluate the generated answer against ground truth using multiple metrics\n",
    "    \"\"\"\n",
    "    # 1. Key term matching\n",
    "    required_terms = extract_key_terms(ground_truth)\n",
    "    terms_found = [term for term in required_terms if term.lower() in generated_answer.lower()]\n",
    "    \n",
    "    term_precision = len(terms_found) / len(required_terms) if required_terms else 0\n",
    "    \n",
    "    # 2. Calculate simple text similarity (fallback if rouge_score not available)\n",
    "    try:\n",
    "        from rouge_score import rouge_scorer\n",
    "        scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        rouge_scores = scorer.score(ground_truth, generated_answer)\n",
    "        rouge1_f1 = rouge_scores['rouge1'].fmeasure\n",
    "        rouge2_f1 = rouge_scores['rouge2'].fmeasure\n",
    "        rougeL_f1 = rouge_scores['rougeL'].fmeasure\n",
    "    except:\n",
    "        # Fallback if rouge_score not available\n",
    "        words_ground_truth = set(ground_truth.lower().split())\n",
    "        words_answer = set(generated_answer.lower().split())\n",
    "        overlap = len(words_ground_truth.intersection(words_answer))\n",
    "        \n",
    "        # Calculate F1 score manually\n",
    "        precision = overlap / len(words_answer) if words_answer else 0\n",
    "        recall = overlap / len(words_ground_truth) if words_ground_truth else 0\n",
    "        rouge1_f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        rouge2_f1 = rouge1_f1 * 0.8  # Approximation\n",
    "        rougeL_f1 = rouge1_f1 * 0.9  # Approximation\n",
    "    \n",
    "    # 3. Calculate semantic similarity using SentenceTransformer\n",
    "    try:\n",
    "        embedder = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "        ground_truth_emb = embedder.encode([ground_truth])[0]\n",
    "        answer_emb = embedder.encode([generated_answer])[0]\n",
    "        semantic_sim = float(cosine_similarity([ground_truth_emb], [answer_emb])[0][0])\n",
    "    except:\n",
    "        semantic_sim = 0.0  # Fallback if error\n",
    "    \n",
    "    # 4. Calculate combined score\n",
    "    combined_score = (\n",
    "        0.4 * term_precision + \n",
    "        0.2 * rouge1_f1 + \n",
    "        0.2 * rougeL_f1 + \n",
    "        0.2 * semantic_sim\n",
    "    )\n",
    "    \n",
    "    # Determine if answer is correct (threshold can be adjusted)\n",
    "    is_correct = combined_score >= 0.6\n",
    "    \n",
    "    return {\n",
    "        'term_precision': float(term_precision),\n",
    "        'terms_found': terms_found,\n",
    "        'required_terms': required_terms,\n",
    "        'rouge1_f1': float(rouge1_f1),\n",
    "        'rouge2_f1': float(rouge2_f1),\n",
    "        'rougeL_f1': float(rougeL_f1),\n",
    "        'semantic_similarity': float(semantic_sim),\n",
    "        'combined_score': float(combined_score),\n",
    "        'is_correct': bool(is_correct)\n",
    "    }\n",
    "\n",
    "def evaluate_with_gold_standard(model_path='t5_squad_legal_model', save_results=True):\n",
    "    \"\"\"\n",
    "    Evaluate model performance using the gold standard dataset\n",
    "    \"\"\"\n",
    "    print(f\"Evaluating model: {model_path}\")\n",
    "    \n",
    "    # Load components\n",
    "    print(\"Loading components...\")\n",
    "    try:\n",
    "        context_retriever = ContextRetriever(use_gpu=torch.cuda.is_available())\n",
    "        context_retriever.load_processed_data('legal_qa_processed.json')\n",
    "        context_retriever.load_indices(\n",
    "            'legal_qa_retrieval_indices_bm25.pkl', \n",
    "            'legal_qa_retrieval_indices_embeddings.npy'\n",
    "        )\n",
    "        print(\"✓ Context retriever loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading context retriever: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Load classifier\n",
    "    try:\n",
    "        classifier = QuestionClassifier()\n",
    "        classifier.load_classifier('question_classifier.pkl')\n",
    "        print(\"✓ Question classifier loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading classifier: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Load the generative model\n",
    "    try:\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        answer_generator = AnswerExtractorGenerator(device=device)\n",
    "        answer_generator.load_generative_model(model_path)\n",
    "        print(f\"✓ Answer generator loaded with model: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading generative model: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Load evaluation dataset\n",
    "    try:\n",
    "        with open('evaluation_dataset.json', 'r') as f:\n",
    "            evaluation_set = json.load(f)\n",
    "        print(f\"✓ Loaded evaluation dataset with {len(evaluation_set)} questions\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading evaluation dataset: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize results\n",
    "    results = {\n",
    "        'overall': {'correct': 0, 'total': 0},\n",
    "        'by_type': {},\n",
    "        'questions': []\n",
    "    }\n",
    "    \n",
    "    # Process each question\n",
    "    print(\"\\nProcessing questions...\")\n",
    "    \n",
    "    for i, item in enumerate(tqdm(evaluation_set)):\n",
    "        question = item['question']\n",
    "        ground_truth = item['ground_truth']\n",
    "        question_type = item['question_type']\n",
    "        \n",
    "        # Add question type to results if not present\n",
    "        if question_type not in results['by_type']:\n",
    "            results['by_type'][question_type] = {'correct': 0, 'total': 0, 'scores': []}\n",
    "        \n",
    "        # Classify question\n",
    "        classification = classifier.classify_question(question)\n",
    "        \n",
    "        # Retrieve contexts\n",
    "        contexts = context_retriever.retrieve_contexts(\n",
    "            question, \n",
    "            question_type=classification['question_type'],\n",
    "            retrieval_method='hybrid',\n",
    "            top_k=5\n",
    "        )\n",
    "        context_passages = [ctx['passage'] for ctx in contexts]\n",
    "        combined_context = \" \".join(context_passages[:3])\n",
    "        \n",
    "        # Generate answer (force generative model)\n",
    "        generated_answer = answer_generator.generate_answer(question, combined_context)\n",
    "        answer_text = generated_answer['answer']\n",
    "        \n",
    "        # Evaluate answer with multiple metrics\n",
    "        evaluation = evaluate_answer(answer_text, ground_truth)\n",
    "        \n",
    "        # Update results\n",
    "        results['overall']['total'] += 1\n",
    "        results['by_type'][question_type]['total'] += 1\n",
    "        \n",
    "        if evaluation['is_correct']:\n",
    "            results['overall']['correct'] += 1\n",
    "            results['by_type'][question_type]['correct'] += 1\n",
    "        \n",
    "        # Store scores\n",
    "        results['by_type'][question_type]['scores'].append(evaluation['combined_score'])\n",
    "        \n",
    "        # Save detailed result\n",
    "        results['questions'].append({\n",
    "            'id': i,\n",
    "            'question': question,\n",
    "            'ground_truth': ground_truth,\n",
    "            'generated_answer': answer_text,\n",
    "            'evaluation': evaluation,\n",
    "            'question_type': question_type,\n",
    "            'classifier_type': classification['question_type'],\n",
    "            'classifier_confidence': float(classification['confidence'])\n",
    "        })\n",
    "    \n",
    "    # Calculate accuracy metrics\n",
    "    results['overall']['accuracy'] = results['overall']['correct'] / results['overall']['total']\n",
    "    results['overall']['avg_score'] = float(np.mean([q['evaluation']['combined_score'] for q in results['questions']]))\n",
    "    \n",
    "    for qtype in results['by_type']:\n",
    "        type_total = results['by_type'][qtype]['total']\n",
    "        if type_total > 0:\n",
    "            results['by_type'][qtype]['accuracy'] = results['by_type'][qtype]['correct'] / type_total\n",
    "            results['by_type'][qtype]['avg_score'] = float(np.mean(results['by_type'][qtype]['scores']))\n",
    "    \n",
    "    # Calculate metrics across all questions\n",
    "    results['metrics'] = {\n",
    "        'term_precision': float(np.mean([q['evaluation']['term_precision'] for q in results['questions']])),\n",
    "        'rouge1_f1': float(np.mean([q['evaluation']['rouge1_f1'] for q in results['questions']])),\n",
    "        'rouge2_f1': float(np.mean([q['evaluation']['rouge2_f1'] for q in results['questions']])),\n",
    "        'rougeL_f1': float(np.mean([q['evaluation']['rougeL_f1'] for q in results['questions']])),\n",
    "        'semantic_similarity': float(np.mean([q['evaluation']['semantic_similarity'] for q in results['questions']]))\n",
    "    }\n",
    "    \n",
    "    # Make all results JSON serializable\n",
    "    results = make_json_serializable(results)\n",
    "    \n",
    "    # Save results to file\n",
    "    if save_results:\n",
    "        model_name = model_path.replace('/', '_')\n",
    "        results_path = f\"evaluation_results_{model_name}.json\"\n",
    "        with open(results_path, 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "        print(f\"\\nDetailed results saved to {results_path}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n========== EVALUATION SUMMARY ==========\")\n",
    "    print(f\"Model: {model_path}\")\n",
    "    print(f\"Overall Accuracy: {results['overall']['accuracy']:.2f}\")\n",
    "    print(f\"Average Score: {results['overall']['avg_score']:.2f}\")\n",
    "    print(\"\\nMetrics:\")\n",
    "    for metric, value in results['metrics'].items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nResults by Question Type:\")\n",
    "    for qtype, data in sorted(results['by_type'].items(), key=lambda x: x[1]['avg_score'], reverse=True):\n",
    "        print(f\"  {qtype}: {data['accuracy']:.2f} accuracy ({data['correct']}/{data['total']}), avg score: {data['avg_score']:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compare_models(model_paths):\n",
    "    \"\"\"\n",
    "    Compare multiple models on the gold standard dataset\n",
    "    \"\"\"\n",
    "    # Run evaluation for each model\n",
    "    all_results = {}\n",
    "    for model_path in model_paths:\n",
    "        print(f\"\\nEvaluating model: {model_path}\")\n",
    "        results = evaluate_with_gold_standard(model_path)\n",
    "        if results:\n",
    "            all_results[model_path] = results\n",
    "    \n",
    "    # If we have multiple models to compare\n",
    "    if len(all_results) > 1:\n",
    "        # Create comparison dataframe\n",
    "        comparison = {\n",
    "            'Model': [],\n",
    "            'Overall Accuracy': [],\n",
    "            'Avg Score': [],\n",
    "            'Term Precision': [],\n",
    "            'ROUGE-1': [],\n",
    "            'ROUGE-L': [],\n",
    "            'Semantic Sim': []\n",
    "        }\n",
    "        \n",
    "        # Add data for each model\n",
    "        for model, results in all_results.items():\n",
    "            comparison['Model'].append(model)\n",
    "            comparison['Overall Accuracy'].append(results['overall']['accuracy'])\n",
    "            comparison['Avg Score'].append(results['overall']['avg_score'])\n",
    "            comparison['Term Precision'].append(results['metrics']['term_precision'])\n",
    "            comparison['ROUGE-1'].append(results['metrics']['rouge1_f1'])\n",
    "            comparison['ROUGE-L'].append(results['metrics']['rougeL_f1'])\n",
    "            comparison['Semantic Sim'].append(results['metrics']['semantic_similarity'])\n",
    "        \n",
    "        # Create dataframe\n",
    "        df = pd.DataFrame(comparison)\n",
    "        \n",
    "        # Print comparison table\n",
    "        print(\"\\n========== MODEL COMPARISON ==========\")\n",
    "        print(df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\"))\n",
    "        \n",
    "        # Create visualization\n",
    "        try:\n",
    "            plt.figure(figsize=(12, 8))\n",
    "            \n",
    "            # Plot overall metrics\n",
    "            plt.subplot(2, 1, 1)\n",
    "            metrics = ['Overall Accuracy', 'Avg Score', 'Term Precision', 'ROUGE-1', 'ROUGE-L', 'Semantic Sim']\n",
    "            \n",
    "            df_plot = df.melt(id_vars=['Model'], value_vars=metrics, \n",
    "                              var_name='Metric', value_name='Score')\n",
    "            \n",
    "            sns.barplot(x='Metric', y='Score', hue='Model', data=df_plot)\n",
    "            plt.title('Comparison of Models - Overall Metrics')\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Plot accuracy by question type for each model\n",
    "            plt.subplot(2, 1, 2)\n",
    "            \n",
    "            # Prepare data for question type comparison\n",
    "            qtype_data = {\n",
    "                'Model': [],\n",
    "                'Question Type': [],\n",
    "                'Accuracy': []\n",
    "            }\n",
    "            \n",
    "            for model, results in all_results.items():\n",
    "                for qtype, data in results['by_type'].items():\n",
    "                    qtype_data['Model'].append(model)\n",
    "                    qtype_data['Question Type'].append(qtype)\n",
    "                    qtype_data['Accuracy'].append(data['accuracy'])\n",
    "            \n",
    "            qtype_df = pd.DataFrame(qtype_data)\n",
    "            \n",
    "            # Filter to most common question types for readability\n",
    "            top_qtypes = qtype_df.groupby('Question Type')['Accuracy'].mean().nlargest(6).index\n",
    "            qtype_df_filtered = qtype_df[qtype_df['Question Type'].isin(top_qtypes)]\n",
    "            \n",
    "            sns.barplot(x='Question Type', y='Accuracy', hue='Model', data=qtype_df_filtered)\n",
    "            plt.title('Comparison of Models - Accuracy by Question Type')\n",
    "            plt.ylim(0, 1)\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            plt.savefig(\"model_comparison.png\", dpi=300, bbox_inches='tight')\n",
    "            print(\"Comparison visualization saved as model_comparison.png\")\n",
    "            \n",
    "            # Show it\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating visualization: {str(e)}\")\n",
    "        \n",
    "    return all_results\n",
    "\n",
    "# Function to run a full evaluation\n",
    "def run_evaluation():\n",
    "    print(\"Legal QA System Evaluation\")\n",
    "    print(\"=========================\\n\")\n",
    "    \n",
    "    try:\n",
    "        # Install required package for ROUGE scores if not already installed\n",
    "        import importlib\n",
    "        if importlib.util.find_spec(\"rouge_score\") is None:\n",
    "            print(\"Installing rouge_score package...\")\n",
    "            import subprocess\n",
    "            subprocess.check_call([\"pip\", \"install\", \"rouge-score\"])\n",
    "    except:\n",
    "        print(\"Warning: rouge_score package installation failed. Proceeding without ROUGE metrics.\")\n",
    "    \n",
    "    # Models to evaluate\n",
    "    models = [\n",
    "        'generative_model',  # Original model\n",
    "        't5_squad_legal_model'  # SQuAD fine-tuned model\n",
    "    ]\n",
    "    \n",
    "    # Check which models are available\n",
    "    available_models = []\n",
    "    for model in models:\n",
    "        try:\n",
    "            if os.path.exists(model) or os.path.exists(model + '/config.json'):\n",
    "                available_models.append(model)\n",
    "                print(f\"Found model: {model}\")\n",
    "            else:\n",
    "                print(f\"Model not found: {model}\")\n",
    "        except:\n",
    "            print(f\"Error checking model: {model}\")\n",
    "    \n",
    "    if not available_models:\n",
    "        print(\"No models available for evaluation. Please train at least one model first.\")\n",
    "        return\n",
    "    \n",
    "    # Run comparison\n",
    "    comparison_results = compare_models(available_models)\n",
    "    \n",
    "    print(\"\\nEvaluation complete!\")\n",
    "    \n",
    "    # Return results for further analysis\n",
    "    return comparison_results\n",
    "\n",
    "# Add error analysis function\n",
    "def analyze_errors(results):\n",
    "    \"\"\"Analyze the types of errors made by the model\"\"\"\n",
    "    error_questions = [q for q in results['questions'] if not q['evaluation']['is_correct']]\n",
    "    \n",
    "    print(f\"Total errors: {len(error_questions)}/{results['overall']['total']}\")\n",
    "    \n",
    "    # Group errors by question type\n",
    "    error_by_type = {}\n",
    "    for q in error_questions:\n",
    "        qtype = q['question_type']\n",
    "        if qtype not in error_by_type:\n",
    "            error_by_type[qtype] = []\n",
    "        error_by_type[qtype].append(q)\n",
    "    \n",
    "    print(\"\\nErrors by question type:\")\n",
    "    for qtype, questions in sorted(error_by_type.items(), key=lambda x: len(x[1]), reverse=True):\n",
    "        total_of_type = results['by_type'][qtype]['total']\n",
    "        error_rate = len(questions) / total_of_type\n",
    "        print(f\"  {qtype}: {len(questions)}/{total_of_type} ({error_rate:.2%})\")\n",
    "    \n",
    "    # Analyze most common missing terms\n",
    "    missing_terms = {}\n",
    "    for q in error_questions:\n",
    "        for term in q['evaluation']['required_terms']:\n",
    "            if term not in q['evaluation']['terms_found']:\n",
    "                if term not in missing_terms:\n",
    "                    missing_terms[term] = 0\n",
    "                missing_terms[term] += 1\n",
    "    \n",
    "    print(\"\\nMost frequently missing terms:\")\n",
    "    for term, count in sorted(missing_terms.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "        print(f\"  '{term}': missing in {count} answers\")\n",
    "    \n",
    "    # Sample error cases\n",
    "    print(\"\\nSample error cases:\")\n",
    "    for i, q in enumerate(error_questions[:5]):\n",
    "        print(f\"\\nError {i+1}:\")\n",
    "        print(f\"Question ({q['question_type']}): {q['question']}\")\n",
    "        print(f\"Ground Truth: {q['ground_truth']}\")\n",
    "        print(f\"Generated: {q['generated_answer']}\")\n",
    "        print(f\"Score: {q['evaluation']['combined_score']:.2f}\")\n",
    "        print(f\"Missing terms: {set(q['evaluation']['required_terms']) - set(q['evaluation']['terms_found'])}\")\n",
    "\n",
    "# Run the evaluation\n",
    "if __name__ == \"__main__\":\n",
    "    import os\n",
    "    # Make sure all necessary packages are imported\n",
    "    try:\n",
    "        from sentence_transformers import SentenceTransformer\n",
    "    except ImportError:\n",
    "        print(\"Installing sentence-transformers package...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([\"pip\", \"install\", \"sentence-transformers\"])\n",
    "    \n",
    "    try:\n",
    "        import seaborn as sns\n",
    "    except ImportError:\n",
    "        print(\"Installing seaborn package...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([\"pip\", \"install\", \"seaborn\"])\n",
    "    \n",
    "    # Run evaluation\n",
    "    results = run_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLEAR HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 historical Q&A pairs from question_history.pkl\n",
      "Question history saved to question_history.pkl\n",
      "Question history cleared. 1 entries removed.\n"
     ]
    }
   ],
   "source": [
    "# Function to clear the question history\n",
    "def clear_question_history():\n",
    "    # Load retrieval system just to clear history\n",
    "    retrieval_system = QuestionRetrievalSystem(use_sentence_transformer=True)\n",
    "    \n",
    "    try:\n",
    "        # Load current history\n",
    "        retrieval_system.load_history('question_history.pkl')\n",
    "        # Get the count for reporting\n",
    "        history_count = len(retrieval_system.question_history)\n",
    "        # Clear it\n",
    "        retrieval_system.question_history = {}\n",
    "        # Save empty history\n",
    "        retrieval_system.save_history('question_history.pkl')\n",
    "        print(f\"Question history cleared. {history_count} entries removed.\")\n",
    "    except:\n",
    "        print(\"No history file found or error clearing history.\")\n",
    "        # Create an empty history file\n",
    "        retrieval_system.save_history('question_history.pkl')\n",
    "        print(\"New empty history file created.\")\n",
    "\n",
    "clear_question_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
